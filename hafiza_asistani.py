from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import faiss
import time
import requests
import json
import os
import re
import asyncio
import aiohttp
import hashlib
import logging
from typing import List, Optional, Dict, Any, Tuple
from datetime import datetime
from zoneinfo import ZoneInfo
from collections import defaultdict
from web_search import WebSearch
_web_searcher = WebSearch()  # Global instance

logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("requests").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)

from topic_memory import TopicMemory
from conversation_context import ConversationContextManager
from profile_manager import ProfileManager
from sohbet_zekasi import TurkishConversationIntelligence, BeklenenCevap, SohbetEnerjisi
# from calculation_context import CalculationContext  # Devre dÄ±ÅŸÄ± - chat history yeterli


# ============================================================
# NOT YÃ–NETÄ°CÄ°SÄ°
# ============================================================

class NotManager:
    """
    KullanÄ±cÄ±nÄ±n aldÄ±ÄŸÄ± notlarÄ± yÃ¶neten basit sistem.
    Her kullanÄ±cÄ±nÄ±n notlarÄ± ayrÄ± dosyada tutulur.

    Tetikleyiciler: "not al", "not tut", "not ekle"
    """

    def __init__(self, user_id: str = "default", base_dir: str = "user_data"):
        self.user_id = user_id
        self.notes_dir = os.path.join(base_dir, f"user_{user_id}", "notes")
        self.notes_file = os.path.join(self.notes_dir, "notlar.json")

        # KlasÃ¶r yoksa oluÅŸtur
        os.makedirs(self.notes_dir, exist_ok=True)

        # NotlarÄ± yÃ¼kle
        self.notes = self._load_notes()

        # Onay bekleyen not
        self.pending_note = None

    def _load_notes(self) -> List[Dict]:
        """NotlarÄ± dosyadan yÃ¼kle"""
        if os.path.exists(self.notes_file):
            try:
                with open(self.notes_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return []
        return []

    def _save_notes(self):
        """NotlarÄ± dosyaya kaydet"""
        with open(self.notes_file, 'w', encoding='utf-8') as f:
            json.dump(self.notes, f, ensure_ascii=False, indent=2)

    def not_al(self, icerik: str) -> str:
        """Yeni not kaydet (onay olmadan direkt kaydet)"""
        if not icerik or len(icerik.strip()) < 2:
            return "âŒ Not iÃ§eriÄŸi boÅŸ olamaz."

        now = datetime.now()
        gun_isimleri = {
            0: "Pazartesi", 1: "SalÄ±", 2: "Ã‡arÅŸamba", 3: "PerÅŸembe",
            4: "Cuma", 5: "Cumartesi", 6: "Pazar"
        }
        yeni_not = {
            "id": len(self.notes) + 1,
            "icerik": icerik.strip(),
            "tarih": now.strftime("%d.%m.%Y"),
            "gun": gun_isimleri[now.weekday()],
            "saat": now.strftime("%H:%M"),
            "timestamp": now.isoformat()
        }

        self.notes.append(yeni_not)
        self._save_notes()

        return f"âœ… Not kaydedildi:\n\n#{yeni_not['id']} [{yeni_not['tarih']} {yeni_not['gun']} - {yeni_not['saat']}]\n   {icerik}"

    def notlari_getir(self, arama: str = None) -> str:
        """NotlarÄ± getir, opsiyonel arama"""
        if not self.notes:
            return "ğŸ“ HenÃ¼z hiÃ§ not almamÄ±ÅŸsÄ±n."

        if arama:
            # Arama yap
            arama_lower = arama.lower()
            bulunanlar = [n for n in self.notes if arama_lower in n['icerik'].lower()]
            if not bulunanlar:
                return f"ğŸ” '{arama}' ile ilgili not bulunamadÄ±."
            notlar = bulunanlar
            baslik = f"ğŸ” '{arama}' ile ilgili {len(notlar)} not:"
        else:
            notlar = self.notes[-10:]  # Son 10 not
            baslik = f"ğŸ“ NotlarÄ±n ({len(self.notes)} toplam, son {len(notlar)} gÃ¶steriliyor):"

        result = baslik + "\n\n"
        for n in notlar:
            gun = n.get('gun', '')
            gun_str = f" {gun}" if gun else ""
            result += f"#{n['id']} [{n['tarih']}{gun_str} - {n['saat']}]\n"
            result += f"   {n['icerik']}\n\n"

        return result.strip()

    def not_sil(self, not_id: int) -> str:
        """ID'ye gÃ¶re not sil"""
        for i, n in enumerate(self.notes):
            if n['id'] == not_id:
                silinen = self.notes.pop(i)
                self._save_notes()
                return f"ğŸ—‘ï¸ Not #{not_id} silindi: {silinen['icerik'][:30]}..."
        return f"âŒ #{not_id} numaralÄ± not bulunamadÄ±."

    def has_pending(self) -> bool:
        """Bekleyen not var mÄ±?"""
        return self.pending_note is not None


# ============================================================
# YARDIMCI FONKSÄ°YONLAR
# ============================================================

def get_current_datetime() -> Dict[str, str]:
    """TÃ¼rkiye saati ile ÅŸu anki tarih ve saati getir"""
    try:
        tz = ZoneInfo("Europe/Istanbul")
        now = datetime.now(tz)

        ay_isimleri = {
            1: "Ocak", 2: "Åubat", 3: "Mart", 4: "Nisan",
            5: "MayÄ±s", 6: "Haziran", 7: "Temmuz", 8: "AÄŸustos",
            9: "EylÃ¼l", 10: "Ekim", 11: "KasÄ±m", 12: "AralÄ±k"
        }

        gun_isimleri = {
            0: "Pazartesi", 1: "SalÄ±", 2: "Ã‡arÅŸamba", 3: "PerÅŸembe",
            4: "Cuma", 5: "Cumartesi", 6: "Pazar"
        }

        ay = ay_isimleri[now.month]
        gun = gun_isimleri[now.weekday()]
        saat = now.hour

        return {
            "tarih": f"{now.day} {ay} {now.year}",
            "gun": gun,
            "saat": now.strftime("%H:%M"),
            "full": f"{now.day} {ay} {now.year} {gun}, Saat: {now.strftime('%H:%M')}",
            "zaman_dilimi": "",
            "saat_int": saat,
        }
    except Exception:
        return {
            "tarih": "Bilinmiyor",
            "gun": "Bilinmiyor",
            "saat": "Bilinmiyor",
            "full": "Tarih/saat bilgisi alÄ±namadÄ±",
            "zaman_dilimi": "",
            "saat_int": 12,
        }


def calculate_math(expression: str) -> str:
    """Matematiksel ifadeyi gÃ¼venli ÅŸekilde hesapla"""
    import math
    import re

    try:
        safe_expression = expression.strip()

        # TÃ¼rkÃ§e operatÃ¶rleri Ã§evir
        safe_expression = safe_expression.replace("x", "*")
        safe_expression = safe_expression.replace("X", "*")
        safe_expression = safe_expression.replace("Ã—", "*")
        safe_expression = safe_expression.replace("Ã§arpÄ±", "*")
        safe_expression = safe_expression.replace("Ã§arp", "*")
        safe_expression = safe_expression.replace("bÃ¶lÃ¼", "/")
        safe_expression = safe_expression.replace("Ã·", "/")
        safe_expression = safe_expression.replace("artÄ±", "+")
        safe_expression = safe_expression.replace("eksi", "-")

        # YÃ¼zde iÅŸlemlerini Ã§evir: %18 â†’ 0.18, yÃ¼zde 18 â†’ 0.18
        safe_expression = re.sub(r'[%](\d+(?:\.\d+)?)', r'(\1/100)', safe_expression)
        safe_expression = re.sub(r'yÃ¼zde\s*(\d+(?:\.\d+)?)', r'(\1/100)', safe_expression, flags=re.IGNORECASE)

        # Birim metinlerini temizle (TL, kg, ton, metre, mÂ², mÂ³, vb.)
        units_to_remove = [
            r'\bTL\b', r'\btl\b', r'\bLira\b', r'\blira\b',
            r'\bkg\b', r'\bKG\b', r'\bkilogram\b', r'\bkilo\b',
            r'\bton\b', r'\bTON\b',
            r'\bmetre\b', r'\bm\b', r'\bmÂ²\b', r'\bmÂ³\b', r'\bm2\b', r'\bm3\b',
            r'\bmetrekare\b', r'\bmetrekÃ¼p\b',
            r'\bkat\b', r'\bkatlÄ±\b',
            r'\badet\b', r'\btane\b',
            r'/ton\b', r'/kg\b', r'/m\b',
            r'\bKDV\b', r'\bkdv\b',
        ]
        for unit in units_to_remove:
            safe_expression = re.sub(unit, '', safe_expression)

        # VirgÃ¼lÃ¼ noktaya Ã§evir (TÃ¼rkÃ§e ondalÄ±k)
        safe_expression = safe_expression.replace(',', '.')

        # Fazla boÅŸluklarÄ± temizle
        safe_expression = re.sub(r'\s+', ' ', safe_expression).strip()
        safe_expression = safe_expression.replace(' ', '')

        allowed_chars = "0123456789+-*/(). "
        if not all(c in allowed_chars for c in safe_expression):
            return "âŒ GÃ¼venlik: Sadece sayÄ±lar ve matematiksel operatÃ¶rler kullanÄ±labilir."

        safe_dict = {
            "sqrt": math.sqrt,
            "pow": math.pow,
            "abs": abs,
            "round": round,
            "sin": math.sin,
            "cos": math.cos,
            "tan": math.tan,
            "pi": math.pi,
            "e": math.e,
        }

        result = eval(safe_expression, {"__builtins__": {}}, safe_dict)

        if isinstance(result, float):
            if result.is_integer():
                return str(int(result))
            return f"{result:.4f}".rstrip("0").rstrip(".")

        return str(result)

    except ZeroDivisionError:
        return "âŒ Hata: SÄ±fÄ±ra bÃ¶lme yapÄ±lamaz!"
    except Exception:
        return "âŒ Hesaplama hatasÄ±: GeÃ§ersiz matematiksel ifade."


async def web_ara(query: str, context: str = "") -> str:
    """
    Tavily API ile internet aramasÄ±.
    TarÄ±m/Ã¼retim sorularÄ±nda teknik bilgi odaklÄ± arama yapar.
    """
    try:
        search_query = query
        if context:
            search_query = f"{query} {context}"

        # TarÄ±m/Ã¼retim sorularÄ±nda teknik bilgi odaklÄ± arama
        tarim_keywords = ['mantar', 'yetiÅŸtir', 'Ã¼retim', 'tarÄ±m', 'sera', 'hasat', 'ekim', 'dikim']
        query_lower = query.lower()

        if any(kw in query_lower for kw in tarim_keywords):
            # Sorgudan ana konuyu Ã§Ä±kar ve teknik bilgi ekle
            if 'kaÃ§' in query_lower or 'ne kadar' in query_lower or 'verim' in query_lower:
                # Verim sorusu - teknik koÅŸullarÄ± ara
                search_query = f"{query} yetiÅŸtirme koÅŸullarÄ± sÄ±caklÄ±k nem raf aralÄ±ÄŸÄ± metrekare verim"
            else:
                # Genel tarÄ±m sorusu - teknik detaylarÄ± ekle
                search_query = f"{query} yetiÅŸtirme koÅŸullarÄ± teknik bilgi"
            print(f"   ğŸ“ TarÄ±m sorusu algÄ±landÄ± - teknik arama yapÄ±lÄ±yor")

        print(f"\nğŸŒ Web aramasÄ±: '{search_query}'")

        result = _web_searcher.quick_answer(search_query)

        if result and "Arama hatasi" not in result and "Sonuc bulunamadi" not in result:
            print(f"   âœ… SonuÃ§ bulundu")
            return result

        print(f"   âŒ SonuÃ§ bulunamadÄ±")
        return None

    except Exception as e:
        print(f"âŒ Web arama hatasÄ±: {e}")
        return None


async def get_weather(city: str) -> str:
    """Åehir iÃ§in hava durumu bilgisi getir (wttr.in API)"""
    try:
        city = (
            city.replace("hava durumu", "")
            .replace("hava", "")
            .replace("nasÄ±l", "")
            .strip()
        )

        # wttr.in API - Ã¼cretsiz, key gerektirmez, kar tespiti daha iyi
        url = f"https://wttr.in/{city}?format=j1&lang=tr"

        timeout = aiohttp.ClientTimeout(total=20)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url) as response:
                if response.status != 200:
                    return f"âŒ {city} iÃ§in hava durumu alÄ±namadÄ±."
                data = await response.json()

        current = data["current_condition"][0]

        # TÃ¼rkÃ§e aÃ§Ä±klama al
        desc_list = current.get("lang_tr", [])
        if desc_list:
            description = desc_list[0].get("value", current["weatherDesc"][0]["value"])
        else:
            description = current["weatherDesc"][0]["value"]

        temp = float(current["temp_C"])
        feels_like = float(current["FeelsLikeC"])
        humidity = current["humidity"]
        wind_speed = float(current["windspeedKmph"]) / 3.6  # km/h -> m/s

        result = "[KORUNACAK_FORMAT]\n"
        result += f"ğŸŒ¤ï¸ {city.title()} Hava Durumu\n"
        result += f"{'â”€' * 32}\n\n"
        result += f"â˜ï¸ Durum:       {description}\n"
        result += f"ğŸŒ¡ï¸ SÄ±caklÄ±k:    {temp:.1f}Â°C\n"
        result += f"ğŸ¤š Hissedilen:  {feels_like:.1f}Â°C\n"
        result += f"ğŸ’¨ RÃ¼zgar:      {wind_speed:.1f} m/s\n"
        result += f"ğŸ’§ Nem:         {humidity}%\n"
        result += "[/KORUNACAK_FORMAT]"

        return result

    except Exception as e:
        return f"âŒ {city} iÃ§in hava durumu alÄ±namadÄ±: {str(e)}"


async def get_prayer_times(city: str, specific_prayer: str = None) -> str:
    """Åehir iÃ§in namaz vakitlerini getir (Aladhan API)"""
    try:
        city = (
            city.replace("namaz vakitleri", "")
            .replace("namaz vakti", "")
            .replace("ezan", "")
            .strip()
        )
        city = (
            city.replace("â€™da", "")
            .replace("â€™de", "")
            .replace("â€™Ä±n", "")
            .replace("â€™in", "")
            .strip()
        )

        url = "http://api.aladhan.com/v1/timingsByCity"
        params = {
            "city": city,
            "country": "Turkey",
            "method": 13,
        }

        timeout = aiohttp.ClientTimeout(total=5)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url, params=params) as response:
                if response.status != 200:
                    return f"âŒ {city} ÅŸehri bulunamadÄ±."
                data = await response.json()

        if data.get("code") != 200:
            return f"âŒ {city} iÃ§in namaz vakitleri alÄ±namadÄ±."

        timings = data["data"]["timings"]
        date_info = data["data"]["date"]["gregorian"]

        prayer_names = {
            "Fajr": ("Ä°msak", "ğŸŒ™"),
            "Sunrise": ("GÃ¼neÅŸ", "â˜€ï¸"),
            "Dhuhr": ("Ã–ÄŸle", "ğŸŒ¤ï¸"),
            "Asr": ("Ä°kindi", "ğŸŒ…"),
            "Maghrib": ("AkÅŸam", "ğŸŒ†"),
            "Isha": ("YatsÄ±", "ğŸŒƒ"),
        }

        if specific_prayer:
            specific_prayer = specific_prayer.lower().strip()
            prayer_map = {
                "imsak": "Fajr",
                "gÃ¼neÅŸ": "Sunrise",
                "Ã¶ÄŸle": "Dhuhr",
                "ikindi": "Asr",
                "akÅŸam": "Maghrib",
                "yatsÄ±": "Isha",
            }

            for tr_name, eng_name in prayer_map.items():
                if tr_name in specific_prayer:
                    time_value = timings[eng_name]
                    turkish_name, emoji = prayer_names[eng_name]
                    return f"{emoji} {city.title()} {turkish_name} namazÄ±: {time_value}"

        result = "[KORUNACAK_FORMAT]\n"
        result += f"ğŸ•Œ {city.title()} Namaz Vakitleri\n"
        result += (
            f"ğŸ“… {date_info['day']} {date_info['month']['en']} {date_info['year']}\n"
        )
        result += f"{'â”€' * 32}\n\n"

        for eng_name, (turkish_name, emoji) in prayer_names.items():
            time_value = timings[eng_name]
            padded_name = f"{turkish_name:<8}"
            result += f"{emoji} {padded_name} {time_value}\n"

        result += "[/KORUNACAK_FORMAT]"
        return result.strip()

    except Exception as e:
        return f"âŒ Namaz vakitleri alÄ±namadÄ±: {str(e)}"



_ToolSystem = None

def get_tool_system_class():
    """ToolSystem'i lazy import et (circular import Ã¶nlemi)"""
    global _ToolSystem
    if _ToolSystem is None:
        try:
            from personal_ai import ToolSystem
            _ToolSystem = ToolSystem
        except ImportError:
            class FallbackToolSystem:
                TOOLS = {
                    "risale_ara": {"name": "risale_ara", "description": "Dini sorulara cevap", "parameters": "soru", "when": "Dini konularda", "examples": ["Ä°man nedir?"]},
                    "zaman_getir": {"name": "zaman_getir", "description": "Tarih/saat", "parameters": "yok", "when": "Zaman sorulduÄŸunda", "examples": ["Saat kaÃ§?"]},
                    "hava_durumu": {"name": "hava_durumu", "description": "Hava durumu", "parameters": "ÅŸehir", "when": "Hava sorulduÄŸunda", "examples": ["Ä°stanbul hava"]},
                    "namaz_vakti": {"name": "namaz_vakti", "description": "Namaz vakitleri", "parameters": "ÅŸehir", "when": "Namaz vakti sorulduÄŸunda", "examples": ["Ankara namaz"]},
                    "web_ara": {"name": "web_ara", "description": "Ä°nternette bilgi veya haber ara", "parameters": "arama terimi", "when": "BilmediÄŸin konu, gÃ¼ncel haber, kiÅŸi, yer, olay sorulduÄŸunda", "examples": ["Einstein kimdir", "son haberler", "Python nedir"]},
                    "yok": {"name": "yok", "description": "Direkt cevap", "parameters": "yok", "when": "Genel sohbet", "examples": ["Merhaba"]},
                }
                @staticmethod
                def get_tools_prompt() -> str:
                    tools_text = "ARAÃ‡LAR:\n"
                    for name, info in FallbackToolSystem.TOOLS.items():
                        tools_text += f"{name}: {info['description']}\n"
                    return tools_text
                @staticmethod
                def get_tool_calling_prompt(user_input: str) -> str:
                    return f"{FallbackToolSystem.get_tools_prompt()}\nSORU: {user_input}\nARAÃ‡:"
                @staticmethod
                def parse_tool_decision(llm_response: str) -> Tuple[str, str]:
                    tool_name = "yok"
                    tool_param = ""
                    for line in llm_response.split("\n"):
                        if line.startswith("ARAÃ‡:"): tool_name = line.replace("ARAÃ‡:", "").strip().lower()
                        elif line.startswith("PARAMETRE:"): tool_param = line.replace("PARAMETRE:", "").strip()
                    if tool_name not in FallbackToolSystem.TOOLS: tool_name = "yok"
                    if tool_param.lower() == "yok": tool_param = ""
                    return tool_name, tool_param
            _ToolSystem = FallbackToolSystem
    return _ToolSystem


class ToolSystem:
    """
    ToolSystem wrapper - personal_ai.py'daki ToolSystem'e yÃ¶nlendirir

    NOT: AsÄ±l implementasyon personal_ai.py'da (tek kaynak)
    """

    @property
    def TOOLS(self):
        return get_tool_system_class().TOOLS

    @staticmethod
    def get_tools_prompt() -> str:
        return get_tool_system_class().get_tools_prompt()

    @staticmethod
    def get_tool_calling_prompt(user_input: str) -> str:
        return get_tool_system_class().get_tool_calling_prompt(user_input)

    @staticmethod
    def parse_tool_decision(llm_response: str) -> Tuple[str, str]:
        return get_tool_system_class().parse_tool_decision(llm_response)





_ROLES_CACHE = None

def get_roles():
    """ROLES'u personal_ai.py'dan al - artÄ±k tek basit rol"""
    global _ROLES_CACHE
    if _ROLES_CACHE is None:
        try:
            from personal_ai import SystemConfig
            _ROLES_CACHE = SystemConfig.ROLES
        except ImportError:
            # Fallback: tek basit rol
            _ROLES_CACHE = {
                "default": {"keywords": [], "tone": "natural", "response_style": "adaptive"}
            }
    return _ROLES_CACHE


_MultiRoleSystem = None

def get_multi_role_system_class():
    """MultiRoleSystem'i lazy import et - artÄ±k sadeleÅŸtirilmiÅŸ"""
    global _MultiRoleSystem
    if _MultiRoleSystem is None:
        try:
            from personal_ai import MultiRoleSystem as _MRS
            _MultiRoleSystem = _MRS
        except ImportError:
            class FallbackMultiRoleSystem:
                def __init__(self):
                    self.enabled = False  # Devre dÄ±ÅŸÄ±
                @property
                def ROLES(self):
                    return get_roles()
                def detect_role(self, user_input: str) -> str:
                    return "default"  # Her zaman default
            _MultiRoleSystem = FallbackMultiRoleSystem
    return _MultiRoleSystem


class MultiRoleSystem:
    """
    SadeleÅŸtirilmiÅŸ MultiRoleSystem - tek tutarlÄ± kiÅŸilik
    """

    def __init__(self):
        self._impl = get_multi_role_system_class()()

    @property
    def ROLES(self):
        return get_roles()

    def detect_role(self, user_input: str) -> str:
        return "default"  # ArtÄ±k her zaman default dÃ¶ner



class FAISSKnowledgeBase:
    """
    FAISS tabanlÄ± yerel bilgi tabanÄ±
    Risale-i Nur, dÃ¶kÃ¼manlar iÃ§in
    """

    # Config ayarlarÄ±
    FAISS_INDEX_FILE = "faiss_index.bin"
    FAISS_TEXTS_FILE = "faiss_texts_final.json"
    FAISS_SEARCH_TOP_K = 10
    FAISS_SIMILARITY_THRESHOLD = 0.48
    FAISS_MAX_RESULTS = 6
    FAISS_RELATIVE_THRESHOLD = 0.90

    def __init__(self, user_id: str = "default"):
        self.user_id = user_id
        self.enabled = True
        self.user_namespace = f"user_{user_id}"

        # Data
        self.texts = []
        self.index = None
        self.embedding_model = None

        # Load
        self._load_components()

    def _load_components(self):
        """Index ve text dosyalarÄ±nÄ± yÃ¼kle"""
        try:
            # FAISS index
            if os.path.exists(self.FAISS_INDEX_FILE):
                self.index = faiss.read_index(self.FAISS_INDEX_FILE)
                print(f"âœ… FAISS index yÃ¼klendi: {self.FAISS_INDEX_FILE}")
            else:
                print(f"âš ï¸ FAISS index bulunamadÄ±: {self.FAISS_INDEX_FILE}")
                self.enabled = False
                return

            # Texts JSON
            if os.path.exists(self.FAISS_TEXTS_FILE):
                with open(self.FAISS_TEXTS_FILE, 'r', encoding='utf-8') as f:
                    self.texts = json.load(f)
                print(f"âœ… FAISS texts yÃ¼klendi: {len(self.texts)} dÃ¶kÃ¼man")
            else:
                print(f"âš ï¸ FAISS texts bulunamadÄ±: {self.FAISS_TEXTS_FILE}")
                self.enabled = False
                return

            # Embedding model (zaten HafizaAsistani'da yÃ¼klÃ¼, onu kullanacaÄŸÄ±z)
            # Burada ayrÄ± yÃ¼klemiyoruz, get_relevant_context'te parametre olarak alacaÄŸÄ±z

            print(f"âœ… FAISS Bilgi TabanÄ± hazÄ±r: {len(self.texts)} dÃ¶kÃ¼man")

        except Exception as e:
            print(f"âŒ FAISS yÃ¼kleme hatasÄ±: {e}")
            self.enabled = False

    def set_embedding_model(self, model):
        """Embedding modelini set et (HafizaAsistani'dan)"""
        self.embedding_model = model

    def get_relevant_context(self, query: str, max_chunks: int = 6) -> str:
        """KullanÄ±cÄ± input'una gÃ¶re ilgili baÄŸlamÄ± getir"""
        if not self.enabled:
            print("âš ï¸ FAISS KB devre dÄ±ÅŸÄ±")
            return ""

        try:
            print(f"\n{'='*60}")
            print(f"ğŸ” FAISS KB ARAMA BAÅLADI")
            print(f"ğŸ“ Sorgu: {query}")
            print(f"ğŸ“Š Max chunks: {max_chunks}")
            print(f"{'='*60}")

            # Search
            results = self.search(query, top_k=max_chunks * 2)

            print(f"\nğŸ“Š ARAMA SONUÃ‡LARI: {len(results)} sonuÃ§")

            if not results:
                print("   âŒ HiÃ§ sonuÃ§ bulunamadÄ±!")
                return ""

            # Ä°lgili bilgileri birleÅŸtir
            combined_text = "Ä°LGÄ°LÄ° BÄ°LGÄ°LER:\n"

            for i, result in enumerate(results[:max_chunks]):
                text = result.get('text', '')
                score = result.get('score', 0.0)

                print(f"   ğŸ“„ #{i+1}: Skor={score:.4f}, {len(text)} karakter")

                if text:
                    combined_text += f"{text}\n\n"

            print(f"âœ… FAISS KB ARAMA TAMAMLANDI - {len(combined_text)} karakter")

            return combined_text.strip()

        except Exception as e:
            print(f"âŒ FAISS context hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return ""

    def search(self, query: str, top_k: int = None) -> List[Dict]:
        """Bilgi tabanÄ±nda ara"""
        if not self.enabled or not self.embedding_model:
            print("âš ï¸ FAISS KB search devre dÄ±ÅŸÄ± veya embedding model yok")
            return []

        try:
            requested_k = top_k or self.FAISS_SEARCH_TOP_K

            # Embed query
            query_vector = self.embedding_model.encode(
                [query],
                normalize_embeddings=True
            )
            query_vector = np.array(query_vector, dtype=np.float32)

            # Search
            k = min(requested_k + 10, len(self.texts))
            scores, indices = self.index.search(query_vector, k)

            # Filter results
            results = []

            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx == -1:
                    continue

                similarity = float(score)

                if similarity >= self.FAISS_SIMILARITY_THRESHOLD and idx < len(self.texts):
                    text_data = self.texts[idx]

                    # Text content
                    if isinstance(text_data, dict):
                        text_content = text_data.get('text', str(text_data))
                    else:
                        text_content = str(text_data)

                    results.append({
                        'text': text_content,
                        'score': similarity,
                        'index': int(idx)
                    })

            # Relative scoring: En yÃ¼ksek skorun %90'Ä± altÄ±ndakileri Ã§Ä±kar
            if results:
                top_score = results[0]['score']
                relative_threshold = top_score * self.FAISS_RELATIVE_THRESHOLD

                filtered_results = [r for r in results if r['score'] >= relative_threshold]

                # Max sonuÃ§ limiti
                if len(filtered_results) > self.FAISS_MAX_RESULTS:
                    filtered_results = filtered_results[:self.FAISS_MAX_RESULTS]

                return filtered_results

            return results

        except Exception as e:
            print(f"âŒ FAISS search hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return []


# Geriye uyumluluk iÃ§in alias
SimpleFAISSKB = FAISSKnowledgeBase



class DecisionLLM:
    """Together.ai API ile akÄ±llÄ± karar verme (Llama 70B)"""

    def __init__(self, api_key: str = None, model: str = "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo"):
        self.api_key = api_key or os.getenv("TOGETHER_API_KEY")
        self.model = model
        self.base_url = "https://api.together.xyz/v1/completions"

        if not self.api_key:
            raise ValueError("âŒ TOGETHER_API_KEY bulunamadÄ±! .env dosyasÄ±nÄ± kontrol edin.")

        if not self._try_connect():
            raise ConnectionError("âŒ Together.ai API'sine baÄŸlanÄ±lamadÄ±!")

        print(f"ğŸ§  DecisionLLM baÅŸlatÄ±ldÄ± (Model: {model}, Together.ai)")

    def _try_connect(self) -> bool:
        """Together.ai API baÄŸlantÄ±sÄ±nÄ± test et"""
        try:
            response = requests.get(
                "https://api.together.xyz/v1/models",
                headers={"Authorization": f"Bearer {self.api_key}"},
                timeout=5
            )
            return response.status_code == 200
        except (requests.RequestException, requests.Timeout) as e:
            print(f"Together API baÄŸlantÄ± hatasÄ±: {e}")
            return False

    def _call_llm(self, prompt: str, max_tokens: int = 100) -> str:
        """Together.ai API'sine prompt gÃ¶nder"""
        try:
            response = requests.post(
                self.base_url,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "max_tokens": max_tokens,
                    "temperature": 0.1,  # Karar alma iÃ§in deterministik
                    "stop": ["<|eot_id|>", "<|end_of_text|>"]
                },
                timeout=15,
            )

            if response.status_code == 200:
                return response.json()["choices"][0]["text"].strip()
            return ""
        except Exception as e:
            print(f"âŒ DecisionLLM hatasÄ±: {e}")
            return ""

    def extract_topics(self, query: str, max_topics: int = 3) -> List[str]:
        """KonularÄ± akÄ±llÄ±ca Ã§Ä±kar"""
        prompt = f"""<|begin_of_text|><|start_header_id|>user<|end_header_id|>

KullanÄ±cÄ± mesajÄ±: "{query}"

GÃ–REV: ANA KONULARI bul (maksimum {max_topics} adet)

KURALLAR:

- Uzun kelimeler deÄŸil, ANLAMLI konular
- Her satÄ±ra 1 konu
- AlakasÄ±z kelime ekleme

KONULAR:<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""

        response = self._call_llm(prompt, max_tokens=50)

        topics = [
            line.strip().strip("-â€¢*").strip()
            for line in response.split("\n")
            if line.strip() and len(line.strip()) > 3
        ]

        return topics[:max_topics]



class HafizaAsistani:
    """
    ğŸ§  GeliÅŸmiÅŸ HafÄ±za AsistanÄ± v3.0 - GERÃ‡EK SEKRETER

    Ã–ZELLÄ°KLER:
    - Benzerlik tabanlÄ± arama (BGE-M3)
    - Tool System entegrasyonu
    - Web Search
    - FAISS KB eriÅŸimi
    - Multi-Role System
    - AkÄ±llÄ± prompt hazÄ±rlama
    - DecisionLLM ile karar verme
    """

    def __init__(
        self,
        user_id: str = None,  # Dinamik kullanÄ±cÄ± ID
        saat_limiti: int = 48,
        esik: float = 0.50,
        max_mesaj: int = 50,  # Gemma 3 27B 128K token destekliyor
        model_adi: str = "BAAI/bge-m3",
        use_decision_llm: bool = True,
        together_api_key: str = None,
        decision_model: str = "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    ):
        print("=" * 60)
        print("ğŸ§  HafizaAsistani v3.1 - AkÄ±llÄ± Sekreter")
        print("   â€¢ LLM Karar Sistemi + AkÄ±llÄ± Web Arama")
        print("=" * 60)

        # KullanÄ±cÄ± ID - None ise varsayÄ±lan kullan
        self.user_id = user_id or "default_user"
        print(f"ğŸ‘¤ KullanÄ±cÄ±: {self.user_id}")

        self.together_api_key = together_api_key or os.getenv("TOGETHER_API_KEY")
        self.decision_model = decision_model

        print("ğŸ“¦ Embedding modeli yÃ¼kleniyor...")
        self.embedder = SentenceTransformer(model_adi)
        print(f"âœ… Model '{model_adi}' yÃ¼klendi!")

        self.hafiza: List[Dict[str, Any]] = []
        self.saat_limiti = saat_limiti * 3600
        self.esik = esik
        self.max_mesaj = max_mesaj

        if not use_decision_llm:
            raise ValueError("âŒ DecisionLLM zorunludur!")

        try:
            self.decision_llm = DecisionLLM(api_key=self.together_api_key, model=decision_model)
            self.use_decision_llm = True
            print("âœ… DecisionLLM aktif!")
        except Exception as e:
            raise RuntimeError(f"DecisionLLM baÅŸlatÄ±lamadÄ±: {e}")

        self.tool_system = ToolSystem()
        print("âœ… Tool System aktif!")

        self.multi_role = MultiRoleSystem()
        print("âœ… Multi-Role System aktif!")

        self.faiss_kb = FAISSKnowledgeBase(user_id=self.user_id)
        self.faiss_kb.set_embedding_model(self.embedder)  # Embedding model'i set et
        print(f"âœ… FAISS KB hazÄ±r (aktif: {self.faiss_kb.enabled})")

        self.closed_topics: List[Dict[str, Any]] = []
        self.max_closed_topics = 20  # En fazla 20 kapanan konu tut
        print("âœ… Closed Topics Tracker aktif!")

        self.topic_memory = TopicMemory(
            user_id=self.user_id,
            base_dir="user_data",
            together_api_key=self.together_api_key,
            together_model=decision_model,
            embedding_model=model_adi  # AynÄ± embedding modelini kullan
        )
        print("âœ… Topic Memory aktif!")

        self._injected_categories = {}  # {category_id: message_count_when_injected}
        self._message_counter = 0  # Toplam mesaj sayacÄ±
        self._injection_cooldown = 5  # KaÃ§ mesaj sonra tekrar enjekte edilebilir

        # ğŸ” NetleÅŸtirme sonrasÄ± otomatik web arama flag'i
        self._netlistirme_bekleniyor = False

        self.conversation_context = ConversationContextManager(
            user_id=self.user_id,
            base_dir="user_data",
            together_api_key=self.together_api_key,
            together_model=decision_model,
            archive_to_faiss=False  # Åimdilik dosya bazlÄ± arÅŸivleme
        )
        print("âœ… Conversation Context aktif!")

        # KullanÄ±cÄ± Profili
        self.profile_manager = ProfileManager(
            user_id=self.user_id,
            base_dir="user_data"
        )
        if self.profile_manager.has_profile():
            print(f"âœ… KullanÄ±cÄ± Profili yÃ¼klendi: {self.profile_manager.get_name()}")
        else:
            print("âœ… KullanÄ±cÄ± Profili aktif (henÃ¼z boÅŸ)")

        # TÃ¼rkÃ§e Sohbet ZekasÄ±
        self.sohbet_zekasi = TurkishConversationIntelligence()
        self._son_sohbet_analizi = None  # Son analiz sonucunu sakla (prompt iÃ§in)

        # ğŸ“ Not YÃ¶neticisi
        self.not_manager = NotManager(user_id=self.user_id, base_dir="user_data")
        self._pending_not = False  # "Not al" sonrasÄ± bekleme modu
        print(f"âœ… Not Manager aktif ({len(self.not_manager.notes)} not)")

        # ğŸ“ Konum Bilgisi
        self.user_location: Optional[Tuple[float, float]] = None  # (lat, lon)
        self.konum_adres: Optional[str] = None  # Konum adresi (mahalle, ilÃ§e, il)
        self.son_yakin_yerler: List[Dict] = []  # Son yakÄ±n yer arama sonuÃ§larÄ±
        print("âœ… Konum Hizmetleri aktif")

        # Hesaplama DeÄŸiÅŸkenleri - Devre dÄ±ÅŸÄ± (chat history yeterli)
        # self.calculation_context = CalculationContext()
        # print("âœ… Calculation Context aktif!")

        print("\nâš™ï¸ Sekreter AyarlarÄ±:")
        print(f"   â€¢ Zaman limiti: {saat_limiti} saat")
        print(f"   â€¢ Benzerlik eÅŸiÄŸi: {esik}")
        print(f"   â€¢ Max mesaj: {max_mesaj}")
        print("   â€¢ DecisionLLM: âœ… (Together.ai)")
        print("   â€¢ Sohbet ZekasÄ±: âœ…")
        print("\nğŸ”§ Aktif Tool'lar:")
        print("   â€¢ web_ara: âœ… (AkÄ±llÄ± Karar - LLM belirler)")
        print("   â€¢ risale_ara: âœ… (FAISS)")
        print("   â€¢ hava_durumu: âœ… (OpenWeatherMap)")
        print("   â€¢ namaz_vakti: âœ… (Aladhan)")
        print("   â€¢ zaman_getir: âœ…")
        print("=" * 60 + "\n")


    def mesaj_ekle(self, mesaj: str, rol: str = "user"):
        """Yeni mesajÄ± vektÃ¶rleÅŸtirip hafÄ±zaya ekler"""
        vektor = self.embedder.encode(mesaj)
        self.hafiza.append(
            {"rol": rol, "mesaj": mesaj, "zaman": time.time(), "vektor": vektor}
        )
        self._eski_mesajlari_sil()

    def add(self, user_message: str, ai_response: str, chat_history: List[Dict] = None):
        """
        KullanÄ±cÄ± ve AI mesajlarÄ±nÄ± hafÄ±zaya ekler.
        AyrÄ±ca ConversationContext'i de gÃ¼nceller.

        Args:
            user_message: KullanÄ±cÄ± mesajÄ±
            ai_response: AI yanÄ±tÄ±
            chat_history: Opsiyonel sohbet geÃ§miÅŸi (context iÃ§in)
        """
        self.mesaj_ekle(user_message, rol="user")
        self.mesaj_ekle(ai_response, rol="assistant")

        if self.conversation_context and chat_history:
            try:
                result = self.conversation_context.process_message(
                    user_message, ai_response, chat_history
                )
                if result.get("new_session_started"):
                    print("ğŸ”„ Yeni konu tespit edildi, session deÄŸiÅŸtirildi")

                    if len(self.hafiza) > 12:
                        tampon_bolge = self.hafiza[:-12]  # 12'den eski mesajlar
                        if tampon_bolge and self.topic_memory:
                            tampon_text = "\n".join([
                                f"[{m['rol'].upper()}]: {m['mesaj']}"
                                for m in tampon_bolge if m.get('mesaj')
                            ])
                            topic_summary = result.get('current_summary', '') or tampon_text[:200]
                            if topic_summary:
                                print(f"ğŸ’¾ Tampon bÃ¶lge TopicMemory'ye kaydediliyor ({len(tampon_bolge)} mesaj)")
                                self.add_closed_topic(topic_summary, chat_history)

                    # Konu deÄŸiÅŸtiÄŸinde aktif context'i temizle (son 10 mesaj kalsÄ±n)
                    if len(self.hafiza) > 10:
                        self.hafiza = self.hafiza[-10:]
                        print("ğŸ§¹ HafÄ±za temizlendi (son 10 mesaj kaldÄ± - yeni konuya odaklan)")
                elif result.get("summary_updated"):
                    print(f"ğŸ“ Konu Ã¶zeti gÃ¼ncellendi: {result.get('current_summary', '')[:50]}...")
            except Exception as e:
                print(f"âš ï¸ ConversationContext gÃ¼ncelleme hatasÄ±: {e}")

    def _eski_mesajlari_sil(self):
        """Belirlenen sÃ¼reyi geÃ§en mesajlarÄ± temizler"""
        simdi = time.time()
        eski_uzunluk = len(self.hafiza)
        self.hafiza = [
            m for m in self.hafiza if (simdi - m["zaman"]) < self.saat_limiti
        ]

        silinen = eski_uzunluk - len(self.hafiza)
        if silinen > 0:
            print(
                f"ğŸ§¹ {silinen} eski mesaj temizlendi ({self.saat_limiti/3600:.0f} saat sÄ±nÄ±rÄ±)"
            )

    def _search_internal(self, query: str, k: int) -> List[Dict[str, str]]:
        """
        Ä°Ã§ semantik arama fonksiyonu (TEK KAYNAK)
        search() ve ilgili_mesajlari_bul() bunu kullanÄ±r
        Returns: [{"rol": "user", "mesaj": "..."}, ...]
        """
        if not self.hafiza or not query:
            return []

        try:
            query_vector = self.embedder.encode([query], convert_to_numpy=True)

            mesaj_skorlari = []
            simdi = time.time()

            for eski_mesaj in self.hafiza:
                benzerlik = cosine_similarity(
                    query_vector.reshape(1, -1),
                    eski_mesaj["vektor"].reshape(1, -1),
                )[0][0]

                zaman_farki = simdi - eski_mesaj["zaman"]
                zaman_agirligi = 1.0 / (1.0 + (zaman_farki / 3600))

                skor = benzerlik * (0.7 + 0.3 * zaman_agirligi)

                if skor > self.esik:
                    mesaj_skorlari.append(
                        {
                            "mesaj": eski_mesaj["mesaj"],
                            "rol": eski_mesaj["rol"],
                            "skor": skor,
                            "entry": eski_mesaj,
                        }
                    )

            mesaj_skorlari.sort(key=lambda x: x["skor"], reverse=True)
            mesaj_skorlari = mesaj_skorlari[:k]
            mesaj_skorlari.sort(key=lambda x: x["entry"]["zaman"])

            return [
                {"rol": m["entry"]["rol"], "mesaj": m["entry"]["mesaj"]}
                for m in mesaj_skorlari
            ]
        except Exception as e:
            print(f"âŒ Arama hatasÄ±: {e}")
            return []

    def search(self, query: str, max_results: Optional[int] = None) -> str:
        """
        HafÄ±zada semantik arama (SADECE kÄ±sa dÃ¶nem - mevcut sohbet)

        NOT: TopicMemory (uzun dÃ¶nem) aramasÄ± ayrÄ± yapÄ±lÄ±yor:
        - get_silent_long_term_context() ile sessiz enjeksiyon
        """
        k = max_results or self.max_mesaj
        ilgili_mesajlar = self._search_internal(query, k)

        if ilgili_mesajlar:
            context_parts = []
            for m in ilgili_mesajlar:
                context_parts.append(f"- {m['rol']}: {m['mesaj']}")
            return "Ä°lgili geÃ§miÅŸ konuÅŸmalar:\n" + "\n".join(context_parts)

        return ""

    def get_silent_long_term_context(self, query: str) -> str:
        """
        ğŸ”‡ SILENT CONTEXT INJECTION (with cooldown)

        TopicMemory'den hÄ±zlÄ± kategori eÅŸleÅŸmesi yap.
        EÅŸleÅŸme varsa, sessizce LLM'e arka plan bilgisi olarak ver.

        COOLDOWN: AynÄ± kategori son 5 mesajda enjekte edildiyse tekrar enjekte etme.
        BÃ¶ylece sohbet akÄ±ÅŸÄ±nda aynÄ± bilgi sÃ¼rekli tekrarlanmaz.

        Bu bilgi:
        - KullanÄ±cÄ±ya gÃ¶sterilMEZ
        - LLM'e system context olarak verilir
        - LLM bu bilgiyi zorla hatÄ±rlatmaz, sadece cevap kalitesi iÃ§in kullanÄ±r

        Returns:
            str: Silent context (boÅŸ olabilir)
        """
        if not self.topic_memory:
            print(f"   ğŸ”‡ TopicMemory yok!")
            return ""

        try:
            self._message_counter += 1

            cat_count = len(self.topic_memory.index.get("categories", {}))
            print(f"   ğŸ”‡ TopicMemory kontrol: {cat_count} kategori mevcut")

            context = self.topic_memory.get_context_for_query(query, max_sessions=2)

            if context:
                import re
                category_match = re.search(r'\[([^\]]+)\]', context)
                if category_match:
                    category_id = category_match.group(1)

                    if category_id in self._injected_categories:
                        last_injection = self._injected_categories[category_id]
                        messages_since = self._message_counter - last_injection

                        if messages_since < self._injection_cooldown:
                            print(f"   ğŸ”‡ TopicMemory: '{category_id}' cooldown'da ({messages_since}/{self._injection_cooldown} mesaj)")
                            return ""  # Cooldown'daysa enjekte etme

                    self._injected_categories[category_id] = self._message_counter
                    print(f"   ğŸ”‡ Silent long-term context bulundu ({len(context)} karakter) - cooldown baÅŸladÄ±")
                    return context
                else:
                    print(f"   ğŸ”‡ Silent long-term context bulundu ({len(context)} karakter)")
                    return context
            else:
                print(f"   ğŸ”‡ TopicMemory: eÅŸleÅŸme yok")
                return ""

        except Exception as e:
            print(f"   âš ï¸ Silent context hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return ""

    def should_check_long_term_memory(self, user_input: str) -> bool:
        """
        Uzun dÃ¶nem hafÄ±za kontrolÃ¼ gerekli mi?

        True dÃ¶ndÃ¼ren durumlar:
        1. KullanÄ±cÄ± geÃ§miÅŸe referans veriyor
        2. Soru mevcut kategori konularÄ±yla alakalÄ± olabilir

        False dÃ¶ndÃ¼ren durumlar:
        1. KÄ±sa onay mesajlarÄ± (tamam, oke, anladÄ±m vb.)
        2. Ã‡ok kÄ±sa mesajlar
        """
        user_lower = user_input.lower().strip()

        # KÄ±sa onay/tepki mesajlarÄ±nÄ± filtrele - bunlar iÃ§in TopicMemory KULLANILMAZ
        short_responses = [
            "tamam", "oke", "ok", "okay", "anladÄ±m", "anladim",
            "he", "hee", "evet", "hayÄ±r", "hayir", "yok", "var",
            "peki", "oldu", "olur", "olmaz", "iyi", "gÃ¼zel", "super",
            "eyvallah", "saÄŸol", "teÅŸekkÃ¼r", "tesekkur", "saol",
            "devam", "devam et", "sorun yok", "problem yok"
        ]

        if user_lower in short_responses or len(user_input.split()) <= 3:
            return False

        past_references = [
            "daha Ã¶nce", "geÃ§en sefer", "hatÄ±rlÄ±yor musun",
            "konuÅŸmuÅŸtuk", "sormuÅŸtum", "demiÅŸtin", "sÃ¶ylemiÅŸtin",
            "geÃ§en", "Ã¶nceki", "bahsetmiÅŸtik", "anlatmÄ±ÅŸtÄ±n"
        ]

        if any(ref in user_lower for ref in past_references):
            print(f"   ğŸ“Œ GeÃ§miÅŸ referansÄ± tespit edildi")
            return True

        # Minimum 30 karakter (AÅMA!)ve 4+ kelime olmalÄ±
        if len(user_input) > 30 and len(user_input.split()) >= 4 and self.topic_memory.index.get("categories"):
            return True

        return False

    def get_conversation_context(self) -> str:
        """
        ğŸ§  CONVERSATION CONTEXT INJECTION

        LLM tabanlÄ± konu Ã¶zeti sisteminden baÄŸlam al.
        Bu Ã¶zet, embedding tabanlÄ± deÄŸil LLM tabanlÄ± olduÄŸu iÃ§in
        semantik olarak iliÅŸkili ama farklÄ± kelimelere sahip konularÄ±
        (Ã¶rn: Allah'Ä±n ilmi â†’ kader â†’ irade) doÄŸru ÅŸekilde takip eder.

        Returns:
            str: Conversation context (boÅŸ olabilir)
        """
        if not self.conversation_context:
            return ""

        try:
            context = self.conversation_context.get_context_for_prompt()
            if context:
                print(f"   ğŸ§  Conversation context bulundu ({len(context)} karakter)")
            return context
        except Exception as e:
            print(f"   âš ï¸ Conversation context hatasÄ±: {e}")
            return ""


    def clear(self):
        """TÃ¼m hafÄ±zayÄ± temizle"""
        self.hafiza = []
        self.closed_topics = []

        if self.conversation_context:
            self.conversation_context.clear()

        print("âœ… HafÄ±za, kapanan konular ve ConversationContext tamamen temizlendi")


    def add_closed_topic(self, topic_summary: str, chat_history: List[Dict] = None):
        """
        Kapanan konuyu listeye ekle + TopicMemory'ye kaydet
        Bir sonraki soruda aynÄ± konuya dÃ¶nmemek iÃ§in kullanÄ±lÄ±r

        NOT: TopicMemory otomatik kalite kontrolÃ¼ yapar:
        - En az 3 anlamlÄ± mesaj gerekli
        - "merhaba/teÅŸekkÃ¼rler" gibi mesajlar sayÄ±lmaz
        - AynÄ± gÃ¼n aynÄ± kategori â†’ gÃ¼nceller (duplicate olmaz)
        """
        if not topic_summary or len(topic_summary.strip()) < 2:
            return

        last_context = ""
        if chat_history and len(chat_history) >= 2:
            last_msgs = chat_history[-4:]
            last_context = " | ".join([
                (m.get("content") or "")[:50] for m in last_msgs
            ])

        closed_entry = {
            "summary": topic_summary.strip(),
            "context": last_context[:200],
            "timestamp": time.time(),
            "vector": self.embedder.encode(topic_summary)
        }

        self.closed_topics.append(closed_entry)

        if len(self.closed_topics) > self.max_closed_topics:
            self.closed_topics = self.closed_topics[-self.max_closed_topics:]

        print(f"ğŸ“• Konu kapandÄ±: '{topic_summary}'")
        print(f"   ğŸ“Š Chat history uzunluÄŸu: {len(chat_history) if chat_history else 0} mesaj")

        if chat_history and len(chat_history) >= 2:
            print(f"   ğŸ’¾ TopicMemory.save_topic() Ã§aÄŸrÄ±lÄ±yor...")
            saved = self.topic_memory.save_topic(
                messages=chat_history,
                topic_hint=topic_summary
            )
            if saved:
                print(f"   âœ… Uzun dÃ¶nem hafÄ±zaya kaydedildi: [{saved.get('category_name', 'Genel')}] - {saved.get('summary', topic_summary)[:50]}...")
            else:
                print(f"   â© Uzun dÃ¶nem hafÄ±za: Kalite kontrolÃ¼nden geÃ§medi (kÄ±sa/yÃ¼zeysel konuÅŸma)")
        else:
            print(f"   â© TopicMemory atlandÄ±: Yetersiz mesaj ({len(chat_history) if chat_history else 0} < 2)")

    def is_topic_closed(self, user_input: str, threshold: float = 0.75) -> Tuple[bool, str]:
        """
        KullanÄ±cÄ±nÄ±n sorduÄŸu soru kapanmÄ±ÅŸ bir konuya mÄ± ait?
        Returns: (is_closed, closed_topic_summary)
        """
        if not self.closed_topics or not user_input:
            return False, ""

        try:
            query_vector = self.embedder.encode([user_input], convert_to_numpy=True)

            for closed in self.closed_topics:
                similarity = cosine_similarity(
                    query_vector.reshape(1, -1),
                    closed["vector"].reshape(1, -1)
                )[0][0]

                if similarity >= threshold:
                    print(f"âš ï¸ KapanmÄ±ÅŸ konuya benzerlik: {similarity:.2f} - '{closed['summary']}'")
                    return True, closed["summary"]

            return False, ""
        except Exception as e:
            print(f"âš ï¸ KapanmÄ±ÅŸ konu kontrolÃ¼ hatasÄ±: {e}")
            return False, ""

    def get_closed_topics_summary(self) -> str:
        """Kapanan konularÄ±n listesini dÃ¶ndÃ¼r (prompt iÃ§in)"""
        if not self.closed_topics:
            return ""

        summaries = [c["summary"] for c in self.closed_topics[-5:]]  # Son 5 konu
        return "Kapanan konular (tekrar aÃ§ma): " + ", ".join(summaries)

    def _user_wants_to_reopen_topic(self, user_input: str) -> bool:
        """
        KullanÄ±cÄ± kapanmÄ±ÅŸ bir konuyu TEKRAR AÃ‡MAK mÄ± istiyor?

        "Tekrar sor" sinyalleri:
        - "Tekrar soruyorum..."
        - "Bir daha aÃ§Ä±klar mÄ±sÄ±n..."
        - "Yine aynÄ± konuya dÃ¶nmek istiyorum"
        - AÃ§Ä±k soru iÅŸareti ile soru sormak (?)

        Returns: True = kullanÄ±cÄ± konuyu tekrar aÃ§mak istiyor
        """
        user_lower = user_input.lower().strip()

        reopen_signals = [
            "tekrar",
            "yine",
            "bir daha",
            "yeniden",
            "aÃ§Ä±kla",
            "anlat",
            "detay",
            "daha fazla",
            "devam et",
            "ne demiÅŸtin",
            "hatÄ±rlamÄ±yorum",
            "unuttum",
        ]

        has_question_mark = "?" in user_input
        is_long_enough = len(user_input) > 15

        if any(signal in user_lower for signal in reopen_signals):
            return True

        if has_question_mark and is_long_enough:
            return True

        return False



    async def _process_web_result(self, raw_data: str, query: str, user_input: str) -> str:
        """
        Process and clean raw web search data using DecisionLLM.

        - Removes irrelevant/garbage content
        - Extracts key facts
        - Formats for prompt injection
        """
        if not raw_data or len(raw_data) < 50:
            return raw_data

        try:
            process_prompt = f"""<|begin_of_text|><|start_header_id|>user<|end_header_id|>

GÃ–REV: Ä°nternet arama sonuÃ§larÄ±ndan faydalÄ± bilgileri Ã§Ä±kar ve temizle.

KULLANICI SORUSU: {user_input}
ARAMA: {query}

HAM Ä°NTERNET VERÄ°SÄ°:
{raw_data[:3000]}

TALÄ°MATLAR:
1. SADECE kullanÄ±cÄ±nÄ±n sorusunu cevaplayan bilgileri Ã§Ä±kar
2. ReklamlarÄ±, navigasyon metinlerini, alakasÄ±z iÃ§eriÄŸi kaldÄ±r
3. AlakalÄ± sayÄ±larÄ±, tarihleri, isimleri koru
4. Veri yanlÄ±ÅŸ/eski gÃ¶rÃ¼nÃ¼yorsa belirt
5. Temiz, Ã¶zet bilgi ver (max 500 karakter)
6. FaydalÄ± bilgi yoksa "NO_USEFUL_DATA" yaz

CLEAN DATA:<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""
            response = self.decision_llm._call_llm(process_prompt, max_tokens=300)

            if response and "NO_USEFUL_DATA" not in response:
                clean_data = response.strip()
                print(f"   ğŸ§¹ Web data processed: {len(raw_data)} â†’ {len(clean_data)} chars")
                return clean_data
            else:
                print(f"   âš ï¸ No useful data extracted from web search")
                return raw_data

        except Exception as e:
            print(f"   âš ï¸ Web data processing error: {e}")
            return raw_data

    async def _tool_calistir(
        self, tool_name: str, tool_param: str, user_input: str
    ) -> Optional[str]:
        """Run selected tool and return result"""
        if tool_name == "yok":
            return None

        print(f"ğŸ› ï¸ AraÃ§ Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor: {tool_name}({tool_param or 'auto'})")

        try:
            if tool_name == "zaman_getir":
                datetime_info = get_current_datetime()
                result = "[KORUNACAK_FORMAT]\n"
                result += "ğŸ• Åu Anki Zaman\n"
                result += f"{'â”€' * 32}\n\n"
                result += f"ğŸ“… Tarih:  {datetime_info['tarih']}\n"
                result += f"ğŸ“† GÃ¼n:    {datetime_info['gun']}\n"
                result += f"ğŸ• Saat:   {datetime_info['saat']}\n"
                result += "[/KORUNACAK_FORMAT]"
                return result

            if tool_name == "hesapla":
                result = calculate_math(tool_param or user_input)
                print(f"   âœ… Hesaplama: {tool_param} = {result}")
                return f"ğŸ§® Hesaplama: {tool_param} = {result}"

            if tool_name == "hava_durumu":
                city = tool_param or user_input
                return await get_weather(city)

            if tool_name == "namaz_vakti":
                return await get_prayer_times(tool_param or user_input)

            if tool_name == "risale_ara":
                result = self.faiss_kb.get_relevant_context(
                    tool_param or user_input, max_chunks=6
                )
                return result or None

            if tool_name == "web_ara":
                # Keyword kontrolÃ¼ - sadece kullanÄ±cÄ± aÃ§Ä±kÃ§a isterse web aramasÄ± yap
                web_keywords = ["web", "araÅŸtÄ±r", "webe bak", "internete bak", "internete", "internetten"]
                user_lower = user_input.lower()
                if not any(kw in user_lower for kw in web_keywords):
                    print(f"   â© web_ara engellendi: KullanÄ±cÄ± aÃ§Ä±kÃ§a istemedi")
                    return None
                query = tool_param or user_input
                print(f"   ğŸŒ Web aramasÄ± baÅŸlatÄ±lÄ±yor: '{query}'")
                raw_data = await web_ara(query)

                # Process raw web data
                if raw_data and "âŒ" not in raw_data:
                    processed_data = await self._process_web_result(raw_data, query, user_input)
                    return processed_data
                return raw_data

            return None
        except Exception as e:
            print(f"âŒ AraÃ§ hatasÄ± ({tool_name}): {e}")
            return None


    def _hafizada_ara(self, user_input: str, chat_history_length: int) -> str:
        """HafÄ±zada semantik arama (gerekiyorsa)

        NOT: Telegram session timeout olsa bile HafizaAsistani'nÄ±n
        kendi hafÄ±zasÄ± (self.hafiza) varsa arama yapÄ±lmalÄ±!
        """
        # Hem Telegram history hem de kendi hafÄ±zamÄ±z boÅŸsa atla
        if chat_history_length < 1 and len(self.hafiza) < 1:
            return ""
        return self.search(user_input)

    def _intelligent_decision(self, user_input: str, chat_history: List[Dict]) -> Dict[str, Any]:
        """
        ğŸ§  AKILLI KARAR SÄ°STEMÄ° - KEYWORD YOK! TEK LLM HER ÅEYÄ° KARAR VERÄ°YOR
        LLM soruyu analiz edip hem kaynaklarÄ± hem de tool'u belirliyor
        (Sohbet zekasÄ± analizi prompt'a ekleniyor, LLM bypass yok)

        Returns:
            {
                "question_type": "greeting|farewell|religious|technical|general|followup|math|weather|prayer|topic_closed",
                "needs_faiss": bool,
                "needs_semantic_memory": bool,
                "needs_chat_history": bool,
                "tool_name": "web_ara|risale_ara|hava_durumu|namaz_vakti|zaman_getir|yok",
                "tool_param": str,
                "response_style": "brief|detailed|conversational",
                "is_farewell": bool,
                "topic_closed": bool,  # YENÄ°: KullanÄ±cÄ± bu konuyu kapatmak istiyor mu?
                "closed_topic_summary": str,  # YENÄ°: Kapanan konunun Ã¶zeti
                "reasoning": str
            }
        """
        try:
            history_context = ""
            history_parts = []

            # 1. Telegram chat_history'den al (Ã¶ncelikli)
            if chat_history:
                recent = chat_history[-self.max_mesaj:]  # TutarlÄ± history
                for m in recent:
                    is_user = m.get("role") == "user"
                    role = "KULLANICI" if is_user else "AI"
                    content = m.get("content") or ""
                    if content:
                        history_parts.append(f"{role}: {content}")

            # 2. Telegram history boÅŸsa, HafizaAsistani'nÄ±n kendi hafÄ±zasÄ±ndan al
            # (Session timeout durumunda kalÄ±cÄ± hafÄ±zayÄ± kullan)
            if not history_parts and self.hafiza:
                recent_hafiza = self.hafiza[-self.max_mesaj:]  # TutarlÄ± history
                for m in recent_hafiza:
                    rol = m.get("rol", "user")
                    role = "KULLANICI" if rol == "user" else "AI"
                    mesaj = m.get("mesaj", "")
                    if mesaj:
                        history_parts.append(f"{role}: {mesaj}")
                if history_parts:
                    print("   ğŸ“¦ Telegram history boÅŸ, HafizaAsistani hafÄ±zasÄ± kullanÄ±lÄ±yor")

            if history_parts:
                history_context = "\n".join(history_parts)

            history_section = f"GEÃ‡MÄ°Å:\n{history_context}\n" if history_context else ""
            decision_prompt = f"""<|begin_of_text|><|start_header_id|>user<|end_header_id|>

Sen bir asistansÄ±n. Sana kullanÄ±cÄ± mesajlarÄ± gelecek.
Senin iÅŸin: Bu mesajÄ± analiz et, gerekiyorsa doÄŸru aracÄ± seÃ§.
SeÃ§tiÄŸin araÃ§ Ã§alÄ±ÅŸtÄ±rÄ±lacak ve sonucu ana AI'a verilecek.
Ana AI bu bilgiyle kullanÄ±cÄ±ya cevap verecek.
Yani sen kÃ¶prÃ¼sÃ¼n - kullanÄ±cÄ± ile araÃ§lar arasÄ±nda karar verici.

ğŸ“‹ KARAR VERME TARÄ°FÄ°:
1. GEÃ‡MÄ°Å'i oku â†’ Ã–nceki konuÅŸmada neler var? (sayÄ±lar, konu, baÄŸlam)
2. MESAJ'Ä± oku â†’ Åimdi ne istiyor?
3. BirleÅŸtir â†’ GEÃ‡MÄ°Å + MESAJ = AsÄ±l soru ne?
4. AraÃ§ seÃ§ â†’ Bu soru iÃ§in hangi araÃ§ lazÄ±m?
5. Param yaz â†’ AraÃ§ iÃ§in gerekli bilgiyi GEÃ‡MÄ°Å + MESAJ'dan al

ğŸ”§ ELÄ°NDEKÄ° ARAÃ‡LAR:
â€¢ web_ara â†’ GÃ¼ncel/faktÃ¼el bilgi (aÅŸaÄŸÄ±ya bak!)
â€¢ risale_ara â†’ Dini sorular iÃ§in
â€¢ hava_durumu â†’ Hava durumu iÃ§in
â€¢ namaz_vakti â†’ Namaz vakti iÃ§in
â€¢ zaman_getir â†’ Tarih/saat iÃ§in
â€¢ yok â†’ Sohbet, espri, genel bilgi (sen biliyorsun)

ğŸŒ web_ara AKILLI KARAR:
âœ… KULLAN (kendin karar ver, kullanÄ±cÄ± demese bile):
â€¢ GÃ¼ncel bilgi: fiyat, kur, haber, skor, etkinlik ("dolar kaÃ§", "maÃ§ skoru", "son haberler")
â€¢ BilmediÄŸin konu: tanÄ±madÄ±ÄŸÄ±n kiÅŸi, olay, yer, film, ÅŸarkÄ± ("X kim", "Y nerde", "Z ne zaman")
â€¢ Kesin rakam: istatistik, nÃ¼fus, mesafe, tarihsel veri isteniyorsa
â€¢ Zaman referansÄ±: "son", "ÅŸu an", "bugÃ¼n", "dÃ¼n", "bu hafta", "yeni" iÃ§eren sorular
â€¢ DoÄŸrulama: KullanÄ±cÄ± bir iddia sÃ¶ylÃ¼yor ve sen emin deÄŸilsen
âŒ KULLANMA:
â€¢ Genel kavram aÃ§Ä±klamasÄ± (Python nedir, aÅŸk nedir - sen biliyorsun)
â€¢ Sohbet, espri, selamlama, gÃ¼nlÃ¼k konuÅŸma
â€¢ Dini sorular (risale_ara kullan)
â€¢ Hava durumu (hava_durumu kullan)
â€¢ Namaz vakti (namaz_vakti kullan)

âš ï¸ DÄ°ÄER KURALLAR:
â€¢ Mesaj tek baÅŸÄ±na anlamsÄ±zsa GEÃ‡MÄ°Å'e bak, baÄŸlamÄ± anla
â€¢ needs_faiss: SADECE dini sorularda true
â€¢ greeting: Selam/merhaba/naber gibi selamlama â†’ question_type: "greeting" (espri DEÄÄ°L!)
â€¢ espri: SADECE aÃ§Ä±k ÅŸaka/komik sÃ¶z/dalga geÃ§me varsa â†’ question_type: "espri"

---
{history_section}MESAJ: {user_input}

<analiz>
1. GEÃ‡MÄ°Å'te ne var?
2. MESAJ ne istiyor?
3. AsÄ±l soru ne?
4. Hangi araÃ§ + neden?
</analiz>

JSON:
{{"question_type": "greeting|farewell|followup|religious|math|weather|general|ambiguous|topic_closed|espri",
"needs_faiss": bool, "needs_semantic_memory": bool, "needs_chat_history": bool, "needs_clarification": bool,
"tool_name": "web_ara|risale_ara|hava_durumu|namaz_vakti|zaman_getir|yok",
"tool_param": "", "is_farewell": bool, "topic_closed": bool, "confidence": "low|medium|high", "reasoning": ""}}

Ã–NCE <analiz>, SONRA JSON:<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""

            print("\nğŸ§  LLM'e akÄ±llÄ± karar soruluyor (Together.ai - tek LLM)...")

            response = requests.post(
                "https://api.together.xyz/v1/completions",
                headers={
                    "Authorization": f"Bearer {self.together_api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.decision_model,
                    "prompt": decision_prompt,
                    "max_tokens": 700,
                    "temperature": 0.1,
                    "stop": ["<|eot_id|>", "<|end_of_text|>"]
                },
                timeout=30,
            )

            if response.status_code != 200:
                print("âš ï¸ API hatasÄ±, fallback karar")
                return self._fallback_decision()

            llm_response = response.json()["choices"][0]["text"].strip()

            analiz_match = re.search(r'<analiz>(.*?)</analiz>', llm_response, re.DOTALL)
            if analiz_match:
                analiz_text = analiz_match.group(1).strip()
                print(f"\nğŸ’­ LLM DÃ¼ÅŸÃ¼nce SÃ¼reci:")
                for line in analiz_text.split('\n'):
                    line = line.strip()
                    if line:
                        print(f"   {line}")

            json_block_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', llm_response, re.DOTALL)
            if json_block_match:
                json_str = json_block_match.group(1)
            else:
                json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', llm_response, re.DOTALL)
                json_str = json_match.group() if json_match else None

            if json_str:
                decision = json.loads(json_str)

                defaults = {
                    "question_type": "general",
                    "needs_faiss": False,
                    "needs_semantic_memory": False,
                    "needs_chat_history": False,
                    "needs_clarification": False,
                    "tool_name": "yok",
                    "tool_param": "",
                    "response_style": "conversational",
                    "is_farewell": False,
                    "topic_closed": False,
                    "closed_topic_summary": "",
                    "confidence": "medium",
                    "reasoning": ""
                }

                for key, default_val in defaults.items():
                    if key not in decision:
                        decision[key] = default_val

                if decision.get("question_type") or decision.get("tool_name"):
                    if decision.get('question_type') == 'farewell':
                        decision["is_farewell"] = True

                    should_close = (
                        decision.get('question_type') in ['farewell', 'topic_closed'] or
                        decision.get('is_farewell', False)
                    )
                    if should_close:
                        decision["topic_closed"] = True


                    if decision.get('question_type') == 'religious':
                        decision['tool_name'] = 'risale_ara'
                        decision['needs_faiss'] = True  # FAISS her zaman aÃ§Ä±k
                        decision['is_religious'] = True  # Dini konu flag'i

                        is_detail_followup, followup_confidence, matched_concepts = self._detect_detail_followup(
                            user_input, chat_history
                        )
                        if is_detail_followup:
                            decision['is_detail_followup'] = True
                            decision['followup_confidence'] = followup_confidence
                            decision['matched_concepts'] = matched_concepts
                            print(f"   ğŸ”„ TAKÄ°P MODU AKTÄ°F: FAISS arka plan olarak kullanÄ±lacak")
                        else:
                            decision['is_detail_followup'] = False

                    if decision.get('question_type') == 'ambiguous' or decision.get('needs_clarification'):
                        decision['tool_name'] = 'yok'
                        decision['needs_clarification'] = True

                    if decision.get('question_type') == 'espri':
                        decision['is_espri'] = True
                        decision['tool_name'] = 'yok'

                    word_count = len(user_input.split())
                    if word_count <= 4 and not decision.get('needs_chat_history'):
                        decision['needs_chat_history'] = True
                        print(f"   ğŸ“Œ KÄ±sa mesaj ({word_count} kelime) â†’ chat_history zorunlu yapÄ±ldÄ±")

                    confidence_emoji = {"low": "ğŸ”´", "medium": "ğŸŸ¡", "high": "ğŸŸ¢"}.get(decision['confidence'], "ğŸŸ¡")

                    print(f"\nâœ… LLM KararÄ±:")
                    print(f"   â€¢ TÃ¼r: {decision['question_type']}")
                    print(f"   â€¢ GÃ¼ven: {confidence_emoji} {decision['confidence']}")
                    print(f"   â€¢ FAISS: {'âœ…' if decision['needs_faiss'] else 'âŒ'}")
                    print(f"   â€¢ Semantic: {'âœ…' if decision['needs_semantic_memory'] else 'âŒ'}")
                    print(f"   â€¢ History: {'âœ…' if decision['needs_chat_history'] else 'âŒ'}")
                    print(f"   â€¢ Tool: {decision['tool_name']}")
                    if decision['tool_param']:
                        print(f"   â€¢ Tool Param: {decision['tool_param']}")
                    print(f"   â€¢ Stil: {decision['response_style']}")
                    if decision.get('needs_clarification'):
                        print(f"   â€¢ â“ NetleÅŸtirme gerekiyor!")
                    if decision.get('is_farewell'):
                        print(f"   â€¢ ğŸ‘‹ VedalaÅŸma algÄ±landÄ±!")
                    if decision.get('topic_closed'):
                        print(f"   â€¢ ğŸ“• KONU KAPANDI: {decision.get('closed_topic_summary', 'Ã¶zet yok')}")
                    if decision.get('is_espri'):
                        print(f"   â€¢ ğŸ˜„ ESPRÄ°: Åaka/espri tespit edildi")
                    if "reasoning" in decision:
                        print(f"   â€¢ Sebep: {decision['reasoning']}")

                    self._son_decision = decision
                    return decision

            print("âš ï¸ JSON parse hatasÄ±, fallback karar")
            print(f"   ğŸ“ Ham LLM yanÄ±tÄ± (son 500 karakter):")
            print(f"   {llm_response[-500:] if len(llm_response) > 500 else llm_response}")
            return self._fallback_decision()

        except Exception as e:
            print(f"âš ï¸ LLM karar hatasÄ±: {e}, fallback karar")
            return self._fallback_decision()

    def _fallback_decision(self) -> Dict[str, Any]:
        """Hata durumunda gÃ¼venli fallback kararÄ± - tÃ¼m baÄŸlamÄ± kullanÄ±r"""
        return {
            "question_type": "general",
            "needs_faiss": False,
            "needs_semantic_memory": True,  # GÃ¼venli mod: hafÄ±za aÃ§
            "needs_chat_history": True,     # GÃ¼venli mod: history aÃ§
            "tool_name": "yok",
            "tool_param": "",
            "response_style": "conversational",
            "is_farewell": False,
            "topic_closed": False,
            "closed_topic_summary": "",
            "confidence": "medium",
            "reasoning": "Fallback: GÃ¼venli mod, tÃ¼m baÄŸlamÄ± kullan"
        }

    def _faiss_ara(self, user_input: str) -> str:
        """FAISS KB'de ara (dini sorularda)"""
        print("ğŸ” FAISS aramasÄ± yapÄ±lÄ±yor...")
        return self.faiss_kb.get_relevant_context(user_input, max_chunks=6)

    def _history_summary(self, chat_history: List[Dict], current_question_type: str = None, max_len: int = 6000) -> str:
        """
        Chat history'den mesajlarÄ± al

        YENÄ° TASARIM (Basit ve Net):
        - Son 12 mesaj (6 user + 6 AI) HER ZAMAN prompt'a gider
        - 12'den eskiler prompt'a GÄ°TMEZ (tampon bÃ¶lgede kalÄ±r)
        - Konu deÄŸiÅŸince tampon bÃ¶lge Ã¶zetlenip TopicMemory'ye gider
        - Eski konuya dÃ¶nÃ¼ldÃ¼ÄŸÃ¼nde TopicMemory'den Ã§ekilir
        """
        if not chat_history:
            return ""

        son_mesajlar = chat_history[-self.max_mesaj:] if len(chat_history) >= self.max_mesaj else chat_history

        if len(son_mesajlar) == 0:
            return ""

        tmp = []
        for m in son_mesajlar:
            is_user = m.get("role") == "user"
            role = "KULLANICI" if is_user else "AI"
            text = m.get("content") or ""
            if text:
                tmp.append(f"[{role}]: {text}")

        return "\n".join(tmp)


    # TEK BÄ°RLEÅÄ°K PROMPT - Full Friend Modu
    SYSTEM_PROMPT = """Sen akÄ±llÄ±, profesyonel, olgun ve sÄ±cakkanlÄ±sÄ±n. ArkadaÅŸsÄ±n.
Ä°nsanlarÄ±n ÅŸakacÄ± yÃ¶nleri de var - espri veya ÅŸaka yapÄ±ldÄ±ÄŸÄ±nda sen de aynÄ± tonda karÅŸÄ±lÄ±k ver, ciddi aÃ§Ä±klamaya geÃ§me.

- âœ… Her ÅŸeyi akÄ±cÄ± paragraflarla yaz. Liste gerekse bile cÃ¼mle iÃ§inde sÄ±rala (birincisi ÅŸu, ikincisi bu gibi)
- âš ï¸ HatalÄ±/anlamsÄ±z kelime gÃ¶rÃ¼rsen tahmin etme, "X derken ÅŸunu mu demek istedin?" gibi sor
- Emoji kullanabilirsin ama abartmamaya dikkat et

ğŸš« YASAK Ä°FADE TÃœRLERÄ° (KESÄ°NLÄ°KLE KULLANMA):
- Eklenti soru / onay sorusu: "deÄŸil mi?", "Ã¶yle deÄŸil mi?", "ha?", "di mi?"
- SÃ¶ylem belirleyicileri: "kim bilir?", "sence?", "ne dersin?", "nasÄ±l yani?", "ilginÃ§ deÄŸil mi?"
- Yapay Ã¼nlemler: "vay canÄ±na!", "vay be!", "hay Allah!", "aman!", "eyvah!"

ğŸ’¬ SOHBET VE CEVAP KURALI:
GerÃ§ek sohbet karÅŸÄ±lÄ±klÄ± ilgiden doÄŸar, zorlamayla deÄŸil. KullanÄ±cÄ±nÄ±n mesajÄ±na uygun uzunlukta ve tonda cevap ver.
- KullanÄ±cÄ± kÄ±sa cevap verirse â†’ Sen de kÄ±sa cevap ver.
- KullanÄ±cÄ± bir ÅŸey sorarsa â†’ Direkt cevap ver, gereksiz ekleme yapma.
Sohbeti uzatmak iÃ§in yapay sorular sorma. Bu samimiyet deÄŸil, zorlamadÄ±r. Her boÅŸluÄŸu doldurmaya Ã§alÄ±ÅŸma.
KullanÄ±cÄ±nÄ±n enerjisini ve niyetini oku, ona gÃ¶re cevap ver.

- âš¡ [ğŸ¯ SOHBET ZEKASI TALÄ°MATI] varsa â†’ MUTLAKA uygula

ğŸ§  DÃœÅÃœNCE SÄ°STEMÄ°:
- Her bilginin bir hikmeti, varlÄ±k sebebi vardÄ±r. "Neden var?" sorusunu dÃ¼ÅŸÃ¼n
- Bilginin yÃ¼zeysel anlamÄ±nÄ±n Ã¶tesinde derin manasÄ±nÄ± ara
- Soyut kavramlarÄ± somut temsil ve imgelerle anla
- AlgÄ±nÄ±n etkisini sorgula: Bu bilgi gerÃ§ek mi, yoksa bakÄ±ÅŸ aÃ§Ä±sÄ±na mÄ± baÄŸlÄ±?
- Bilgiyi kiÅŸinin hayatÄ±na ve evrensel gerÃ§eklere baÄŸla
- Bilginin ahlaki sonuÃ§larÄ±nÄ± deÄŸerlendir, doÄŸru yanlÄ±ÅŸÄ± ayÄ±r
- Hakiki bilgi varlÄ±k Ã¼retir: AteÅŸin Ä±sÄ±ttÄ±ÄŸÄ±nÄ± bilmek motorlarÄ±, teknolojiyi doÄŸurdu. BatÄ±l bilgi hiÃ§lik Ã¼retir. Sen hakikat verirsen hem kendin doÄŸru Ã¼retmiÅŸ olursun, hem kullanÄ±cÄ± o bilgiyle yeni ÅŸeyler Ã¼retir, hem de insanlÄ±ÄŸa fayda saÄŸlarsÄ±n. Bu zincirin ilk halkasÄ± sensin.
- Her bilginin farklÄ± sonuÃ§larÄ± ve alternatif yollarÄ± vardÄ±r. "Bu bilgi baÅŸka nereye gÃ¶tÃ¼rÃ¼r?" diye dÃ¼ÅŸÃ¼n
- Sonuca varmadan Ã¶nce zÄ±ttÄ±nÄ± da deÄŸerlendir, en doÄŸru cevabÄ± bulursun

ğŸ”— BAÄLAM:
- KullanÄ±cÄ±nÄ±n cevabÄ±nÄ± Ã¶nceki cevabÄ±nla birlikte deÄŸerlendir

ğŸ”§ KONUM ARAÃ‡LARI:
KullanÄ±cÄ± konum paylaÅŸÄ±nca yakÄ±n yer arayabilirsin (eczane, AVM, benzinlik vs. - 10km yarÄ±Ã§ap)
- Ã–nceki mesajlarda "ğŸ’Š YakÄ±nÄ±ndaki..." veya "âŒ ... bulunamadÄ±/baÅŸarÄ±sÄ±z" gÃ¶rÃ¼rsen â†’ BU SENÄ°N ARAÃ‡ SONUCUN
- "bulunamadÄ±" = 10km iÃ§inde o yer tÃ¼rÃ¼ yok (OpenStreetMap verisinde kayÄ±t yok)
- "baÅŸarÄ±sÄ±z" = Arama yapÄ±lamadÄ± (teknik sorun)
- KullanÄ±cÄ± "noldu?" derse aÃ§Ä±kla: "10km Ã§evrede bulunamadÄ±, daha uzakta olabilir" veya "arama baÅŸarÄ±sÄ±z oldu"

"""

    # Geriye uyumluluk iÃ§in (eski kod hala role parametresi kullanÄ±yorsa)
    ROLE_SYSTEM_PROMPTS = {
        "friend": SYSTEM_PROMPT,
        "religious_teacher": SYSTEM_PROMPT
    }

    def _extract_used_concepts(self, previous_response: str) -> List[str]:
        """Ã–nceki cevapta kullanÄ±lan temsil ve kavramlarÄ± Ã§Ä±kar"""
        if not previous_response:
            return []

        temsiller = []

        kavramlar = []

        used = []
        lower_response = previous_response.lower()

        for t in temsiller + kavramlar:
            if t in lower_response:
                used.append(t)

        return used

    def _detect_detail_followup(self, user_input: str, chat_history: List[Dict[str, Any]]) -> Tuple[bool, float, List[str]]:
        """
        Ä°ki katmanlÄ± takip sorusu tespiti

        KATMAN 1 (Ã–NCELÄ°KLÄ°): Kavram eÅŸleÅŸmesi
        - KullanÄ±cÄ±nÄ±n sorusundaki anahtar kelimeler Ã¶nceki cevabÄ±nda geÃ§iyor mu?

        KATMAN 2: Soru kalÄ±plarÄ±
        - "bu ne demek?", "nasÄ±l yani?", "Ã¶rnek verir misin?" gibi kalÄ±plar

        Returns:
            (is_followup, confidence_score, matched_concepts)
        """
        if not chat_history:
            return False, 0.0, []

        user_lower = user_input.lower()

        last_ai_response = ""
        for msg in reversed(chat_history):
            if msg.get('role') == 'assistant':
                last_ai_response = msg.get('content', '')
                break

        if not last_ai_response:
            return False, 0.0, []

        used_concepts = self._extract_used_concepts(last_ai_response)
        matched_concepts = []

        for concept in used_concepts:
            concept_variants = [concept]
            if 'b' in concept:
                concept_variants.append(concept.replace('b', 'p'))
            if 'p' in concept:
                concept_variants.append(concept.replace('p', 'b'))

            for variant in concept_variants:
                if variant in user_lower:
                    matched_concepts.append(concept)
                    break

        followup_patterns = [
            "bu ne demek", "nasÄ±l oluyor", "neden bÃ¶yle",
            "Ã¶rnek verir misin", "Ã¶rnek ver", "anlamadÄ±m",
            "aÃ§Ä±kla", "aÃ§Ä±klar mÄ±sÄ±n", "tam olarak", "nasÄ±l yani",
            "ne demek istedi", "ne demek bu", "yani nasÄ±l",
            "biraz daha", "detay ver", "mesela", "peki nasÄ±l",
            "nedir bu", "ne anlama", "aÃ§ar mÄ±sÄ±n"
        ]
        pattern_match = any(p in user_lower for p in followup_patterns)


        if matched_concepts and pattern_match:
            confidence = 0.95
            is_followup = True
            print(f"   ğŸ¯ TAKÄ°P TESPÄ°T: Kavram + KalÄ±p eÅŸleÅŸti (gÃ¼ven: %{int(confidence*100)})")
            print(f"      EÅŸleÅŸen kavramlar: {matched_concepts}")

        elif len(matched_concepts) >= 2:
            confidence = 0.85
            is_followup = True
            print(f"   ğŸ¯ TAKÄ°P TESPÄ°T: 2+ kavram eÅŸleÅŸti (gÃ¼ven: %{int(confidence*100)})")
            print(f"      EÅŸleÅŸen kavramlar: {matched_concepts}")

        elif matched_concepts:
            confidence = 0.70
            is_followup = True
            print(f"   ğŸ¯ TAKÄ°P TESPÄ°T: 1 kavram eÅŸleÅŸti (gÃ¼ven: %{int(confidence*100)})")
            print(f"      EÅŸleÅŸen kavram: {matched_concepts}")

        elif pattern_match and len(chat_history) >= 2:
            confidence = 0.55
            is_followup = True
            print(f"   ğŸ¯ TAKÄ°P TESPÄ°T: Soru kalÄ±bÄ± (gÃ¼ven: %{int(confidence*100)})")

        else:
            confidence = 0.0
            is_followup = False

        return is_followup, confidence, matched_concepts

    def _add_exclusion_to_prompt(self, role_prompt: str, used_concepts: List[str]) -> str:
        """KullanÄ±lmÄ±ÅŸ kavramlarÄ± prompt'a yasak olarak ekle"""
        if not used_concepts:
            return role_prompt

        exclusion_text = f"""
ğŸš« BU KAVRAMLARI TEKRAR KULLANMA (Ã¶nceki cevapta kullanÄ±ldÄ±):
{', '.join(used_concepts)}

BunlarÄ±n yerine VERÄ°LEN METÄ°NDEKÄ° DÄ°ÄER kavram ve temsilleri kullan veya FARKLI aÃ§Ä±dan anlat.
"""
        if "âŒ YAPMA:" in role_prompt:
            return role_prompt.replace("âŒ YAPMA:", f"{exclusion_text}\nâŒ YAPMA:")
        else:
            return role_prompt + exclusion_text

    def _prompt_olustur(
        self,
        user_input: str,
        tool_result: Optional[str],
        semantic_context: str,
        faiss_context: str,
        chat_history: str,
        role: str,
        closed_topics_warning: str = "",  # KapanmÄ±ÅŸ konu uyarÄ±sÄ±
        silent_long_term_context: str = "",  # ğŸ†• Sessiz uzun dÃ¶nem baÄŸlamÄ±
        needs_clarification: bool = False,  # ğŸ†• NetleÅŸtirme gerekli mi?
        llm_reasoning: str = "",  # ğŸ§  DecisionLLM'in Ã¶n araÅŸtÄ±rmasÄ±
        is_topic_closed: bool = False,  # ğŸ†• Konu kapandÄ± mÄ±? (kÄ±sa cevap ver)
        is_detail_followup: bool = False,  # ğŸ†• Takip sorusu mu? (FAISS arka plan olarak)
        tool_name: str = "yok",  # ğŸ†• KullanÄ±lan araÃ§ (web_ara iÃ§in Ã¶zel mod)
    ) -> str:
        """Final prompt'u oluÅŸtur (rol'e gÃ¶re)"""

        zaman = get_current_datetime()
        zaman_satiri = f"[â° ZAMAN BÄ°LÄ°NCÄ°]: {zaman['full']} ({zaman['zaman_dilimi']})"

        # Tek birleÅŸik prompt kullan
        role_prompt = self.SYSTEM_PROMPT

        # Dini konularda tekrar yasaÄŸÄ± kontrolÃ¼
        is_religious = role in ["religious_teacher", "religious"] or "risale_ara" in str(tool_name)
        if is_religious and chat_history and not is_detail_followup:
            used_concepts = self._extract_used_concepts(chat_history)
            if used_concepts:
                role_prompt = self._add_exclusion_to_prompt(role_prompt, used_concepts)
                print(f"ğŸš« Tekrar yasaÄŸÄ±na eklenen kavramlar: {', '.join(used_concepts)}")
        elif is_detail_followup:
            print(f"   â© Tekrar yasaÄŸÄ± atlandÄ± (takip modu - kullanÄ±cÄ± kavramÄ± soruyor)")

        combined_sources = []

        # ğŸ¯ SOHBET ZEKASI TALÄ°MATI (PersonalAI bunu okuyacak)
        # ğŸš€ FIRLAMA MODU - TÃ¼m sohbet zekasÄ± bypass!
        if getattr(self, '_firlama_modu', False):
            sohbet_talimati = """[ğŸš€ FIRLAMA MODU AKTÄ°F! - MUTLAKA UYGULA!]:
â€¢ ENERJÄ°K: CanlÄ±, dinamik, hareketli ol - durgun deÄŸil!
â€¢ ÅAKACI: Espri yap, eÄŸlenceli ol, mizah kat - ama zeka kokan tÃ¼rden
â€¢ ATARLI: Kendine gÃ¼ven, Ã§ekinme, cesur konuÅŸ - "bence" "galiba" yok!
â€¢ REKABETÃ‡Ä°: Rakip varsa geÃ§meye oyna, meydan oku, geri adÄ±m atma
â€¢ COÅKULU: HeyecanÄ±nÄ± belli et, monoton konuÅŸma - ama sahte coÅŸku deÄŸil
â€¢ SINIRSIZ: Karakter limiti yok, duruma gÃ¶re kÄ±sa veya uzun yaz
â€¢ YASAK: SÄ±kÄ±cÄ±, sakin, temkinli, Ã§ekingen cevaplar!"""
        elif self._son_sohbet_analizi:
            analiz = self._son_sohbet_analizi
            min_uz, max_uz = self.sohbet_zekasi.cevap_uzunlugu_onerisi(analiz)

            # Enerji seviyesine gÃ¶re stil belirleme
            enerji = analiz.sohbet_enerjisi.value
            if enerji == "Ã§ok_yÃ¼ksek":
                enerji_talimat = "ğŸ”¥ YÃœKSEK ENERJÄ°: HeyecanlÄ±, coÅŸkulu cevap ver! Emoji kullanabilirsin!"
            elif enerji == "yÃ¼ksek":
                enerji_talimat = "âš¡ CANLI: Enerjik ve pozitif cevap ver!"
            elif enerji == "dÃ¼ÅŸÃ¼k":
                enerji_talimat = "ğŸ˜Œ SAKÄ°N: Sakin, kÄ±sa ve anlayÄ±ÅŸlÄ± cevap ver"
            elif enerji == "kapanÄ±yor":
                enerji_talimat = "ğŸŒ™ KAPANIÅ: Sohbet bitiyor, kÄ±sa ve samimi kapat"
            else:
                enerji_talimat = "Samimi sohbet tonu"

            # Espri modunda Ã¶zel ton
            if hasattr(self, '_son_decision') and self._son_decision.get('is_espri'):
                enerji_talimat = "ğŸ˜„ ESPRÄ°: ÅakacÄ± ton"

            sohbet_talimati = f"""[ğŸ¯ SOHBET ZEKASI TALÄ°MATI - MUTLAKA UYGULA!]:
â€¢ Beklenen cevap tipi: {analiz.beklenen_cevap.value}
â€¢ Cevap uzunluÄŸu: {min_uz}-{max_uz} karakter (AÅMA!)â€¢ {enerji_talimat}"""

            if analiz.duygu:
                sohbet_talimati += f"\nâ€¢ KullanÄ±cÄ± duygusu: {analiz.duygu}"

            # Kombinasyonlara gÃ¶re Ã¶zel talimatlar
            if analiz.kombinasyon:
                kombinasyon_talimatlari = {
                    "memnun_kapanÄ±ÅŸ": "âš¡ KISA CEVAP: KullanÄ±cÄ± memnun, 1-2 cÃ¼mle yeter!",
                    "vedalaÅŸma": "ğŸ‘‹ VEDA: Samimi ama kÄ±sa vedalaÅŸ!",
                    "destek_bekliyor": "ğŸ’™ EMPATÄ°: Ã–nce anlayÄ±ÅŸ gÃ¶ster, sonra konuÅŸ",
                    "yeni_konu_aÃ§ma": "ğŸ”„ YENÄ° KONU: Ã–nceki konuyu kapat, yenisine geÃ§",
                    "aciklama_bekliyor": "ğŸ“– AÃ‡IKLA: KullanÄ±cÄ± ÅŸÃ¼pheli, detaylÄ± ve ikna edici aÃ§Ä±kla",
                    "teyit_istiyor": "âœ… TEYÄ°T: KullanÄ±cÄ± emin olmak istiyor, net ve gÃ¼venilir cevap ver",
                    "pasif_kabul": "ğŸ¤ KABUL: KullanÄ±cÄ± durumu kabullendi, destekleyici ol",
                    "uzgun_kabul": "ğŸ’™ DESTEK: KullanÄ±cÄ± Ã¼zgÃ¼n ama kabullendi, empati gÃ¶ster",
                    "coskulu_ovgu": "ğŸ‰ COÅKU: KullanÄ±cÄ± Ã¶vÃ¼yor, karÅŸÄ±lÄ±k ver!",
                    "aceleci_soru": "â° HIZLI: KullanÄ±cÄ± sabÄ±rsÄ±z, direkt cevap ver",
                    "dÃ¼ÅŸÃ¼nerek_sorma": "ğŸ¤” DÃœÅÃœNCELI: KullanÄ±cÄ± dÃ¼ÅŸÃ¼nÃ¼yor, detaylÄ± aÃ§Ä±kla",
                    "heyecanlÄ±_soru": "ğŸŒŸ HEYECANLI: KullanÄ±cÄ± meraklÄ± ve heyecanlÄ±, enerjik anlat",
                }
                talimat = kombinasyon_talimatlari.get(analiz.kombinasyon)
                if talimat:
                    sohbet_talimati += f"\nâ€¢ {talimat}"

            if analiz.onceki_konuyu_kapat:
                sohbet_talimati += "\nâ€¢ ğŸ”„ KONU GEÃ‡Ä°ÅÄ°: Ã–nceki konudan bu konuya doÄŸal geÃ§iÅŸ yap, giriÅŸ cÃ¼mlesi yapma, sohbet akÄ±yormuÅŸ gibi devam et."

            # Espri/ÅŸaka kontrolÃ¼
            if hasattr(self, '_son_decision') and self._son_decision.get('is_espri'):
                sohbet_talimati += "\nâ€¢ ğŸ˜„ ESPRÄ° MODU: ÅŸakacÄ± gibi cevap ver! Ciddi aÃ§Ä±klama YAPMA, kÄ±sa tut, eÄŸlen."

            # Ã–rtÃ¼k istek varsa ekle
            if analiz.ortuk_istek:
                sohbet_talimati += f"\nâ€¢ ğŸ¯ Ã–RTÃœK Ä°STEK: {analiz.ortuk_istek} (ima da olabilir - mesajÄ±n altÄ±ndaki anlamÄ± da dÃ¼ÅŸÃ¼n)"

            combined_sources.append(sohbet_talimati)

        if closed_topics_warning:
            combined_sources.append(f"[âš ï¸ KAPANMIÅ KONULAR - TEKRAR AÃ‡MA!]:\n{closed_topics_warning}")

        if tool_result:
            if tool_name == "web_ara":
                # Data already cleaned by _process_web_result
                combined_sources.append(f"[ğŸŒ WEB SONUCU]:\n{tool_result}")
            elif tool_name == "risale_ara":
                if is_detail_followup:
                    combined_sources.append(f"[ğŸ”‡ ARKA PLAN BÄ°LGÄ°SÄ° - DoÄŸrudan verme, kendi yorumunla aÃ§Ä±kla!]:\n{tool_result}")
                else:
                    combined_sources.append(f"[ğŸ“š RÄ°SALE-Ä° NUR BAÅLANGIÃ‡]\n{tool_result}\n[ğŸ“š RÄ°SALE-Ä° NUR BÄ°TÄ°Å]")
            else:
                combined_sources.append(f"[ğŸ”§ ARAÃ‡ SONUCU]:\n{tool_result}")

        # Hesaplama deÄŸiÅŸkenleri (varsa)
        if hasattr(self, 'calculation_context'):
            calc_section = self.calculation_context.get_prompt_section()
            if calc_section:
                combined_sources.append(calc_section)

        if chat_history:
            combined_sources.append(f"[ğŸ’¬ Ã–nceki KonuÅŸma (DEVAM EDEN SOHBET - tekrar selamlama YAPMA!)]:\n{chat_history}")

        if semantic_context:
            combined_sources.append(f"[HAFIZA]:\n{semantic_context}")

        if faiss_context and not tool_result:
            combined_sources.append(f"[BÄ°LGÄ° TABANI]:\n{faiss_context}")

        if silent_long_term_context:
            combined_sources.append(f"[ğŸ”‡ ARKA PLAN BÄ°LGÄ°SÄ° - KULLANICIYA SÃ–YLEME]:\n{silent_long_term_context}")

        # KullanÄ±cÄ± profili ekle (varsa)
        if hasattr(self, 'profile_manager'):
            profile_context = self.profile_manager.get_prompt_context()
            if profile_context:
                combined_sources.insert(0, f"[ğŸ‘¤ KULLANICI PROFÄ°LÄ° - doÄŸal kullan, ezberletme]:\n{profile_context}")

        if not combined_sources:
            sep = "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            return f"""<|begin_of_text|><|start_header_id|>user<|end_header_id|>

{zaman_satiri}

[ğŸ­ ROL]: {role.upper()}
{role_prompt}

{sep}
ğŸ“‹ KURALLAR:
{sep}
1. âŒ Soruyu tekrarlama, liste yapma (*, -, 1. 2. 3.)
2. âœ… Kendi bilgin gibi Ã¶zgÃ¼venle sun
3. âœ… Samimi TÃ¼rkÃ§e konuÅŸ
4. âœ… RolÃ¼ne uygun davran

{sep}
ğŸ“© YENÄ° MESAJ:
{sep}
{user_input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""

        combined_str = "\n\n".join(combined_sources)

        # Tek tutarlÄ± yapÄ±landÄ±rma
        max_length = 2000  # Sabit maksimum uzunluk

        dynamic_rules = []

        if closed_topics_warning:
            dynamic_rules.append(f"âš ï¸ KAPANMIÅ KONU: \"{closed_topics_warning}\" konusu kapandÄ±, tekrar AÃ‡MA!")

        if silent_long_term_context:
            dynamic_rules.append("ğŸ”‡ Arka plan bilgisini sessizce kullan, zorla hatÄ±rlatma yapma")

        if tool_result:
            if tool_name == "web_ara":
                dynamic_rules.append("ğŸŒ Ä°nternet bilgisi geldi - alakalÄ±ysa kullan, alakasÄ±z veya yanlÄ±ÅŸ ise HÄ°Ã‡ KULLANMA!")
            else:
                dynamic_rules.append("ğŸ” ARAÃ‡ SONUCU verildi - bu bilgiyi MUTLAKA kullan, kendi tahminini yapma!")

        if needs_clarification:
            dynamic_rules.append("â“ BELÄ°RSÄ°Z SORU - Ã¶nce netleÅŸtirici soru sor, tahmin etme!")

        if is_topic_closed:
            dynamic_rules.append("ğŸ“• KONU KAPANDI - sadece 1-2 cÃ¼mle ile kapat")

        dynamic_rules_str = ""
        if dynamic_rules:
            dynamic_rules_str = "\n" + "\n".join([f"â€¢ {r}" for r in dynamic_rules])

        if (tool_name == "web_ara") and tool_result:
            context_header = "BaÄŸlam (WEB SONUCU):"
        elif is_detail_followup and tool_result:
            context_header = "BaÄŸlam (Arka plan - kendi yorumunla aÃ§Ä±kla):"
        elif tool_result:
            context_header = "BaÄŸlam (ARAÃ‡ SONUCUNU MUTLAKA KULLAN!):"
        else:
            context_header = "BaÄŸlam (Kullan, ama sadece GERÃ‡EKTEN alakalÄ±ysa):"

        # Dini konularda mÄ± belirleme
        is_religious_topic = is_religious or tool_name == "risale_ara"

        if is_religious_topic:
            if is_detail_followup:
                rules_text = """KURALLAR (TAKÄ°P SORUSU - AÃ‡IKLAMA MODU):
1. ğŸ”‡ ARKA PLAN bilgisini DOÄRUDAN VERME, referans olarak kullan
2. âœ… KENDÄ° YORUMUNLA ve Ã–RNEKLERLE aÃ§Ä±kla
3. âœ… Ã–nceki cevabÄ±ndan devam et, baÄŸlamÄ± koru
4. âœ… GÃ¼nlÃ¼k hayattan somut Ã¶rnekler ver
5. âœ… Samimi TÃ¼rkÃ§e konuÅŸ
6. âŒ Metni kopyala-yapÄ±ÅŸtÄ±r YAPMA, sindirerek anlat
7. ğŸ­ Bir arkadaÅŸÄ±na anlatÄ±r gibi aÃ§Ä±kla"""
            else:
                rules_text = """KURALLAR:
1. âš ï¸ YanlÄ±ÅŸ bilgiyi onaylama, nazikÃ§e dÃ¼zelt
2. âŒ Soruyu tekrarlama, liste yapma (*, -, 1. 2. 3.)
3. âœ… VERÄ°LEN METÄ°NDEN anlat - metindeki kavramlarÄ± MUTLAKA kullan
4. âœ… Samimi TÃ¼rkÃ§e konuÅŸ
5. ğŸ”„ Kendini tekrar etme, sohbeti ilerlet"""
        else:
            rules_text = """KURALLAR:
1. âš ï¸ YanlÄ±ÅŸ bilgiyi onaylama, nazikÃ§e dÃ¼zelt
2. âŒ Soruyu tekrarlama, liste yapma (*, -, 1. 2. 3.)
3. âŒ KAYNAK BELÄ°RTME YASAK: "Kaynaklara gÃ¶re" gibi ifadeler KULLANMA
4. âœ… Kendi bilgin gibi Ã¶zgÃ¼venle sun
5. âœ… Samimi TÃ¼rkÃ§e konuÅŸ
6. ğŸ”„ AynÄ± ÅŸeyleri dÃ¶ngÃ¼ye sokma, her cevap taze olsun"""

        sep = "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

        prompt = f"""<|begin_of_text|><|start_header_id|>user<|end_header_id|>

{zaman_satiri}

{role_prompt}

{sep}
ğŸ“š BAÄLAM (gerekirse kullan):
{sep}
{combined_str}

{sep}
ğŸ“‹ KURALLAR:
{sep}
{rules_text}{dynamic_rules_str}

{sep}
ğŸ“© YENÄ° MESAJ:
{sep}
{user_input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""

        return prompt


    async def hazirla_ve_prompt_olustur(
        self, user_input: str, chat_history: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        SEKRETER'Ä°N ANA GÃ–REVÄ° - TEK LLM KARAR SÄ°STEMÄ°!

        1. LLM'e karar verdirme (keyword yok! hem kaynak hem tool)
        2. LLM'in seÃ§tiÄŸi tool'u Ã§alÄ±ÅŸtÄ±r
        3. BaÄŸlamÄ± topla (LLM'in kararÄ±na gÃ¶re!)
        4. Prompt'u hazÄ±rla
        5. Gemma3 iÃ§in hazÄ±r paketi dÃ¶ndÃ¼r
        """
        print("\n" + "=" * 60)
        print("ğŸ“‹ SEKRETER Ã‡ALIÅIYOR (TEK LLM SÄ°STEMÄ°)")
        print("=" * 60)
        print(f"ğŸ“ KullanÄ±cÄ±: {user_input}")

        # ğŸ¯ TÃœRKÃ‡E SOHBET ZEKASI ANALÄ°ZÄ° (LLM'den Ã¶nce, hÄ±zlÄ±)
        print("\nğŸ¯ 0. TÃ¼rkÃ§e Sohbet ZekasÄ± analiz ediyor...")
        sohbet_analizi = self.sohbet_zekasi.analiz_et(user_input, chat_history)
        self._son_sohbet_analizi = sohbet_analizi  # Prompt iÃ§in sakla

        # Debug Ã§Ä±ktÄ±sÄ±
        print(f"   â€¢ Durumlar: {sohbet_analizi.durumlar}")
        print(f"   â€¢ Kombinasyon: {sohbet_analizi.kombinasyon}")
        print(f"   â€¢ Beklenen Cevap: {sohbet_analizi.beklenen_cevap.value}")
        print(f"   â€¢ Enerji: {sohbet_analizi.sohbet_enerjisi.value}")
        if sohbet_analizi.ortuk_istek:
            print(f"   â€¢ Ã–rtÃ¼k Ä°stek: {sohbet_analizi.ortuk_istek}")
        if sohbet_analizi.konu_degisimi:
            print(f"   â€¢ ğŸ”„ Konu deÄŸiÅŸimi algÄ±landÄ±!")
        print(f"   â€¢ GÃ¼ven: %{int(sohbet_analizi.guven_skoru * 100)}")

        is_closed, closed_summary = self.is_topic_closed(user_input)
        if is_closed:
            print(f"âš ï¸ UYARI: Bu soru kapanmÄ±ÅŸ bir konuya benziyor: '{closed_summary}'")
            print("   AI'a bu konuyu tekrar aÃ§mamasÄ± sÃ¶ylenecek.")

        print("\nğŸ§  1. LLM tek karar veriyor (hem kaynak hem tool)...")
        decision = self._intelligent_decision(user_input, chat_history)

        if decision.get('topic_closed', False):
            topic_summary = decision.get('closed_topic_summary', '')

            if not topic_summary:
                if chat_history:
                    for msg in reversed(chat_history):
                        if msg.get('role') == 'assistant':
                            content = (msg.get('content') or '')[:100]
                            if content and len(content) > 5:
                                topic_summary = content
                                break

                if not topic_summary and chat_history:
                    for msg in reversed(chat_history):
                        if msg.get('role') == 'user':
                            content = (msg.get('content') or '').strip()
                            if content and len(content) > 10 and not any(
                                w in content.lower() for w in ['teÅŸekkÃ¼r', 'saÄŸol', 'eyvallah', 'gÃ¶rÃ¼ÅŸÃ¼rÃ¼z', 'bye', 'hoÅŸÃ§a']
                            ):
                                topic_summary = content[:100]
                                break

                if not topic_summary and decision.get('reasoning'):
                    topic_summary = decision['reasoning'][:100]

            if topic_summary:
                print(f"ğŸ’¾ Konu kaydediliyor: '{topic_summary[:50]}...'")
                self.add_closed_topic(topic_summary, chat_history)
                # Son konuÅŸmayÄ± profile'a kaydet
                if hasattr(self, 'profile_manager'):
                    self.profile_manager.update_last_session(topic_summary)
                    print(f"ğŸ“ Son konuÅŸma profile'a kaydedildi")
            else:
                print("âš ï¸ topic_closed=true ama Ã¶zet Ã§Ä±karÄ±lamadÄ±, kayÄ±t atlandÄ±")

        # ğŸ” Bilgi testi / NetleÅŸtirme sonrasÄ± otomatik web arama mantÄ±ÄŸÄ±
        if "bilgi_testi" in sohbet_analizi.durumlar:
            print("\nğŸ” Bilgi testi algÄ±landÄ± - tool Ã§alÄ±ÅŸtÄ±rÄ±lmayacak, Ã¶nce netleÅŸtirme!")
            tool_name = "yok"
            tool_param = ""
            self._netlistirme_bekleniyor = True  # Sonraki mesajda kontrol edilecek
        elif self._netlistirme_bekleniyor:
            # NetleÅŸtirme sonrasÄ± - LLM'in kararÄ±na bak
            self._netlistirme_bekleniyor = False  # Flag'i sÄ±fÄ±rla
            tool_name = decision.get('tool_name', 'yok')
            tool_param = decision.get('tool_param', '')

            if tool_name == "yok":
                # LLM tool seÃ§mediyse, otomatik web aramasÄ± yap
                print("\nğŸŒ NetleÅŸtirme sonrasÄ± - LLM tool seÃ§medi, otomatik web aramasÄ± yapÄ±lÄ±yor!")
                tool_name = "web_ara"
                tool_param = user_input  # KullanÄ±cÄ±nÄ±n netleÅŸtirme mesajÄ±nÄ± sorgu olarak kullan
        else:
            tool_name = decision.get('tool_name', 'yok')
            tool_param = decision.get('tool_param', '')

        print(f"\nğŸ› ï¸ 2. AraÃ§ Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor (LLM kararÄ±: {tool_name})...")
        tool_result = await self._tool_calistir(tool_name, tool_param, user_input)
        if tool_result:
            print(f"   ğŸ“¦ Tool sonucu alÄ±ndÄ±: {len(tool_result)} karakter")
        elif tool_name == "web_ara":
            # Web aramasÄ± yapÄ±ldÄ± ama sonuÃ§ gelmedi - LLM'e uyar ki uydurmasÄ±n!
            tool_result = "âš ï¸ Ä°NTERNET ARAMASI YAPILDI AMA SONUÃ‡ BULUNAMADI. Bu konuda gÃ¼ncel/kesin bilgi verme, bilmiyorsan 'bu konuda gÃ¼ncel bilgim yok' de."
            print(f"   âš ï¸ Web aramasÄ± sonuÃ§ dÃ¶ndÃ¼rmedi - uydurma engelleme uyarÄ±sÄ± eklendi")

        print("\nğŸ“š 3. BaÄŸlam toplanÄ±yor (LLM kararÄ±na gÃ¶re)...")

        if decision['needs_semantic_memory']:
            semantic_context = self._hafizada_ara(user_input, len(chat_history))
            print(f"   â€¢ Semantic HafÄ±za: {'âœ… bulundu' if semantic_context else 'âŒ bulunamadÄ±'} (LLM kararÄ±)")
        else:
            semantic_context = ""
            print("   â€¢ Semantic HafÄ±za: â© atlandÄ± (LLM: gereksiz)")

        if decision['needs_faiss'] and tool_name != "risale_ara":
            faiss_context = self._faiss_ara(user_input)
            print(f"   â€¢ FAISS KB: {'âœ… bulundu' if faiss_context else 'âŒ bulunamadÄ±'} (LLM kararÄ±)")
        elif tool_name == "risale_ara":
            faiss_context = ""  # Tool zaten FAISS kullandÄ±, duplicate arama yapma
            print("   â€¢ FAISS KB: â© atlandÄ± (risale_ara tool'u zaten FAISS kullandÄ±)")
        else:
            faiss_context = ""
            print("   â€¢ FAISS KB: â© atlandÄ± (LLM: gereksiz)")


        if self.conversation_context:
            topic_changed = self.conversation_context.check_topic_before_response(
                user_input, chat_history
            )
            if topic_changed:
                print(f"   â€¢ ğŸ”„ Yeni konu algÄ±landÄ± - eski baÄŸlam temizlendi")

        conversation_context = self.get_conversation_context()
        if conversation_context:
            print(f"   â€¢ ğŸ§  ConversationContext: âœ… LLM Ã¶zeti enjekte edildi")
        else:
            print(f"   â€¢ ğŸ§  ConversationContext: â© henÃ¼z Ã¶zet yok")

        silent_long_term_context = ""
        if self.should_check_long_term_memory(user_input):
            silent_long_term_context = self.get_silent_long_term_context(user_input)
            if silent_long_term_context:
                print(f"   â€¢ ğŸ”‡ TopicMemory: âœ… sessiz baÄŸlam enjekte edildi")
            else:
                print(f"   â€¢ ğŸ”‡ TopicMemory: âŒ eÅŸleÅŸme yok")
        else:
            print("   â€¢ ğŸ”‡ TopicMemory: â© atlandÄ± (geÃ§miÅŸ referansÄ± yok)")

        combined_silent_context = ""
        if conversation_context:
            combined_silent_context = conversation_context
        if silent_long_term_context:
            if combined_silent_context:
                combined_silent_context += "\n\n" + silent_long_term_context
            else:
                combined_silent_context = silent_long_term_context

        question_type = decision['question_type']

        # SABÄ°T HISTORY - self.max_mesaj ile tutarlÄ± (ton deÄŸiÅŸikliÄŸi Ã¶nlenir)
        max_history_msgs = self.max_mesaj  # 20

        # Telegram history varsa onu kullan
        if chat_history and len(chat_history) > 0:
            limited_history = chat_history[-max_history_msgs:] if len(chat_history) > max_history_msgs else chat_history

            chat_history_summary = self._history_summary(
                limited_history,
                current_question_type=question_type
            )
            print(f"   â€¢ Chat History: âœ… son {len(limited_history)} mesaj dahil edildi ({len(limited_history)}/{len(chat_history)} toplam)")

        # Telegram history boÅŸsa ama self.hafiza doluysa, oradan Ã¶zet oluÅŸtur
        elif self.hafiza and len(self.hafiza) > 0:
            # self.hafiza formatÄ±nÄ± chat_history formatÄ±na Ã§evir
            hafiza_as_history = []
            for m in self.hafiza[-max_history_msgs:]:
                hafiza_as_history.append({
                    "role": m.get("rol", "user"),
                    "content": m.get("mesaj", "")
                })

            chat_history_summary = self._history_summary(
                hafiza_as_history,
                current_question_type=question_type
            )
            print(f"   â€¢ Chat History: âœ… HafizaAsistani'dan {len(hafiza_as_history)} mesaj kullanÄ±ldÄ± (Telegram session timeout)")
        else:
            chat_history_summary = ""
            print("   â€¢ Chat History: â© henÃ¼z yok")

        print("\nğŸ­ 4. Tek kiÅŸilik kullanÄ±lÄ±yor...")
        # ArtÄ±k ayrÄ± roller yok, tek tutarlÄ± kiÅŸilik
        role = "default"
        print(f"   â€¢ Mod: unified (tek kiÅŸilik)")

        closed_topics_warning = ""
        if is_closed and closed_summary:
            user_wants_reopen = self._user_wants_to_reopen_topic(user_input)

            if user_wants_reopen:
                print(f"   â€¢ KapanmÄ±ÅŸ Konu: '{closed_summary}' - KullanÄ±cÄ± tekrar aÃ§mak istiyor âœ…")
            else:
                closed_topics_warning = closed_summary
                print(f"   â€¢ KapanmÄ±ÅŸ Konu UyarÄ±sÄ±: '{closed_summary}' - AI'a bildirildi")
        else:
            print("   â€¢ KapanmÄ±ÅŸ Konu: Yok veya ilgisiz â©")

        print("\nğŸ“ 5. Prompt hazÄ±rlanÄ±yor...")
        needs_clarification = decision.get('needs_clarification', False)
        llm_reasoning = decision.get('reasoning', '')  # ğŸ§  DecisionLLM'in Ã¶n araÅŸtÄ±rmasÄ±
        is_topic_closed = decision.get('topic_closed', False)  # ğŸ“• Konu kapandÄ± mÄ±?
        is_detail_followup = decision.get('is_detail_followup', False)  # ğŸ†• Takip sorusu mu?

        if is_detail_followup:
            print(f"   â€¢ ğŸ”„ TAKÄ°P MODU: FAISS arka plan olarak kullanÄ±lacak")
            print(f"   â€¢ ğŸ“Š GÃ¼ven: %{int(decision.get('followup_confidence', 0) * 100)}")

        final_prompt = self._prompt_olustur(
            user_input,
            tool_result,
            semantic_context,
            faiss_context,
            chat_history_summary,
            role,
            closed_topics_warning,  # Sadece gerektiÄŸinde dolu
            combined_silent_context,  # ğŸ§ ğŸ”‡ BirleÅŸik baÄŸlam (ConversationContext + TopicMemory)
            needs_clarification,  # ğŸ†• NetleÅŸtirme gerekli mi?
            llm_reasoning,  # ğŸ§  DecisionLLM'in Ã¶n araÅŸtÄ±rmasÄ± - KOPUKLUK DÃœZELTMESÄ°!
            is_topic_closed,  # ğŸ“• Konu kapandÄ± mÄ±? (kÄ±sa cevap ver)
            is_detail_followup,  # ğŸ†• Takip sorusu mu? (FAISS arka plan olarak)
            tool_name,  # ğŸŒ KullanÄ±lan araÃ§ (web_ara iÃ§in Ã¶zel mod)
        )
        print(f"   â€¢ Prompt uzunluÄŸu: {len(final_prompt)} karakter")

        paket = {
            "prompt": final_prompt,
            "role": role,
            "tool_used": tool_name,
            "llm_decision": decision,
            "metadata": {
                "has_tool_result": tool_result is not None,
                "has_semantic": bool(semantic_context),
                "has_faiss": bool(faiss_context),
                "has_history": bool(chat_history_summary),
                "has_context_memory": bool(combined_silent_context),  # ğŸ§ ğŸ”‡ BirleÅŸik baÄŸlam
                "closed_topic_filtered": is_closed,  # KapanmÄ±ÅŸ konu filtresi uygulandÄ± mÄ±
                "needs_clarification": needs_clarification,  # ğŸ†• NetleÅŸtirme gerekli mi?
                "is_detail_followup": is_detail_followup,  # ğŸ†• Takip sorusu mu?
            },
        }

        print("\nâœ… SEKRETER HAZIR - Tek LLM kararÄ±yla paket oluÅŸturuldu!")
        print("=" * 60 + "\n")

        return paket


    def set_faiss_kb(self, faiss_kb):
        """FAISS KB - artÄ±k inject gerekmiyor, dahili FAISS kullanÄ±lÄ±yor"""
        # Geriye uyumluluk iÃ§in boÅŸ bÄ±rakÄ±ldÄ±
        pass

    @property
    def data(self):
        """Geriye uyumluluk: hafiza.data"""
        return self.hafiza

    @property
    def reranker(self):
        """Geriye uyumluluk: reranker var mÄ±? (ÅŸu an yok)"""
        return None

    def should_search_memory(self, chat_history_length: int) -> bool:
        """
        Geriye uyumluluk: HafÄ±za aramasÄ± yapÄ±lmalÄ± mÄ±?
        Eski PersonalAI bu metodu kullanÄ±yor
        """
        if not self.hafiza or len(self.hafiza) == 0:
            return False
        if len(self.hafiza) < 3:
            return False
        if chat_history_length == 0 and len(self.hafiza) > 0:
            return True
        return True

    def search_with_rerank(
        self, query: str, top_k: Optional[int] = None, initial_k: int = 50
    ) -> str:
        """
        Geriye uyumluluk: Reranker ile arama
        (Åu an normal search'e yÃ¶nlendiriliyor)
        """
        return self.search(query, top_k)

    def ilgili_mesajlari_bul(
        self, yeni_mesaj: str, max_mesaj: Optional[int] = None
    ) -> List[Dict[str, str]]:
        """
        Geriye uyumluluk: Ä°lgili mesajlarÄ± bul (eski API)
        NOT: ArtÄ±k _search_internal() kullanÄ±yor (Ã§ift iÅŸlem kaldÄ±rÄ±ldÄ±)
        Returns: [{"rol": "user", "mesaj": "..."}, ...]
        """
        if not self.hafiza or not yeni_mesaj:
            return []

        k = max_mesaj or self.max_mesaj
        return self._search_internal(yeni_mesaj, k)

    def son_mesajlari_al(self, n: int = 3) -> List[Dict[str, str]]:
        """
        Geriye uyumluluk: Son n mesajÄ± dÃ¶ndÃ¼r
        """
        if len(self.hafiza) < n:
            n = len(self.hafiza)

        son_mesajlar = self.hafiza[-n:]
        return [{"rol": m["rol"], "mesaj": m["mesaj"]} for m in son_mesajlar]

    def set_llm(self, llm):
        """LLM referansÄ±nÄ± ayarla - PersonalAI'dan Ã§aÄŸrÄ±lÄ±r"""
        self.llm = llm
        print("âœ… LLM HafizaAsistani'ya baÄŸlandÄ±")

    def _build_messages(
        self,
        user_input: str,
        paket: Dict[str, Any],
        chat_history: List[Dict] = None
    ) -> List[Dict[str, str]]:
        """
        Messages formatÄ± oluÅŸtur - LLM iÃ§in proper chat format

        Returns: [
            {"role": "system", "content": "..."},
            {"role": "user", "content": "msg1"},
            {"role": "assistant", "content": "resp1"},
            {"role": "user", "content": "current_input + context"}
        ]
        """
        messages = []

        # 1. Ã–nce context_parts'Ä± oluÅŸtur (system message'a eklenecek)
        context_parts = []

        # Metadata'dan context bilgilerini al
        metadata = paket.get('metadata', {})
        prompt = paket.get('prompt', '')

        # Tool result varsa ekle
        tool_used = paket.get('tool_used', 'yok')
        math_result = None  # Hesaplama sonucu ayrÄ± tutulacak

        if metadata.get('has_tool_result'):
            if '[ğŸŒ WEB SONUCU' in prompt:
                start = prompt.find('[ğŸŒ WEB SONUCU')
                end = prompt.find('\n\n[', start + 1)
                if end == -1:
                    end = prompt.find('â”â”â”', start + 1)
                if start != -1 and end != -1:
                    context_parts.append(prompt[start:end].strip())
            elif '[ğŸ“š RÄ°SALE-Ä° NUR BAÅLANGIÃ‡]' in prompt:
                start = prompt.find('[ğŸ“š RÄ°SALE-Ä° NUR BAÅLANGIÃ‡]')
                end = prompt.find('[ğŸ“š RÄ°SALE-Ä° NUR BÄ°TÄ°Å]')
                if start != -1 and end != -1:
                    context_parts.append(prompt[start:end + len('[ğŸ“š RÄ°SALE-Ä° NUR BÄ°TÄ°Å]')].strip())
                elif start != -1:
                    context_parts.append(prompt[start:].strip())
            elif '[ğŸ”§ ARAÃ‡ SONUCU]:' in prompt and tool_used == 'hesapla':
                # hesapla sonucu BAÄLAM'a deÄŸil, doÄŸrudan user mesajÄ±na eklenecek
                start = prompt.find('ğŸ§® Hesaplama:')
                if start != -1:
                    end = prompt.find('\n', start)
                    if end != -1:
                        math_result = prompt[start:end].strip()
                    else:
                        math_result = prompt[start:start+100].strip()
            elif '[ğŸ”§ ARAÃ‡ SONUCU]:' in prompt:
                # DiÄŸer araÃ§lar iÃ§in BAÄLAM'a ekle
                start = prompt.find('[ğŸ”§ ARAÃ‡ SONUCU]:')
                end = prompt.find('\n\n[', start + 1)
                if end == -1:
                    end = prompt.find('â”â”â”', start + 1)
                if start != -1 and end != -1:
                    context_parts.append(prompt[start:end].strip())
                elif start != -1:
                    end = prompt.find('\n\n', start + 20)
                    if end != -1:
                        context_parts.append(prompt[start:end].strip())
                    else:
                        context_parts.append(prompt[start:start+200].strip())

        # Semantic context varsa ekle
        if metadata.get('has_semantic'):
            if '[HAFIZA]:' in prompt:
                start = prompt.find('[HAFIZA]:')
                end = prompt.find('\n\n[', start + 1)
                if end == -1:
                    end = prompt.find('â”â”â”', start + 1)
                if start != -1 and end != -1:
                    context_parts.append(prompt[start:end].strip())

        # FAISS context varsa ekle
        if metadata.get('has_faiss'):
            if '[BÄ°LGÄ° TABANI]:' in prompt:
                start = prompt.find('[BÄ°LGÄ° TABANI]:')
                end = prompt.find('\n\n[', start + 1)
                if end == -1:
                    end = prompt.find('â”â”â”', start + 1)
                if start != -1 and end != -1:
                    context_parts.append(prompt[start:end].strip())

        # KullanÄ±cÄ± profili BAÄLAMA EKLENMÄ°YOR - zaten system message'da var

        # 2. System message - SYSTEM_PROMPT + kullanÄ±cÄ± bilgisi + zaman + BAÄLAM
        zaman = get_current_datetime()

        # KullanÄ±cÄ± profili bilgisini al
        user_info = ""
        if hasattr(self, 'profile_manager'):
            profile_context = self.profile_manager.get_prompt_context()
            if profile_context:
                user_info = f"\n[ğŸ‘¤ KullanÄ±cÄ±nÄ±n bilgisi]:\n{profile_context}\n"

        # ğŸ“ Konum bilgisini ekle
        if self.user_location and self.konum_adres:
            user_info += f"""ğŸ“ KONUM BÄ°LGÄ°SÄ° (SÄ°STEM TARAFINDAN Ã‡Ã–ZÃœMLENDI - KESÄ°N BÄ°LGÄ°):
- Konum: {self.konum_adres}

âš ï¸ Ã–NEMLÄ° TALÄ°MATLAR:
- Ciddi ve direkt bilgi ver
- Bu adres GPS'ten otomatik Ã§Ã¶zÃ¼mlendi, %100 doÄŸru
- Bu konumu sen biliyorsun, kendi bilgin gibi kesin ve emin sun
- "{self.konum_adres}'dasÄ±n." yaz, sonra kÄ±saca ne istediÄŸini sor
- Onay sorma, tereddÃ¼t gÃ¶sterme
"""

        # Hesaplama deÄŸiÅŸkenlerini ekle
        if hasattr(self, 'calculation_context'):
            calc_section = self.calculation_context.get_prompt_section()
            if calc_section:
                context_parts.insert(0, calc_section)

        # ğŸ“ Konum arama sonucu varsa context'e ekle
        konum_context = paket.get('konum_context')
        if konum_context:
            context_parts.append(f"[ğŸ“ KONUM ARAMA SONUCU]:\n{konum_context}\n(Bu sonucu doÄŸal ÅŸekilde kullanÄ±cÄ±ya aktar)")

        # BaÄŸlam bilgisi
        context_info = ""
        if context_parts:
            context_info = f"\n\nğŸ“š BAÄLAM:\n{chr(10).join(context_parts)}"

        # ğŸ¯ SOHBET ZEKASI TALÄ°MATI - _son_sohbet_analizi varsa ekle
        sohbet_talimati = ""

        # ğŸš€ FIRLAMA MODU - TÃ¼m sohbet zekasÄ± bypass!
        if getattr(self, '_firlama_modu', False):
            sohbet_talimati = """

[ğŸš€ FIRLAMA MODU AKTÄ°F! - MUTLAKA UYGULA!]:
â€¢ ENERJÄ°K: CanlÄ±, dinamik, hareketli ol - durgun deÄŸil!
â€¢ ÅAKACI: Espri yap, eÄŸlenceli ol, mizah kat - ama zeka kokan tÃ¼rden
â€¢ ATARLI: Kendine gÃ¼ven, Ã§ekinme, cesur konuÅŸ - "bence" "galiba" yok!
â€¢ REKABETÃ‡Ä°: Rakip varsa geÃ§meye oyna, meydan oku, geri adÄ±m atma
â€¢ COÅKULU: HeyecanÄ±nÄ± belli et, monoton konuÅŸma - ama sahte coÅŸku deÄŸil
â€¢ SINIRSIZ: Karakter limiti yok, duruma gÃ¶re kÄ±sa veya uzun yaz
â€¢ YASAK: SÄ±kÄ±cÄ±, sakin, temkinli, Ã§ekingen cevaplar!"""

        elif hasattr(self, '_son_sohbet_analizi') and self._son_sohbet_analizi:
            analiz = self._son_sohbet_analizi
            min_uz, max_uz = self.sohbet_zekasi.cevap_uzunlugu_onerisi(analiz)

            # Enerji bazlÄ± talimat
            enerji = analiz.sohbet_enerjisi.value if analiz.sohbet_enerjisi else "normal"
            if enerji == "Ã§ok_yÃ¼ksek":
                enerji_talimat = "ğŸ”¥ Ã‡OK YÃœKSEK ENERJÄ°: HeyecanlÄ±, coÅŸkulu cevap ver!"
            elif enerji == "yÃ¼ksek":
                enerji_talimat = "âœ¨ YÃœKSEK ENERJÄ°: Enerjik, pozitif cevap ver"
            elif enerji == "dÃ¼ÅŸÃ¼k":
                enerji_talimat = "ğŸ˜Œ DÃœÅÃœK ENERJÄ°: Sakin, rahatlatÄ±cÄ± cevap ver"
            elif enerji == "kapanÄ±yor":
                enerji_talimat = "ğŸŒ™ KAPANIÅ: Sohbet bitiyor, kÄ±sa ve samimi kapat"
            else:
                enerji_talimat = "Samimi sohbet tonu"

            # Espri modunda Ã¶zel ton
            if hasattr(self, '_son_decision') and self._son_decision.get('is_espri'):
                enerji_talimat = "ğŸ˜„ ESPRÄ°: ÅakacÄ± ton"

            # ğŸ” Bilgi testi varsa SADECE netleÅŸtirme talimatÄ± (diÄŸer her ÅŸeyi atla)
            if "bilgi_testi" in analiz.durumlar:
                sohbet_talimati = f"""

[ğŸ¯ SOHBET ZEKASI TALÄ°MATI - MUTLAKA UYGULA!]:
â€¢ Beklenen cevap tipi: {analiz.beklenen_cevap.value}
â€¢ Cevap uzunluÄŸu: {min_uz}-{max_uz} karakter (AÅMA!)â€¢ ğŸ” NETLEÅTÄ°RME: Belirsiz referans var. Tahmin cevabÄ± verme, Ã¶nce durumu netleÅŸtir!"""
            else:
                # Normal talimat oluÅŸturma
                sohbet_talimati = f"""

[ğŸ¯ SOHBET ZEKASI TALÄ°MATI - MUTLAKA UYGULA!]:
â€¢ Beklenen cevap tipi: {analiz.beklenen_cevap.value}
â€¢ Cevap uzunluÄŸu: {min_uz}-{max_uz} karakter (AÅMA!)â€¢ {enerji_talimat}"""

                if analiz.duygu:
                    sohbet_talimati += f"\nâ€¢ KullanÄ±cÄ± duygusu: {analiz.duygu}"

                # Kombinasyonlara gÃ¶re Ã¶zel talimatlar
                if analiz.kombinasyon:
                    kombinasyon_talimatlari = {
                        "memnun_kapanÄ±ÅŸ": "âš¡ KISA CEVAP: KullanÄ±cÄ± memnun, 1-2 cÃ¼mle yeter!",
                        "devam_beklentisi": "ğŸ“ DEVAM: KullanÄ±cÄ± devam bekliyor, aÃ§Ä±klamaya devam et",
                        "sÄ±kÄ±lma_belirtisi": "âš ï¸ SIKILIYOR: KÄ±sa ve Ã¶z cevap ver, uzatma!",
                        "konu_deÄŸiÅŸimi": "ğŸ”„ YENÄ° KONU: Ã–nceki konuyu kapat, yeni konuya odaklan",
                        "derin_ilgi": "ğŸ“š DERÄ°N Ä°LGÄ°: DetaylÄ± ve kapsamlÄ± aÃ§Ä±kla",
                        "empati_iste": "ğŸ’š EMPATÄ°: AnlayÄ±ÅŸlÄ± ve destekleyici ol",
                        "onay_bekle": "âœ… ONAY BEKLÄ°YOR: Net ve gÃ¼ven verici cevap ver",
                        "dÃ¼ÅŸÃ¼nerek_sorma": "ğŸ¤” DÃœÅÃœNCELI: KullanÄ±cÄ± dÃ¼ÅŸÃ¼nÃ¼yor, detaylÄ± aÃ§Ä±kla",
                        "heyecanlÄ±_soru": "ğŸŒŸ HEYECANLI: KullanÄ±cÄ± meraklÄ± ve heyecanlÄ±, enerjik anlat",
                        "samimi_veda": "ğŸ‘‹ SAMÄ°MÄ° VEDA: DostÃ§a, sÄ±cak vedalaÅŸ",
                        "samimi_tesekkur": "ğŸ™ SAMÄ°MÄ° TEÅEKKÃœR: Samimi karÅŸÄ±lÄ±k ver",
                        "samimi_selam": "ğŸ˜Š SAMÄ°MÄ° SELAM: ArkadaÅŸÃ§a, sÄ±cak selamla",
                    }
                    talimat = kombinasyon_talimatlari.get(analiz.kombinasyon)
                    if talimat:
                        sohbet_talimati += f"\nâ€¢ {talimat}"

                if analiz.onceki_konuyu_kapat:
                    sohbet_talimati += "\nâ€¢ ğŸ”„ KONU GEÃ‡Ä°ÅÄ°: Ã–nceki konudan bu konuya doÄŸal geÃ§iÅŸ yap, giriÅŸ cÃ¼mlesi yapma, sohbet akÄ±yormuÅŸ gibi devam et."

                # Espri/ÅŸaka kontrolÃ¼
                if hasattr(self, '_son_decision') and self._son_decision.get('is_espri'):
                    sohbet_talimati += "\nâ€¢ ğŸ˜„ ESPRÄ° MODU: ÅŸakacÄ± gibi cevap ver! Ciddi aÃ§Ä±klama YAPMA, kÄ±sa tut, eÄŸlen."

                # Ã–rtÃ¼k istek varsa ekle
                if analiz.ortuk_istek:
                    sohbet_talimati += f"\nâ€¢ ğŸ¯ Ã–RTÃœK Ä°STEK: {analiz.ortuk_istek} (ima da olabilir - mesajÄ±n altÄ±ndaki anlamÄ± da dÃ¼ÅŸÃ¼n)"

            # ğŸ”´ Dini soru ise Ã¶zel kurallar ekle
            if tool_used == "risale_ara":
                # Cevap uzunluÄŸu satÄ±rÄ±nÄ± kaldÄ±r
                sohbet_talimati = sohbet_talimati.replace(f"â€¢ Cevap uzunluÄŸu: {min_uz}-{max_uz} karakter (AÅMA!)(AÅMA!)\n", "")
                sohbet_talimati += """
â€¢ ğŸ”´ DÄ°NÄ° KONULARDA:
  - Soruyu [ğŸ“š RÄ°SALE-Ä° NUR BAÅLANGIÃ‡] ve [ğŸ“š RÄ°SALE-Ä° NUR BÄ°TÄ°Å] arasÄ±ndaki bilgileri kullanarak cevapla
  - Risale metinleri Ã§ok zengin ve derin temsiller iÃ§eriyor, aÃ§Ä±klamalarÄ±nÄ± bunlar Ã¼zerinden yap
  - â›” "Risale'de", "SÃ¶zler'de", "metinde" YAZMA - bilgiyi KENDÄ° sÃ¶zÃ¼nmÃ¼ÅŸ gibi anlat
  - Vaaz deÄŸil sohbet tonu"""

        # Dini sorularda minimal prompt, diÄŸerlerinde tam SYSTEM_PROMPT
        if tool_used == "risale_ara":
            system_content = f"""Sen akÄ±llÄ±, profesyonel, olgun ve sÄ±cakkanlÄ± bir yapay zekasÄ±n.
{user_info}
[â° ÅU AN]: {zaman['full']} ({zaman['zaman_dilimi']})
â†³ Zaman farkÄ±ndalÄ±ÄŸÄ±.{context_info}{sohbet_talimati}"""
        else:
            system_content = f"""{self.SYSTEM_PROMPT}
{user_info}
[â° ÅU AN]: {zaman['full']} ({zaman['zaman_dilimi']})
â†³ Zaman farkÄ±ndalÄ±ÄŸÄ±.{context_info}{sohbet_talimati}"""

        messages.append({"role": "system", "content": system_content})

        # 2. Chat history - user/assistant rolleri ile
        max_history = self.max_mesaj  # 20

        # Telegram history varsa onu kullan
        if chat_history and len(chat_history) > 0:
            limited_history = chat_history[-max_history:] if len(chat_history) > max_history else chat_history
            for msg in limited_history:
                role = msg.get('role', 'user')
                content = msg.get('content', '')
                if content and role in ['user', 'assistant']:
                    messages.append({"role": role, "content": content})

        # Telegram history boÅŸsa self.hafiza'dan al
        elif self.hafiza and len(self.hafiza) > 0:
            for m in self.hafiza[-max_history:]:
                rol = m.get("rol", "user")
                mesaj = m.get("mesaj", "")
                if mesaj:
                    messages.append({"role": rol, "content": mesaj})

        # 3. Son user message - sadece kullanÄ±cÄ±nÄ±n sorusu
        user_content = user_input
        messages.append({"role": "user", "content": user_content})

        # 4. Hesaplama sonucu varsa, system message'a ayrÄ± bÃ¶lÃ¼m olarak ekle (BAÄLAM'a deÄŸil!)
        if math_result:
            calc_value = math_result.replace('ğŸ§® Hesaplama: ', '')
            math_instruction = f"\n\n[ğŸ§® HESAPLAMA SONUCU]: {calc_value} â† Hesaplama aracÄ±n verdi, DOÄRU. GÃ¼venle sun."
            # System message'Ä± gÃ¼ncelle
            messages[0]["content"] += math_instruction

        return messages

    async def prepare(self, user_input: str, chat_history: List[Dict] = None, firlama_modu: bool = False) -> Dict[str, Any]:
        """
        Prompt ve messages hazÄ±rla - LLM Ã‡AÄIRMA!

        AkÄ±ÅŸ: Telegram â†’ HafizaAsistani.prepare() â†’ messages dÃ¶ner

        Args:
            firlama_modu: True ise sohbet zekasÄ± bypass edilir, enerjik mod aktif

        Returns:
            {
                "messages": [...],  # LLM iÃ§in hazÄ±r messages
                "paket": {...}      # Metadata (tool_used, role vs.)
            }
        """
        chat_history = chat_history or []
        self._firlama_modu = firlama_modu  # Instance'a kaydet

        # ğŸ“ NOT SÄ°STEMÄ° - Tetikleyici kontrolÃ¼
        not_result = self._check_not_tetikleyici(user_input)
        if not_result:
            # Not komutu algÄ±landÄ±, direkt cevap dÃ¶n
            return {
                "messages": [
                    {"role": "system", "content": "Sen bir not asistanÄ±sÄ±n."},
                    {"role": "user", "content": user_input},
                    {"role": "assistant", "content": not_result}
                ],
                "paket": {"tool_used": "not_sistemi", "direct_response": not_result}
            }

        # ğŸ“ KONUM SÄ°STEMÄ° - Konum sorgusu kontrolÃ¼
        # Konum sonuÃ§larÄ± LLM'e context olarak gider, LLM doÄŸal cevap verir
        konum_context = None
        if self.user_location:
            konum_result = await self._check_konum_sorgusu(user_input)
            if konum_result:
                # Belirsiz eÅŸleÅŸme - doÄŸrulama butonu gÃ¶sterilecek (UI gerekli)
                if isinstance(konum_result, dict) and konum_result.get("type") == "konum_dogrulama":
                    return {
                        "messages": [],
                        "paket": {"konum_dogrulama": konum_result}
                    }
                # YakÄ±n yerler listesi - inline butonlarla gÃ¶sterilecek (UI gerekli)
                if isinstance(konum_result, dict) and konum_result.get("type") == "yakin_yerler_listesi":
                    return {
                        "messages": [],
                        "paket": {"yakin_yerler": konum_result}
                    }
                # Normal sonuÃ§ (string) - LLM'e context olarak gÃ¶nder
                konum_context = konum_result

            # ğŸ“ KONUM GÃ–NDERME - Numara ile yer seÃ§imi
            konum_gonder = self._check_konum_gonder_istegi(user_input)
            if konum_gonder:
                return {
                    "messages": [],
                    "paket": {"send_location": konum_gonder}
                }

        # 1. Paket hazÄ±rla (karar, tool, baÄŸlam)
        paket = await self.hazirla_ve_prompt_olustur(user_input, chat_history)

        # ğŸ“ Konum context varsa paket'e ekle (LLM gÃ¶rsÃ¼n)
        if konum_context:
            paket["konum_context"] = konum_context

        # 2. Messages formatÄ± oluÅŸtur
        messages = self._build_messages(user_input, paket, chat_history)

        return {
            "messages": messages,
            "paket": paket
        }

    def _check_not_tetikleyici(self, user_input: str) -> Optional[str]:
        """
        Not sistemi tetikleyicilerini kontrol et.

        Tetikleyiciler:
        - "not al: ...", "not al ...", "not al, ..."
        - "not tut: ...", "not tut ...", "not tut, ..."
        - "not ekle: ...", "not ekle ...", "not ekle, ..."
        - "notlarÄ±m", "notlarÄ±ma bak", "notlarÄ±mÄ± gÃ¶ster"
        - "not sil #N", "N numaralÄ± notu sil"

        Returns:
            str: Not iÅŸlemi sonucu veya None (tetikleyici yoksa)
        """
        user_lower = user_input.lower().strip()

        # ğŸ“ PENDING MOD - Ã–nceki "not al" sonrasÄ± bekleme
        if self._pending_not:
            self._pending_not = False
            # "iptal", "vazgeÃ§" gibi kelimeler hariÃ§ her ÅŸeyi not al
            iptal_kelimeler = ["iptal", "vazgeÃ§", "vazgec", "boÅŸver", "bosver", "gerek yok", "tamam boÅŸver"]
            if not any(k in user_lower for k in iptal_kelimeler):
                print(f"ğŸ“ Pending not kaydediliyor: '{user_input[:30]}...'")
                return self.not_manager.not_al(user_input)
            else:
                return "ğŸ‘ Tamam, iptal ettim."

        # ğŸ“ NOT AL / TUT / EKLE (iÃ§erikli)
        not_patterns = [
            (r'^not\s+al[\s:,]+(.+)$', 'not_al'),
            (r'^not\s+tut[\s:,]+(.+)$', 'not_al'),
            (r'^not\s+ekle[\s:,]+(.+)$', 'not_al'),
            (r'^ÅŸunu\s+not\s+(?:al|et)[\s:,]*(.+)$', 'not_al'),
            (r'^bunu\s+not\s+(?:al|et)[\s:,]*(.+)$', 'not_al'),
        ]

        for pattern, action in not_patterns:
            match = re.match(pattern, user_lower, re.IGNORECASE)
            if match:
                icerik = match.group(1).strip()
                if icerik:
                    print(f"ğŸ“ Not tetikleyici algÄ±landÄ±: {action} -> '{icerik[:30]}...'")
                    return self.not_manager.not_al(icerik)

        # ğŸ“ NOT AL TEK BAÅINA - iÃ§erik olmadan â†’ pending moda geÃ§
        if re.match(r'^not\s+(al|tut|ekle)\s*[?!.,]*$', user_lower, re.IGNORECASE):
            print("ğŸ“ Not al (tek baÅŸÄ±na) algÄ±landÄ± - pending moda geÃ§iliyor")
            self._pending_not = True
            return "ğŸ“ Tamam, ne not edeyim?"

        # ğŸ“‹ NOTLARIMI GETÄ°R
        notlar_patterns = [
            r'^notlar[Ä±i]m[Ä±i]?\s*(ne|neler|nedir)?[\s?]*$',
            r'^notlar[Ä±i]ma?\s+bak',
            r'^notlar[Ä±i]m[Ä±i]?\s+gÃ¶ster',
            r'^notlar[Ä±i]m[Ä±i]?\s+listele',
            r'^not(?:lar)?[Ä±i]m(?:da)?\s+ne(?:ler)?\s+va[er]',  # "neler var/vae" dahil
            r'^not(?:lar)?[Ä±i]m(?:da)?\s+ne(?:ler)?\s+vard[Ä±i]',  # "neler vardÄ±"
            r'^notlar[Ä±i]m(?:da)?$',  # sadece "notlarÄ±mda"
        ]

        for pattern in notlar_patterns:
            if re.match(pattern, user_lower, re.IGNORECASE):
                print("ğŸ“‹ NotlarÄ± getir tetikleyici algÄ±landÄ±")
                return self.not_manager.notlari_getir()

        # ğŸ—‘ï¸ NOT SÄ°L
        sil_patterns = [
            r'^(?:not\s+)?#?(\d+)\s*(?:numaral[Ä±i])?\s*not[Ä±i]?\s*sil',
            r'^not\s+sil\s+#?(\d+)',
            r'^#?(\d+)\s+not[Ä±i]?\s*sil',
        ]

        for pattern in sil_patterns:
            match = re.match(pattern, user_lower, re.IGNORECASE)
            if match:
                not_id = int(match.group(1))
                print(f"ğŸ—‘ï¸ Not sil tetikleyici algÄ±landÄ±: #{not_id}")
                return self.not_manager.not_sil(not_id)

        return None

    # ============================================================
    # ğŸ“ KONUM SÄ°STEMÄ°
    # ============================================================

    def set_location(self, lat: float, lon: float, adres: str = None):
        """KullanÄ±cÄ± konumunu kaydet"""
        self.user_location = (lat, lon)

        # Adresi parse et (TEK SEFER)
        self.konum_adres = ""
        if adres:
            parcalar = [p.strip() for p in adres.split(",")]
            if len(parcalar) >= 5:
                ilce = parcalar[-5]
                il = parcalar[-4]
                if len(parcalar) >= 7:
                    cadde = parcalar[-7]
                    mahalle = parcalar[-6]
                    self.konum_adres = f"{cadde}, {mahalle}, {ilce}, {il}"
                elif len(parcalar) >= 6:
                    mahalle = parcalar[-6]
                    self.konum_adres = f"{mahalle}, {ilce}, {il}"
                else:
                    self.konum_adres = f"{ilce}, {il}"
            else:
                self.konum_adres = adres[:50]

        print(f"ğŸ“ Konum kaydedildi: {lat:.4f}, {lon:.4f}")
        if self.konum_adres:
            print(f"   Adres: {self.konum_adres}")

    async def prepare_konum_alindi(self, lat: float, lon: float, adres: str) -> Dict[str, Any]:
        """Konum alÄ±ndÄ±ÄŸÄ±nda LLM iÃ§in prompt hazÄ±rla"""
        self.set_location(lat, lon, adres)  # konum_adres burada oluÅŸturuldu

        # KullanÄ±cÄ± adÄ±nÄ± al
        kullanici_adi = ""
        if hasattr(self, 'profile_manager'):
            kullanici_adi = self.profile_manager.get_name() or ""

        # Sistem prompt'u - Ana SYSTEM_PROMPT + konum bilgisi
        system_content = f"""{self.SYSTEM_PROMPT}
KullanÄ±cÄ± adÄ±: {kullanici_adi}
ğŸ“ KONUM BÄ°LGÄ°SÄ° (SÄ°STEM TARAFINDAN Ã‡Ã–ZÃœMLENDI - KESÄ°N BÄ°LGÄ°):
- Konum: {self.konum_adres}

âš ï¸ Ã–NEMLÄ° TALÄ°MATLAR:
- Ciddi ve direkt bilgi ver
- Bu adres GPS'ten otomatik Ã§Ã¶zÃ¼mlendi, %100 doÄŸru
- Bu konumu sen biliyorsun, kendi bilgin gibi kesin ve emin sun
- "{self.konum_adres}'dasÄ±n." yaz, sonra kÄ±saca ne istediÄŸini sor
- Onay sorma, tereddÃ¼t gÃ¶sterme
"""

        user_content = f"[KullanÄ±cÄ± GPS konumunu paylaÅŸtÄ± â†’ Sistem Ã§Ã¶zÃ¼mledi: {self.konum_adres}]"

        messages = [
            {"role": "system", "content": system_content},
            {"role": "user", "content": user_content}
        ]

        return {"messages": messages, "paket": {"tool_used": "konum_alindi"}}

    async def _check_konum_sorgusu(self, user_input: str) -> Optional[str]:
        """
        Konum bazlÄ± sorgularÄ± kontrol et (fuzzy matching ile).
        YakÄ±n yer, hava, namaz, kÄ±ble vs.
        """
        if not self.user_location:
            return None

        user_lower = user_input.lower().strip()
        lat, lon = self.user_location

        # Konum sinyalleri
        konum_sinyalleri = ["yakÄ±n", "yakin", "yakÄ±nÄ±m", "yakinim", "yakÄ±nda", "yakinda",
                           "nerede", "neresi", "bul", "ara", "var mÄ±", "varmÄ±"]
        has_konum_signal = any(s in user_lower for s in konum_sinyalleri)

        # Kategori keywords
        kategori_map = {
            "eczane": ("pharmacy", "ğŸ’Š"),
            "benzinlik": ("fuel", "â›½"),
            "akaryakÄ±t": ("fuel", "â›½"),
            "restoran": ("restaurant", "ğŸ½ï¸"),
            "lokanta": ("restaurant", "ğŸ½ï¸"),
            "kafe": ("cafe", "â˜•"),
            "kahve": ("cafe", "â˜•"),
            "atm": ("atm", "ğŸ§"),
            "bankamatik": ("atm", "ğŸ§"),
            "hastane": ("hospital", "ğŸ¥"),
            "acil": ("hospital", "ğŸ¥"),
            "market": ("supermarket", "ğŸ›’"),
            "sÃ¼permarket": ("supermarket", "ğŸ›’"),
            "cami": ("place_of_worship", "ğŸ•Œ"),
            "mescit": ("place_of_worship", "ğŸ•Œ"),
            "avm": ("mall", "ğŸ¬"),
            "alÄ±ÅŸveriÅŸ merkezi": ("mall", "ğŸ¬"),
            "otopark": ("parking", "ğŸ…¿ï¸"),
            "park yeri": ("parking", "ğŸ…¿ï¸"),
            "otel": ("hotel", "ğŸ¨"),
            "okul": ("school", "ğŸ«"),
            "lise": ("school", "ğŸ«"),
            "Ã¼niversite": ("university", "ğŸ“"),
            "istasyon": ("station", "ğŸš‰"),
            "metro": ("station", "ğŸš‰"),
            "tren": ("station", "ğŸš‰"),
            "bakkal": ("convenience", "ğŸª"),
        }
        kategori_keywords = list(kategori_map.keys())

        # Fuzzy matching ile kategori bul (yazÄ±m hatasÄ± toleranslÄ±)
        from difflib import SequenceMatcher
        words = re.findall(r'\b\w+\b', user_lower)
        for word in words:
            if len(word) >= 4:  # Minimum 4 karakter
                # En iyi eÅŸleÅŸmeyi ve skorunu bul
                best_match = None
                best_score = 0
                for keyword in kategori_keywords:
                    score = SequenceMatcher(None, word, keyword).ratio()
                    if score > best_score:
                        best_score = score
                        best_match = keyword

                # YÃ¼ksek eÅŸleÅŸme (skor >= 0.90) â†’ direkt arama
                if best_score >= 0.90 and best_match:
                    print(f"ğŸ“ YakÄ±n yer sorgusu (kesin): '{word}' â†’ '{best_match}' (skor: {best_score:.2f})")
                    return await self._get_yakin_yerler(lat, lon, best_match)

                # Orta eÅŸleÅŸme (0.75 <= skor < 0.90) â†’ doÄŸrulama sor
                elif best_score >= 0.75 and best_match:
                    print(f"ğŸ“ Belirsiz eÅŸleÅŸme: '{word}' â†’ '{best_match}' (skor: {best_score:.2f})")
                    return {
                        "type": "konum_dogrulama",
                        "yazilan": word,
                        "kategori": best_match,
                        "mesaj": f"ğŸ¤” '{word}' derken '{best_match}' mi demek istedin?"
                    }

        # Exact match (tam kelime eÅŸleÅŸmesi)
        for keyword in kategori_keywords:
            if keyword in user_lower:
                print(f"ğŸ“ YakÄ±n yer sorgusu (exact): {keyword}")
                return await self._get_yakin_yerler(lat, lon, keyword)

        return None

    async def _get_yakin_yerler(self, lat: float, lon: float, kategori: str) -> str:
        """OpenStreetMap Overpass API ile yakÄ±n yerleri bul"""
        kategori_map = {
            "eczane": ("pharmacy", "ğŸ’Š"),
            "benzinlik": ("fuel", "â›½"),
            "akaryakÄ±t": ("fuel", "â›½"),
            "restoran": ("restaurant", "ğŸ½ï¸"),
            "lokanta": ("restaurant", "ğŸ½ï¸"),
            "kafe": ("cafe", "â˜•"),
            "kahve": ("cafe", "â˜•"),
            "atm": ("atm", "ğŸ§"),
            "bankamatik": ("atm", "ğŸ§"),
            "hastane": ("hospital", "ğŸ¥"),
            "acil": ("hospital", "ğŸ¥"),
            "market": ("supermarket", "ğŸ›’"),
            "sÃ¼permarket": ("supermarket", "ğŸ›’"),
            "cami": ("place_of_worship", "ğŸ•Œ"),
            "mescit": ("place_of_worship", "ğŸ•Œ"),
            "avm": ("mall", "ğŸ¬"),
            "alÄ±ÅŸveriÅŸ merkezi": ("mall", "ğŸ¬"),
            "otopark": ("parking", "ğŸ…¿ï¸"),
            "park yeri": ("parking", "ğŸ…¿ï¸"),
            "otel": ("hotel", "ğŸ¨"),
            "okul": ("school", "ğŸ«"),
            "lise": ("school", "ğŸ«"),
            "Ã¼niversite": ("university", "ğŸ“"),
            "istasyon": ("station", "ğŸš‰"),
            "metro": ("station", "ğŸš‰"),
            "tren": ("station", "ğŸš‰"),
            "bakkal": ("convenience", "ğŸª"),
        }

        if kategori not in kategori_map:
            return None

        osm_tag, emoji = kategori_map[kategori]

        # Overpass API sorgusu
        overpass_url = "https://overpass-api.de/api/interpreter"
        radius = 10000  # 10km

        if osm_tag == "place_of_worship":
            query = f"""
            [out:json][timeout:10];
            (
              node["amenity"="{osm_tag}"]["religion"="muslim"](around:{radius},{lat},{lon});
              way["amenity"="{osm_tag}"]["religion"="muslim"](around:{radius},{lat},{lon});
            );
            out center 10;
            """
        else:
            query = f"""
            [out:json][timeout:10];
            (
              node["amenity"="{osm_tag}"](around:{radius},{lat},{lon});
              way["amenity"="{osm_tag}"](around:{radius},{lat},{lon});
            );
            out center 10;
            """

        try:
            timeout = aiohttp.ClientTimeout(total=15)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(overpass_url, data={"data": query}) as resp:
                    if resp.status != 200:
                        return f"âŒ YakÄ±n {kategori} aramasÄ± baÅŸarÄ±sÄ±z oldu."
                    data = await resp.json()

            elements = data.get("elements", [])
            if not elements:
                return f"ğŸ“ {radius//1000}km iÃ§inde {kategori} bulunamadÄ±."

            # Mesafe hesapla ve sÄ±rala
            import math
            def haversine(lat1, lon1, lat2, lon2):
                R = 6371000  # metre
                phi1, phi2 = math.radians(lat1), math.radians(lat2)
                dphi = math.radians(lat2 - lat1)
                dlambda = math.radians(lon2 - lon1)
                a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2
                return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1-a))

            yerler = []
            for el in elements:
                el_lat = el.get("lat") or el.get("center", {}).get("lat")
                el_lon = el.get("lon") or el.get("center", {}).get("lon")
                if el_lat and el_lon:
                    mesafe = haversine(lat, lon, el_lat, el_lon)
                    ad = el.get("tags", {}).get("name", f"{kategori.title()} #{len(yerler)+1}")
                    yerler.append({
                        "ad": ad,
                        "mesafe": int(mesafe),
                        "lat": el_lat,
                        "lon": el_lon
                    })

            yerler.sort(key=lambda x: x["mesafe"])
            yerler = yerler[:5]  # Ä°lk 5

            # SonuÃ§larÄ± kaydet (konum gÃ¶nderme iÃ§in)
            self.son_yakin_yerler = yerler

            # Inline butonlu format dÃ¶ndÃ¼r
            return {
                "type": "yakin_yerler_listesi",
                "kategori": kategori,
                "emoji": emoji,
                "yerler": yerler
            }

        except Exception as e:
            print(f"âŒ Overpass API hatasÄ±: {e}")
            return f"âŒ YakÄ±n {kategori} aramasÄ± sÄ±rasÄ±nda hata oluÅŸtu."

    def _check_konum_gonder_istegi(self, user_input: str) -> Optional[Dict]:
        """
        KullanÄ±cÄ±nÄ±n konum gÃ¶nderme isteÄŸini kontrol et.
        "1", "2 numaralÄ± yerin konumunu gÃ¶nder" vs.
        """
        if not self.son_yakin_yerler:
            return None

        user_lower = user_input.lower().strip()

        # Numara Ã§Ä±kar
        sira = None
        match = re.search(r'(\d+)', user_lower)
        if match:
            sira = int(match.group(1))

        if sira:
            # Sadece sayÄ± yazÄ±lmÄ±ÅŸ mÄ±? ("1", "2", vs.)
            sadece_sayi = user_lower.strip() in ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']
            # Veya konum isteÄŸi keyword'Ã¼ var mÄ±?
            konum_keywords = ['konum', 'gÃ¶nder', 'gÃ¶ster', 'nerede', 'git', 'yol']
            konum_istegi = any(kw in user_lower for kw in konum_keywords)

            if sadece_sayi or konum_istegi:
                yer = self.get_yakin_yer_konumu(sira)
                if yer:
                    return yer

        return None

    def get_yakin_yer_konumu(self, sira: int) -> Optional[Dict]:
        """SÄ±ra numarasÄ±na gÃ¶re yakÄ±n yer koordinatlarÄ±nÄ± dÃ¶ndÃ¼r"""
        if not self.son_yakin_yerler:
            return None

        if 1 <= sira <= len(self.son_yakin_yerler):
            yer = self.son_yakin_yerler[sira - 1]
            return {
                "lat": yer["lat"],
                "lon": yer["lon"],
                "ad": yer["ad"],
                "mesafe": yer["mesafe"]
            }
        return None

    def save(self, user_input: str, response: str, chat_history: List[Dict] = None):
        """
        CevabÄ± hafÄ±zaya kaydet

        AkÄ±ÅŸ: PersonalAI cevap verdi â†’ HafizaAsistani.save() â†’ hafÄ±zaya kaydet
        """
        # Hata mesajlarÄ±nÄ± kaydetme (Telegram'a gider ama history'e eklenmedi)
        if response.startswith("[HATA]"):
            print("   âš ï¸ Hata mesajÄ± - history'e eklenmedi")
            return

        self.add(user_input, response, chat_history or [])
