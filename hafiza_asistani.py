from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import time
import requests
import json
import os
import re
import asyncio
import aiohttp
import hashlib
import logging
from typing import List, Optional, Dict, Any, Tuple
from datetime import datetime
from zoneinfo import ZoneInfo
from collections import defaultdict
from web_search import WebSearch
_web_searcher = WebSearch()  # Global instance

logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("requests").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)

from topic_memory import TopicMemory
from conversation_context import ConversationContextManager
from profile_manager import ProfileManager


def get_current_datetime() -> Dict[str, str]:
    """TÃ¼rkiye saati ile ÅŸu anki tarih ve saati getir"""
    try:
        tz = ZoneInfo("Europe/Istanbul")
        now = datetime.now(tz)

        ay_isimleri = {
            1: "Ocak", 2: "Åubat", 3: "Mart", 4: "Nisan",
            5: "MayÄ±s", 6: "Haziran", 7: "Temmuz", 8: "AÄŸustos",
            9: "EylÃ¼l", 10: "Ekim", 11: "KasÄ±m", 12: "AralÄ±k"
        }

        gun_isimleri = {
            0: "Pazartesi", 1: "SalÄ±", 2: "Ã‡arÅŸamba", 3: "PerÅŸembe",
            4: "Cuma", 5: "Cumartesi", 6: "Pazar"
        }

        ay = ay_isimleri[now.month]
        gun = gun_isimleri[now.weekday()]
        saat = now.hour

        if 0 <= saat < 6:
            zaman_dilimi = "gece"
        elif 6 <= saat < 12:
            zaman_dilimi = "sabah"
        elif 12 <= saat < 18:
            zaman_dilimi = "Ã¶ÄŸleden sonra"
        else:
            zaman_dilimi = "akÅŸam"

        cuma_notu = " (Cuma)" if now.weekday() == 4 else ""

        return {
            "tarih": f"{now.day} {ay} {now.year}",
            "gun": gun,
            "saat": now.strftime("%H:%M"),
            "full": f"{now.day} {ay} {now.year} {gun}, Saat: {now.strftime('%H:%M')}",
            "zaman_dilimi": zaman_dilimi + cuma_notu,
            "saat_int": saat,
        }
    except Exception:
        return {
            "tarih": "Bilinmiyor",
            "gun": "Bilinmiyor",
            "saat": "Bilinmiyor",
            "full": "Tarih/saat bilgisi alÄ±namadÄ±",
            "zaman_dilimi": "",
            "saat_int": 12,
        }


def calculate_math(expression: str) -> str:
    """Matematiksel ifadeyi gÃ¼venli ÅŸekilde hesapla"""
    import math

    try:
        safe_expression = expression.strip()

        safe_expression = safe_expression.replace("x", "*")
        safe_expression = safe_expression.replace("X", "*")
        safe_expression = safe_expression.replace("Ã§arpÄ±", "*")
        safe_expression = safe_expression.replace("Ã§arp", "*")
        safe_expression = safe_expression.replace("bÃ¶lÃ¼", "/")
        safe_expression = safe_expression.replace("artÄ±", "+")
        safe_expression = safe_expression.replace("eksi", "-")

        allowed_chars = "0123456789+-*/(). "
        if not all(c in allowed_chars for c in safe_expression):
            return "âŒ GÃ¼venlik: Sadece sayÄ±lar ve matematiksel operatÃ¶rler kullanÄ±labilir."

        safe_dict = {
            "sqrt": math.sqrt,
            "pow": math.pow,
            "abs": abs,
            "round": round,
            "sin": math.sin,
            "cos": math.cos,
            "tan": math.tan,
            "pi": math.pi,
            "e": math.e,
        }

        result = eval(safe_expression, {"__builtins__": {}}, safe_dict)

        if isinstance(result, float):
            if result.is_integer():
                return str(int(result))
            return f"{result:.4f}".rstrip("0").rstrip(".")

        return str(result)

    except ZeroDivisionError:
        return "âŒ Hata: SÄ±fÄ±ra bÃ¶lme yapÄ±lamaz!"
    except Exception:
        return "âŒ Hesaplama hatasÄ±: GeÃ§ersiz matematiksel ifade."


async def web_ara(query: str, context: str = "") -> str:
    """
    Tavily API ile internet aramasÄ±.

    Args:
        query: Arama sorgusu
        context: Opsiyonel baÄŸlam
    """
    try:
        search_query = query
        if context:
            search_query = f"{query} {context}"

        print(f"\nğŸŒ Web aramasÄ±: '{search_query}'")

        result = _web_searcher.quick_answer(search_query)

        if result and "Arama hatasi" not in result and "Sonuc bulunamadi" not in result:
            print(f"   âœ… SonuÃ§ bulundu")
            return result

        return f"âŒ '{query}' iÃ§in bilgi bulunamadÄ±."

    except Exception as e:
        print(f"âŒ Web arama hatasÄ±: {e}")
        return f"âŒ Arama hatasÄ±: {str(e)}"


async def wiki_ara(query: str) -> str:
    """Eski isim - web_ara'ya yÃ¶nlendirir."""
    return await web_ara(query)


async def get_weather(city: str) -> str:
    """Åehir iÃ§in hava durumu bilgisi getir"""
    try:
        city = (
            city.replace("hava durumu", "")
            .replace("hava", "")
            .replace("nasÄ±l", "")
            .strip()
        )

        api_key = os.getenv("OPENWEATHER_API_KEY", "")

        if not api_key:
            return await get_weather_fallback(city)

        url = "http://api.openweathermap.org/data/2.5/weather"
        params = {
            "q": f"{city},TR",
            "appid": api_key,
            "units": "metric",
            "lang": "tr",
        }

        timeout = aiohttp.ClientTimeout(total=5)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url, params=params) as response:
                if response.status != 200:
                    return await get_weather_fallback(city)
                data = await response.json()

        temp = data["main"]["temp"]
        feels_like = data["main"]["feels_like"]
        humidity = data["main"]["humidity"]
        description = data["weather"][0]["description"].capitalize()
        wind_speed = data["wind"]["speed"]

        result = "[KORUNACAK_FORMAT]\n"
        result += f"ğŸŒ¤ï¸ {city.title()} Hava Durumu\n"
        result += f"{'â”€' * 32}\n\n"
        result += f"â˜ï¸ Durum:       {description}\n"
        result += f"ğŸŒ¡ï¸ SÄ±caklÄ±k:    {temp:.1f}Â°C\n"
        result += f"ğŸ¤š Hissedilen:  {feels_like:.1f}Â°C\n"
        result += f"ğŸ’¨ RÃ¼zgar:      {wind_speed:.1f} m/s\n"
        result += f"ğŸ’§ Nem:         {humidity}%\n"
        result += "[/KORUNACAK_FORMAT]"

        return result

    except Exception:
        return await get_weather_fallback(city)


async def get_weather_fallback(city: str) -> str:
    """Fallback: hava durumu - Web search kaldÄ±rÄ±ldÄ±"""
    return f"âŒ {city} iÃ§in hava durumu servisi kullanÄ±lamÄ±yor. Web arama devre dÄ±ÅŸÄ±."


async def get_prayer_times(city: str, specific_prayer: str = None) -> str:
    """Åehir iÃ§in namaz vakitlerini getir (Aladhan API)"""
    try:
        city = (
            city.replace("namaz vakitleri", "")
            .replace("namaz vakti", "")
            .replace("ezan", "")
            .strip()
        )
        city = (
            city.replace("â€™da", "")
            .replace("â€™de", "")
            .replace("â€™Ä±n", "")
            .replace("â€™in", "")
            .strip()
        )

        url = "http://api.aladhan.com/v1/timingsByCity"
        params = {
            "city": city,
            "country": "Turkey",
            "method": 13,
        }

        timeout = aiohttp.ClientTimeout(total=5)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url, params=params) as response:
                if response.status != 200:
                    return f"âŒ {city} ÅŸehri bulunamadÄ±."
                data = await response.json()

        if data.get("code") != 200:
            return f"âŒ {city} iÃ§in namaz vakitleri alÄ±namadÄ±."

        timings = data["data"]["timings"]
        date_info = data["data"]["date"]["gregorian"]

        prayer_names = {
            "Fajr": ("Ä°msak", "ğŸŒ™"),
            "Sunrise": ("GÃ¼neÅŸ", "â˜€ï¸"),
            "Dhuhr": ("Ã–ÄŸle", "ğŸŒ¤ï¸"),
            "Asr": ("Ä°kindi", "ğŸŒ…"),
            "Maghrib": ("AkÅŸam", "ğŸŒ†"),
            "Isha": ("YatsÄ±", "ğŸŒƒ"),
        }

        if specific_prayer:
            specific_prayer = specific_prayer.lower().strip()
            prayer_map = {
                "imsak": "Fajr",
                "gÃ¼neÅŸ": "Sunrise",
                "Ã¶ÄŸle": "Dhuhr",
                "ikindi": "Asr",
                "akÅŸam": "Maghrib",
                "yatsÄ±": "Isha",
            }

            for tr_name, eng_name in prayer_map.items():
                if tr_name in specific_prayer:
                    time_value = timings[eng_name]
                    turkish_name, emoji = prayer_names[eng_name]
                    return f"{emoji} {city.title()} {turkish_name} namazÄ±: {time_value}"

        result = "[KORUNACAK_FORMAT]\n"
        result += f"ğŸ•Œ {city.title()} Namaz Vakitleri\n"
        result += (
            f"ğŸ“… {date_info['day']} {date_info['month']['en']} {date_info['year']}\n"
        )
        result += f"{'â”€' * 32}\n\n"

        for eng_name, (turkish_name, emoji) in prayer_names.items():
            time_value = timings[eng_name]
            padded_name = f"{turkish_name:<8}"
            result += f"{emoji} {padded_name} {time_value}\n"

        result += "[/KORUNACAK_FORMAT]"
        return result.strip()

    except Exception as e:
        return f"âŒ Namaz vakitleri alÄ±namadÄ±: {str(e)}"



_ToolSystem = None

def get_tool_system_class():
    """ToolSystem'i lazy import et (circular import Ã¶nlemi)"""
    global _ToolSystem
    if _ToolSystem is None:
        try:
            from personal_ai import ToolSystem
            _ToolSystem = ToolSystem
        except ImportError:
            class FallbackToolSystem:
                TOOLS = {
                    "risale_ara": {"name": "risale_ara", "description": "Dini sorulara cevap", "parameters": "soru", "when": "Dini konularda", "examples": ["Ä°man nedir?"]},
                    "zaman_getir": {"name": "zaman_getir", "description": "Tarih/saat", "parameters": "yok", "when": "Zaman sorulduÄŸunda", "examples": ["Saat kaÃ§?"]},
                    "hesapla": {"name": "hesapla", "description": "Hesaplama", "parameters": "ifade", "when": "Matematik sorulduÄŸunda", "examples": ["2+2"]},
                    "hava_durumu": {"name": "hava_durumu", "description": "Hava durumu", "parameters": "ÅŸehir", "when": "Hava sorulduÄŸunda", "examples": ["Ä°stanbul hava"]},
                    "namaz_vakti": {"name": "namaz_vakti", "description": "Namaz vakitleri", "parameters": "ÅŸehir", "when": "Namaz vakti sorulduÄŸunda", "examples": ["Ankara namaz"]},
                    "web_ara": {"name": "web_ara", "description": "Ä°nternette bilgi veya haber ara", "parameters": "arama terimi", "when": "BilmediÄŸin konu, gÃ¼ncel haber, kiÅŸi, yer, olay sorulduÄŸunda", "examples": ["Einstein kimdir", "son haberler", "Python nedir"]},
                    "yok": {"name": "yok", "description": "Direkt cevap", "parameters": "yok", "when": "Genel sohbet", "examples": ["Merhaba"]},
                }
                @staticmethod
                def get_tools_prompt() -> str:
                    tools_text = "ARAÃ‡LAR:\n"
                    for name, info in FallbackToolSystem.TOOLS.items():
                        tools_text += f"{name}: {info['description']}\n"
                    return tools_text
                @staticmethod
                def get_tool_calling_prompt(user_input: str) -> str:
                    return f"{FallbackToolSystem.get_tools_prompt()}\nSORU: {user_input}\nARAÃ‡:"
                @staticmethod
                def parse_tool_decision(llm_response: str) -> Tuple[str, str]:
                    tool_name = "yok"
                    tool_param = ""
                    for line in llm_response.split("\n"):
                        if line.startswith("ARAÃ‡:"): tool_name = line.replace("ARAÃ‡:", "").strip().lower()
                        elif line.startswith("PARAMETRE:"): tool_param = line.replace("PARAMETRE:", "").strip()
                    if tool_name not in FallbackToolSystem.TOOLS: tool_name = "yok"
                    if tool_param.lower() == "yok": tool_param = ""
                    return tool_name, tool_param
            _ToolSystem = FallbackToolSystem
    return _ToolSystem


class ToolSystem:
    """
    ToolSystem wrapper - personal_ai.py'daki ToolSystem'e yÃ¶nlendirir

    NOT: AsÄ±l implementasyon personal_ai.py'da (tek kaynak)
    """

    @property
    def TOOLS(self):
        return get_tool_system_class().TOOLS

    @staticmethod
    def get_tools_prompt() -> str:
        return get_tool_system_class().get_tools_prompt()

    @staticmethod
    def get_tool_calling_prompt(user_input: str) -> str:
        return get_tool_system_class().get_tool_calling_prompt(user_input)

    @staticmethod
    def parse_tool_decision(llm_response: str) -> Tuple[str, str]:
        return get_tool_system_class().parse_tool_decision(llm_response)





_ROLES_CACHE = None

def get_roles():
    """ROLES'u personal_ai.py'dan al - artÄ±k tek basit rol"""
    global _ROLES_CACHE
    if _ROLES_CACHE is None:
        try:
            from personal_ai import SystemConfig
            _ROLES_CACHE = SystemConfig.ROLES
        except ImportError:
            # Fallback: tek basit rol
            _ROLES_CACHE = {
                "default": {"keywords": [], "tone": "natural", "response_style": "adaptive"}
            }
    return _ROLES_CACHE


_MultiRoleSystem = None

def get_multi_role_system_class():
    """MultiRoleSystem'i lazy import et - artÄ±k sadeleÅŸtirilmiÅŸ"""
    global _MultiRoleSystem
    if _MultiRoleSystem is None:
        try:
            from personal_ai import MultiRoleSystem as _MRS
            _MultiRoleSystem = _MRS
        except ImportError:
            class FallbackMultiRoleSystem:
                def __init__(self):
                    self.enabled = False  # Devre dÄ±ÅŸÄ±
                @property
                def ROLES(self):
                    return get_roles()
                def detect_role(self, user_input: str) -> str:
                    return "default"  # Her zaman default
            _MultiRoleSystem = FallbackMultiRoleSystem
    return _MultiRoleSystem


class MultiRoleSystem:
    """
    SadeleÅŸtirilmiÅŸ MultiRoleSystem - tek tutarlÄ± kiÅŸilik
    """

    def __init__(self):
        self._impl = get_multi_role_system_class()()

    @property
    def ROLES(self):
        return get_roles()

    def detect_role(self, user_input: str) -> str:
        return "default"  # ArtÄ±k her zaman default dÃ¶ner



class SimpleFAISSKB:
    """
    Basit FAISS KB wrapper
    (GerÃ§ek FAISS KB PersonalAIâ€™dan alÄ±nÄ±r ve buraya inject edilir)
    """

    def __init__(self):
        self.enabled = False
        self.faiss_kb = None

    def set_faiss_kb(self, faiss_kb):
        """GerÃ§ek FAISS KB'yi inject et"""
        self.faiss_kb = faiss_kb
        self.enabled = (
            faiss_kb is not None and hasattr(faiss_kb, "enabled") and faiss_kb.enabled
        )

    def get_relevant_context(self, query: str, max_chunks: int = 6) -> str:
        """FAISS'ten ilgili baÄŸlamÄ± getir"""
        if not self.enabled or not self.faiss_kb:
            return ""
        try:
            return self.faiss_kb.get_relevant_context(query, max_chunks)
        except Exception as e:
            print(f"âŒ FAISS hatasÄ±: {e}")
            return ""



class DecisionLLM:
    """Together.ai API ile akÄ±llÄ± karar verme (Llama 70B)"""

    def __init__(self, api_key: str = None, model: str = "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo"):
        self.api_key = api_key or os.getenv("TOGETHER_API_KEY")
        self.model = model
        self.base_url = "https://api.together.xyz/v1/completions"

        if not self.api_key:
            raise ValueError("âŒ TOGETHER_API_KEY bulunamadÄ±! .env dosyasÄ±nÄ± kontrol edin.")

        if not self._try_connect():
            raise ConnectionError("âŒ Together.ai API'sine baÄŸlanÄ±lamadÄ±!")

        print(f"ğŸ§  DecisionLLM baÅŸlatÄ±ldÄ± (Model: {model}, Together.ai)")

    def _try_connect(self) -> bool:
        """Together.ai API baÄŸlantÄ±sÄ±nÄ± test et"""
        try:
            response = requests.get(
                "https://api.together.xyz/v1/models",
                headers={"Authorization": f"Bearer {self.api_key}"},
                timeout=5
            )
            return response.status_code == 200
        except (requests.RequestException, requests.Timeout) as e:
            print(f"Together API baÄŸlantÄ± hatasÄ±: {e}")
            return False

    def _call_llm(self, prompt: str, max_tokens: int = 100) -> str:
        """Together.ai API'sine prompt gÃ¶nder"""
        try:
            response = requests.post(
                self.base_url,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "max_tokens": max_tokens,
                    "temperature": 0.3,
                    "stop": ["<|eot_id|>", "<|end_of_text|>"]
                },
                timeout=15,
            )

            if response.status_code == 200:
                return response.json()["choices"][0]["text"].strip()
            return ""
        except Exception as e:
            print(f"âŒ DecisionLLM hatasÄ±: {e}")
            return ""

    def extract_topics(self, query: str, max_topics: int = 3) -> List[str]:
        """KonularÄ± akÄ±llÄ±ca Ã§Ä±kar"""
        prompt = f"""<|begin_of_text|><|start_header_id|>user<|end_header_id|>

KullanÄ±cÄ± mesajÄ±: "{query}"

GÃ–REV: ANA KONULARI bul (maksimum {max_topics} adet)

KURALLAR:

- Uzun kelimeler deÄŸil, ANLAMLI konular
- Her satÄ±ra 1 konu
- AlakasÄ±z kelime ekleme

KONULAR:<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""

        response = self._call_llm(prompt, max_tokens=50)

        topics = [
            line.strip().strip("-â€¢*").strip()
            for line in response.split("\n")
            if line.strip() and len(line.strip()) > 3
        ]

        return topics[:max_topics]



class HafizaAsistani:
    """
    ğŸ§  GeliÅŸmiÅŸ HafÄ±za AsistanÄ± v3.0 - GERÃ‡EK SEKRETER

    Ã–ZELLÄ°KLER:
    - Benzerlik tabanlÄ± arama (BGE-M3)
    - Tool System entegrasyonu
    - Web Search
    - FAISS KB eriÅŸimi
    - Multi-Role System
    - AkÄ±llÄ± prompt hazÄ±rlama
    - DecisionLLM ile karar verme
    """

    def __init__(
        self,
        saat_limiti: int = 48,
        esik: float = 0.50,
        max_mesaj: int = 20,
        model_adi: str = "BAAI/bge-m3",
        use_decision_llm: bool = True,
        together_api_key: str = None,
        decision_model: str = "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    ):
        print("=" * 60)
        print("ğŸ§  HafizaAsistani v3.0 - GeniÅŸletilmiÅŸ Sekreter")
        print("=" * 60)

        self.together_api_key = together_api_key or os.getenv("TOGETHER_API_KEY")
        self.decision_model = decision_model

        print("ğŸ“¦ Embedding modeli yÃ¼kleniyor...")
        self.embedder = SentenceTransformer(model_adi)
        print(f"âœ… Model '{model_adi}' yÃ¼klendi!")

        self.hafiza: List[Dict[str, Any]] = []
        self.saat_limiti = saat_limiti * 3600
        self.esik = esik
        self.max_mesaj = max_mesaj

        if not use_decision_llm:
            raise ValueError("âŒ DecisionLLM zorunludur!")

        try:
            self.decision_llm = DecisionLLM(api_key=self.together_api_key, model=decision_model)
            self.use_decision_llm = True
            print("âœ… DecisionLLM aktif!")
        except Exception as e:
            raise RuntimeError(f"DecisionLLM baÅŸlatÄ±lamadÄ±: {e}")

        self.tool_system = ToolSystem()
        print("âœ… Tool System aktif!")

        self.multi_role = MultiRoleSystem()
        print("âœ… Multi-Role System aktif!")

        self.faiss_kb = SimpleFAISSKB()
        print("âœ… FAISS KB wrapper hazÄ±r (inject edilecek)!")

        self.closed_topics: List[Dict[str, Any]] = []
        self.max_closed_topics = 20  # En fazla 20 kapanan konu tut
        print("âœ… Closed Topics Tracker aktif!")

        self.topic_memory = TopicMemory(
            user_id="murat",  # Sabit kullanÄ±cÄ±
            base_dir="user_data",
            together_api_key=self.together_api_key,
            together_model=decision_model,
            embedding_model=model_adi  # AynÄ± embedding modelini kullan
        )
        print("âœ… Topic Memory aktif!")

        self._injected_categories = {}  # {category_id: message_count_when_injected}
        self._message_counter = 0  # Toplam mesaj sayacÄ±
        self._injection_cooldown = 5  # KaÃ§ mesaj sonra tekrar enjekte edilebilir

        self.conversation_context = ConversationContextManager(
            user_id="murat",  # Sabit kullanÄ±cÄ±
            base_dir="user_data",
            together_api_key=self.together_api_key,
            together_model=decision_model,
            archive_to_faiss=False  # Åimdilik dosya bazlÄ± arÅŸivleme
        )
        print("âœ… Conversation Context aktif!")

        # KullanÄ±cÄ± Profili
        self.profile_manager = ProfileManager(
            user_id="murat",  # Sabit kullanÄ±cÄ±
            base_dir="user_data"
        )
        if self.profile_manager.has_profile():
            print(f"âœ… KullanÄ±cÄ± Profili yÃ¼klendi: {self.profile_manager.get_name()}")
        else:
            print("âœ… KullanÄ±cÄ± Profili aktif (henÃ¼z boÅŸ)")

        print("\nâš™ï¸ Sekreter AyarlarÄ±:")
        print(f"   â€¢ Zaman limiti: {saat_limiti} saat")
        print(f"   â€¢ Benzerlik eÅŸiÄŸi: {esik}")
        print(f"   â€¢ Max mesaj: {max_mesaj}")
        print("   â€¢ Tool System: âœ…")
        print("   â€¢ Web Arama (web_ara): âœ…")
        print("   â€¢ Multi-Role: âœ…")
        print("   â€¢ DecisionLLM: âœ…")
        print("   â€¢ Topic Memory (v2.0): âœ…")
        print("=" * 60 + "\n")


    def mesaj_ekle(self, mesaj: str, rol: str = "user"):
        """Yeni mesajÄ± vektÃ¶rleÅŸtirip hafÄ±zaya ekler"""
        vektor = self.embedder.encode(mesaj)
        self.hafiza.append(
            {"rol": rol, "mesaj": mesaj, "zaman": time.time(), "vektor": vektor}
        )
        self._eski_mesajlari_sil()

    def add(self, user_message: str, ai_response: str, chat_history: List[Dict] = None):
        """
        KullanÄ±cÄ± ve AI mesajlarÄ±nÄ± hafÄ±zaya ekler.
        AyrÄ±ca ConversationContext'i de gÃ¼nceller.

        Args:
            user_message: KullanÄ±cÄ± mesajÄ±
            ai_response: AI yanÄ±tÄ±
            chat_history: Opsiyonel sohbet geÃ§miÅŸi (context iÃ§in)
        """
        self.mesaj_ekle(user_message, rol="user")
        self.mesaj_ekle(ai_response, rol="assistant")

        if self.conversation_context and chat_history:
            try:
                result = self.conversation_context.process_message(
                    user_message, ai_response, chat_history
                )
                if result.get("new_session_started"):
                    print("ğŸ”„ Yeni konu tespit edildi, session deÄŸiÅŸtirildi")

                    if len(self.hafiza) > 12:
                        tampon_bolge = self.hafiza[:-12]  # 12'den eski mesajlar
                        if tampon_bolge and self.topic_memory:
                            tampon_text = "\n".join([
                                f"[{m['rol'].upper()}]: {m['mesaj']}"
                                for m in tampon_bolge if m.get('mesaj')
                            ])
                            topic_summary = result.get('current_summary', '') or tampon_text[:200]
                            if topic_summary:
                                print(f"ğŸ’¾ Tampon bÃ¶lge TopicMemory'ye kaydediliyor ({len(tampon_bolge)} mesaj)")
                                self.add_closed_topic(topic_summary, chat_history)

                    if len(self.hafiza) > 4:
                        self.hafiza = self.hafiza[-4:]
                        print("ğŸ§¹ HafÄ±za temizlendi (son 4 mesaj kaldÄ± - baÄŸlam korundu)")
                elif result.get("summary_updated"):
                    print(f"ğŸ“ Konu Ã¶zeti gÃ¼ncellendi: {result.get('current_summary', '')[:50]}...")
            except Exception as e:
                print(f"âš ï¸ ConversationContext gÃ¼ncelleme hatasÄ±: {e}")

    def _eski_mesajlari_sil(self):
        """Belirlenen sÃ¼reyi geÃ§en mesajlarÄ± temizler"""
        simdi = time.time()
        eski_uzunluk = len(self.hafiza)
        self.hafiza = [
            m for m in self.hafiza if (simdi - m["zaman"]) < self.saat_limiti
        ]

        silinen = eski_uzunluk - len(self.hafiza)
        if silinen > 0:
            print(
                f"ğŸ§¹ {silinen} eski mesaj temizlendi ({self.saat_limiti/3600:.0f} saat sÄ±nÄ±rÄ±)"
            )

    def _search_internal(self, query: str, k: int) -> List[Dict[str, str]]:
        """
        Ä°Ã§ semantik arama fonksiyonu (TEK KAYNAK)
        search() ve ilgili_mesajlari_bul() bunu kullanÄ±r
        Returns: [{"rol": "user", "mesaj": "..."}, ...]
        """
        if not self.hafiza or not query:
            return []

        try:
            query_vector = self.embedder.encode([query], convert_to_numpy=True)

            mesaj_skorlari = []
            simdi = time.time()

            for eski_mesaj in self.hafiza:
                benzerlik = cosine_similarity(
                    query_vector.reshape(1, -1),
                    eski_mesaj["vektor"].reshape(1, -1),
                )[0][0]

                zaman_farki = simdi - eski_mesaj["zaman"]
                zaman_agirligi = 1.0 / (1.0 + (zaman_farki / 3600))

                skor = benzerlik * (0.7 + 0.3 * zaman_agirligi)

                if skor > self.esik:
                    mesaj_skorlari.append(
                        {
                            "mesaj": eski_mesaj["mesaj"],
                            "rol": eski_mesaj["rol"],
                            "skor": skor,
                            "entry": eski_mesaj,
                        }
                    )

            mesaj_skorlari.sort(key=lambda x: x["skor"], reverse=True)
            mesaj_skorlari = mesaj_skorlari[:k]
            mesaj_skorlari.sort(key=lambda x: x["entry"]["zaman"])

            return [
                {"rol": m["entry"]["rol"], "mesaj": m["entry"]["mesaj"]}
                for m in mesaj_skorlari
            ]
        except Exception as e:
            print(f"âŒ Arama hatasÄ±: {e}")
            return []

    def search(self, query: str, max_results: Optional[int] = None) -> str:
        """
        HafÄ±zada semantik arama (SADECE kÄ±sa dÃ¶nem - mevcut sohbet)

        NOT: TopicMemory (uzun dÃ¶nem) aramasÄ± ayrÄ± yapÄ±lÄ±yor:
        - get_silent_long_term_context() ile sessiz enjeksiyon
        """
        k = max_results or self.max_mesaj
        ilgili_mesajlar = self._search_internal(query, k)

        if ilgili_mesajlar:
            context_parts = []
            for m in ilgili_mesajlar:
                context_parts.append(f"- {m['rol']}: {m['mesaj']}")
            return "Ä°lgili geÃ§miÅŸ konuÅŸmalar:\n" + "\n".join(context_parts)

        return ""

    def get_silent_long_term_context(self, query: str) -> str:
        """
        ğŸ”‡ SILENT CONTEXT INJECTION (with cooldown)

        TopicMemory'den hÄ±zlÄ± kategori eÅŸleÅŸmesi yap.
        EÅŸleÅŸme varsa, sessizce LLM'e arka plan bilgisi olarak ver.

        COOLDOWN: AynÄ± kategori son 5 mesajda enjekte edildiyse tekrar enjekte etme.
        BÃ¶ylece sohbet akÄ±ÅŸÄ±nda aynÄ± bilgi sÃ¼rekli tekrarlanmaz.

        Bu bilgi:
        - KullanÄ±cÄ±ya gÃ¶sterilMEZ
        - LLM'e system context olarak verilir
        - LLM bu bilgiyi zorla hatÄ±rlatmaz, sadece cevap kalitesi iÃ§in kullanÄ±r

        Returns:
            str: Silent context (boÅŸ olabilir)
        """
        if not self.topic_memory:
            print(f"   ğŸ”‡ TopicMemory yok!")
            return ""

        try:
            self._message_counter += 1

            cat_count = len(self.topic_memory.index.get("categories", {}))
            print(f"   ğŸ”‡ TopicMemory kontrol: {cat_count} kategori mevcut")

            context = self.topic_memory.get_context_for_query(query, max_sessions=2)

            if context:
                import re
                category_match = re.search(r'\[([^\]]+)\]', context)
                if category_match:
                    category_id = category_match.group(1)

                    if category_id in self._injected_categories:
                        last_injection = self._injected_categories[category_id]
                        messages_since = self._message_counter - last_injection

                        if messages_since < self._injection_cooldown:
                            print(f"   ğŸ”‡ TopicMemory: '{category_id}' cooldown'da ({messages_since}/{self._injection_cooldown} mesaj)")
                            return ""  # Cooldown'daysa enjekte etme

                    self._injected_categories[category_id] = self._message_counter
                    print(f"   ğŸ”‡ Silent long-term context bulundu ({len(context)} karakter) - cooldown baÅŸladÄ±")
                    return context
                else:
                    print(f"   ğŸ”‡ Silent long-term context bulundu ({len(context)} karakter)")
                    return context
            else:
                print(f"   ğŸ”‡ TopicMemory: eÅŸleÅŸme yok")
                return ""

        except Exception as e:
            print(f"   âš ï¸ Silent context hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return ""

    def should_check_long_term_memory(self, user_input: str) -> bool:
        """
        Uzun dÃ¶nem hafÄ±za kontrolÃ¼ gerekli mi?

        True dÃ¶ndÃ¼ren durumlar:
        1. KullanÄ±cÄ± geÃ§miÅŸe referans veriyor
        2. Soru mevcut kategori konularÄ±yla alakalÄ± olabilir
        """
        user_lower = user_input.lower()

        past_references = [
            "daha Ã¶nce", "geÃ§en sefer", "hatÄ±rlÄ±yor musun",
            "konuÅŸmuÅŸtuk", "sormuÅŸtum", "demiÅŸtin", "sÃ¶ylemiÅŸtin",
            "geÃ§en", "Ã¶nceki", "bahsetmiÅŸtik", "anlatmÄ±ÅŸtÄ±n"
        ]

        if any(ref in user_lower for ref in past_references):
            print(f"   ğŸ“Œ GeÃ§miÅŸ referansÄ± tespit edildi")
            return True

        if len(user_input) > 15 and self.topic_memory.index.get("categories"):
            return True

        return False

    def get_conversation_context(self) -> str:
        """
        ğŸ§  CONVERSATION CONTEXT INJECTION

        LLM tabanlÄ± konu Ã¶zeti sisteminden baÄŸlam al.
        Bu Ã¶zet, embedding tabanlÄ± deÄŸil LLM tabanlÄ± olduÄŸu iÃ§in
        semantik olarak iliÅŸkili ama farklÄ± kelimelere sahip konularÄ±
        (Ã¶rn: Allah'Ä±n ilmi â†’ kader â†’ irade) doÄŸru ÅŸekilde takip eder.

        Returns:
            str: Conversation context (boÅŸ olabilir)
        """
        if not self.conversation_context:
            return ""

        try:
            context = self.conversation_context.get_context_for_prompt()
            if context:
                print(f"   ğŸ§  Conversation context bulundu ({len(context)} karakter)")
            return context
        except Exception as e:
            print(f"   âš ï¸ Conversation context hatasÄ±: {e}")
            return ""


    def clear(self):
        """TÃ¼m hafÄ±zayÄ± temizle"""
        self.hafiza = []
        self.closed_topics = []

        if self.conversation_context:
            self.conversation_context.clear()

        print("âœ… HafÄ±za, kapanan konular ve ConversationContext tamamen temizlendi")


    def add_closed_topic(self, topic_summary: str, chat_history: List[Dict] = None):
        """
        Kapanan konuyu listeye ekle + TopicMemory'ye kaydet
        Bir sonraki soruda aynÄ± konuya dÃ¶nmemek iÃ§in kullanÄ±lÄ±r

        NOT: TopicMemory otomatik kalite kontrolÃ¼ yapar:
        - En az 3 anlamlÄ± mesaj gerekli
        - "merhaba/teÅŸekkÃ¼rler" gibi mesajlar sayÄ±lmaz
        - AynÄ± gÃ¼n aynÄ± kategori â†’ gÃ¼nceller (duplicate olmaz)
        """
        if not topic_summary or len(topic_summary.strip()) < 2:
            return

        last_context = ""
        if chat_history and len(chat_history) >= 2:
            last_msgs = chat_history[-4:]
            last_context = " | ".join([
                (m.get("content") or "")[:50] for m in last_msgs
            ])

        closed_entry = {
            "summary": topic_summary.strip(),
            "context": last_context[:200],
            "timestamp": time.time(),
            "vector": self.embedder.encode(topic_summary)
        }

        self.closed_topics.append(closed_entry)

        if len(self.closed_topics) > self.max_closed_topics:
            self.closed_topics = self.closed_topics[-self.max_closed_topics:]

        print(f"ğŸ“• Konu kapandÄ±: '{topic_summary}'")
        print(f"   ğŸ“Š Chat history uzunluÄŸu: {len(chat_history) if chat_history else 0} mesaj")

        if chat_history and len(chat_history) >= 2:
            print(f"   ğŸ’¾ TopicMemory.save_topic() Ã§aÄŸrÄ±lÄ±yor...")
            saved = self.topic_memory.save_topic(
                messages=chat_history,
                topic_hint=topic_summary
            )
            if saved:
                print(f"   âœ… Uzun dÃ¶nem hafÄ±zaya kaydedildi: [{saved.get('category_name', 'Genel')}] - {saved.get('summary', topic_summary)[:50]}...")
            else:
                print(f"   â© Uzun dÃ¶nem hafÄ±za: Kalite kontrolÃ¼nden geÃ§medi (kÄ±sa/yÃ¼zeysel konuÅŸma)")
        else:
            print(f"   â© TopicMemory atlandÄ±: Yetersiz mesaj ({len(chat_history) if chat_history else 0} < 2)")

    def is_topic_closed(self, user_input: str, threshold: float = 0.75) -> Tuple[bool, str]:
        """
        KullanÄ±cÄ±nÄ±n sorduÄŸu soru kapanmÄ±ÅŸ bir konuya mÄ± ait?
        Returns: (is_closed, closed_topic_summary)
        """
        if not self.closed_topics or not user_input:
            return False, ""

        try:
            query_vector = self.embedder.encode([user_input], convert_to_numpy=True)

            for closed in self.closed_topics:
                similarity = cosine_similarity(
                    query_vector.reshape(1, -1),
                    closed["vector"].reshape(1, -1)
                )[0][0]

                if similarity >= threshold:
                    print(f"âš ï¸ KapanmÄ±ÅŸ konuya benzerlik: {similarity:.2f} - '{closed['summary']}'")
                    return True, closed["summary"]

            return False, ""
        except Exception as e:
            print(f"âš ï¸ KapanmÄ±ÅŸ konu kontrolÃ¼ hatasÄ±: {e}")
            return False, ""

    def get_closed_topics_summary(self) -> str:
        """Kapanan konularÄ±n listesini dÃ¶ndÃ¼r (prompt iÃ§in)"""
        if not self.closed_topics:
            return ""

        summaries = [c["summary"] for c in self.closed_topics[-5:]]  # Son 5 konu
        return "Kapanan konular (tekrar aÃ§ma): " + ", ".join(summaries)

    def _user_wants_to_reopen_topic(self, user_input: str) -> bool:
        """
        KullanÄ±cÄ± kapanmÄ±ÅŸ bir konuyu TEKRAR AÃ‡MAK mÄ± istiyor?

        "Tekrar sor" sinyalleri:
        - "Tekrar soruyorum..."
        - "Bir daha aÃ§Ä±klar mÄ±sÄ±n..."
        - "Yine aynÄ± konuya dÃ¶nmek istiyorum"
        - AÃ§Ä±k soru iÅŸareti ile soru sormak (?)

        Returns: True = kullanÄ±cÄ± konuyu tekrar aÃ§mak istiyor
        """
        user_lower = user_input.lower().strip()

        reopen_signals = [
            "tekrar",
            "yine",
            "bir daha",
            "yeniden",
            "aÃ§Ä±kla",
            "anlat",
            "detay",
            "daha fazla",
            "devam et",
            "ne demiÅŸtin",
            "hatÄ±rlamÄ±yorum",
            "unuttum",
        ]

        has_question_mark = "?" in user_input
        is_long_enough = len(user_input) > 15

        if any(signal in user_lower for signal in reopen_signals):
            return True

        if has_question_mark and is_long_enough:
            return True

        return False



    async def _tool_calistir(
        self, tool_name: str, tool_param: str, user_input: str
    ) -> Optional[str]:
        """SeÃ§ilen aracÄ± Ã§alÄ±ÅŸtÄ±r ve sonucu dÃ¶ndÃ¼r"""
        if tool_name == "yok":
            return None

        print(f"ğŸ› ï¸ AraÃ§ Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor: {tool_name}({tool_param or 'auto'})")

        try:
            if tool_name == "zaman_getir":
                datetime_info = get_current_datetime()
                result = "[KORUNACAK_FORMAT]\n"
                result += "ğŸ• Åu Anki Zaman\n"
                result += f"{'â”€' * 32}\n\n"
                result += f"ğŸ“… Tarih:  {datetime_info['tarih']}\n"
                result += f"ğŸ“† GÃ¼n:    {datetime_info['gun']}\n"
                result += f"ğŸ• Saat:   {datetime_info['saat']}\n"
                result += "[/KORUNACAK_FORMAT]"
                return result

            if tool_name == "hesapla":
                result = calculate_math(tool_param or user_input)
                return f"ğŸ§® {result}"

            if tool_name == "hava_durumu":
                city = tool_param or user_input
                return await get_weather(city)

            if tool_name == "namaz_vakti":
                return await get_prayer_times(tool_param or user_input)

            if tool_name == "risale_ara":
                result = self.faiss_kb.get_relevant_context(
                    tool_param or user_input, max_chunks=6
                )
                return result or None

            if tool_name == "web_ara" or tool_name == "wiki_ara":
                query = tool_param or user_input
                result = await web_ara(query)
                return result

            return None
        except Exception as e:
            print(f"âŒ AraÃ§ hatasÄ± ({tool_name}): {e}")
            return None


    def _hafizada_ara(self, user_input: str, chat_history_length: int) -> str:
        """HafÄ±zada semantik arama (gerekiyorsa)

        NOT: Telegram session timeout olsa bile HafizaAsistani'nÄ±n
        kendi hafÄ±zasÄ± (self.hafiza) varsa arama yapÄ±lmalÄ±!
        """
        # Hem Telegram history hem de kendi hafÄ±zamÄ±z boÅŸsa atla
        if chat_history_length < 1 and len(self.hafiza) < 1:
            return ""
        return self.search(user_input)

    def _intelligent_decision(self, user_input: str, chat_history: List[Dict]) -> Dict[str, Any]:
        """
        ğŸ§  AKILLI KARAR SÄ°STEMÄ° - KEYWORD YOK! TEK LLM HER ÅEYÄ° KARAR VERÄ°YOR
        LLM soruyu analiz edip hem kaynaklarÄ± hem de tool'u belirliyor

        Returns:
            {
                "question_type": "greeting|farewell|religious|technical|general|followup|math|weather|prayer|topic_closed",
                "needs_faiss": bool,
                "needs_semantic_memory": bool,
                "needs_chat_history": bool,
                "tool_name": "yok|hesapla|zaman_getir|hava_durumu|namaz_vakti|risale_ara|web_ara",
                "tool_param": str,
                "response_style": "brief|detailed|conversational",
                "is_farewell": bool,
                "topic_closed": bool,  # YENÄ°: KullanÄ±cÄ± bu konuyu kapatmak istiyor mu?
                "closed_topic_summary": str,  # YENÄ°: Kapanan konunun Ã¶zeti
                "reasoning": str
            }
        """
        try:
            history_context = ""
            history_parts = []

            # 1. Telegram chat_history'den al (Ã¶ncelikli)
            if chat_history:
                recent = chat_history[-self.max_mesaj:]  # TutarlÄ± history
                for m in recent:
                    is_user = m.get("role") == "user"
                    role = "KULLANICI" if is_user else "AI"
                    content = m.get("content") or ""
                    if content:
                        history_parts.append(f"{role}: {content}")

            # 2. Telegram history boÅŸsa, HafizaAsistani'nÄ±n kendi hafÄ±zasÄ±ndan al
            # (Session timeout durumunda kalÄ±cÄ± hafÄ±zayÄ± kullan)
            if not history_parts and self.hafiza:
                recent_hafiza = self.hafiza[-self.max_mesaj:]  # TutarlÄ± history
                for m in recent_hafiza:
                    rol = m.get("rol", "user")
                    role = "KULLANICI" if rol == "user" else "AI"
                    mesaj = m.get("mesaj", "")
                    if mesaj:
                        history_parts.append(f"{role}: {mesaj}")
                if history_parts:
                    print("   ğŸ“¦ Telegram history boÅŸ, HafizaAsistani hafÄ±zasÄ± kullanÄ±lÄ±yor")

            if history_parts:
                history_context = "\n".join(history_parts)

            history_section = f"GEÃ‡MÄ°Å:\n{history_context}\n" if history_context else ""
            decision_prompt = f"""<|begin_of_text|><|start_header_id|>user<|end_header_id|>

Karar sistemi. Ã–NCE <analiz> YAZ, SONRA JSON VER.

{history_section}MESAJ: {user_input}

<analiz>
1. TÄ°P: Sohbet/bilgi/teknik/dini/matematik/duygusal?
2. GÃœVENÄ°M: %90+ biliyor muyum?
3. KAYNAK: Kendi bilgim mi, tool mu lazÄ±m?
</analiz>

KURALLAR:
â€¢ Selam/merhaba/veda/evet/tamam/anladÄ±m â†’ friend, tool_name="yok"
â€¢ Dini (Allah/iman/namaz/Kuran) â†’ religious_teacher, risale_ara
â€¢ Matematik â†’ hesapla | Saat â†’ zaman_getir | Hava â†’ hava_durumu
â€¢ Belirsiz â†’ needs_clarification=true
â€¢ BilmediÄŸin konu, gÃ¼ncel haber, kiÅŸi/yer/olay â†’ web_ara
â€¢ "araÅŸtÄ±r/gÃ¼ncel bilgi/son haberler/internetten bak" â†’ web_ara (MUTLAKA!)
â€¢ KullanÄ±cÄ± "eski bilgi" derse â†’ web_ara ile TEKRAR ara
â€¢ âš ï¸ GÃœNCEL KONU KURALI: Haber/gÃ¼ncel olay konusunda HER SORU iÃ§in web_ara kullan. "Zaten aradÄ±k" deme, her seferinde gÃ¼ncel bilgi getir!

JSON:
{{"question_type": "greeting|farewell|followup|religious|math|weather|general|ambiguous",
"needs_faiss": bool, "needs_semantic_memory": bool, "needs_chat_history": bool,
"needs_clarification": bool, "tool_name": "yok|hesapla|zaman_getir|hava_durumu|namaz_vakti|risale_ara|web_ara",
"tool_param": "", "is_farewell": bool, "topic_closed": bool, "confidence": "low|medium|high", "reasoning": ""}}

Ã–RNEKLER:
1) "Selam/Merhaba/NasÄ±lsÄ±n" â†’ {{"question_type":"greeting","tool_name":"yok","confidence":"high"}}
2) "Hava durumu nasÄ±l" â†’ {{"question_type":"weather","tool_name":"hava_durumu","confidence":"high"}}
3) "BugÃ¼n hava nasÄ±l" â†’ {{"question_type":"weather","tool_name":"hava_durumu","confidence":"high"}}
4) "Hava kaÃ§ derece" â†’ {{"question_type":"weather","tool_name":"hava_durumu","confidence":"high"}}
5) "Allah'Ä±n kudreti" â†’ {{"question_type":"religious","tool_name":"risale_ara","needs_faiss":true}}
6) "evet ilginÃ§miÅŸ" â†’ {{"question_type":"followup","tool_name":"yok"}}
7) "Python nedir" â†’ {{"question_type":"general","tool_name":"web_ara","tool_param":"Python programlama dili"}}
8) "iyi araÅŸtÄ±r/gÃ¼ncel bilgi istiyorum" â†’ {{"question_type":"general","tool_name":"web_ara","tool_param":"[Ã¶nceki konuyla ilgili arama]"}}
9) "bu eski bilgi, son haberlere bak" â†’ {{"question_type":"general","tool_name":"web_ara","tool_param":"[konu] son haberler 2026"}}

Ã–NCE <analiz>, SONRA JSON:<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""

            print("\nğŸ§  LLM'e akÄ±llÄ± karar soruluyor (Together.ai - tek LLM)...")

            response = requests.post(
                "https://api.together.xyz/v1/completions",
                headers={
                    "Authorization": f"Bearer {self.together_api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.decision_model,
                    "prompt": decision_prompt,
                    "max_tokens": 700,
                    "temperature": 0.1,
                    "stop": ["<|eot_id|>", "<|end_of_text|>"]
                },
                timeout=30,
            )

            if response.status_code != 200:
                print("âš ï¸ API hatasÄ±, fallback karar")
                return self._fallback_decision()

            llm_response = response.json()["choices"][0]["text"].strip()

            analiz_match = re.search(r'<analiz>(.*?)</analiz>', llm_response, re.DOTALL)
            if analiz_match:
                analiz_text = analiz_match.group(1).strip()
                print(f"\nğŸ’­ LLM DÃ¼ÅŸÃ¼nce SÃ¼reci:")
                for line in analiz_text.split('\n'):
                    line = line.strip()
                    if line:
                        print(f"   {line}")

            json_block_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', llm_response, re.DOTALL)
            if json_block_match:
                json_str = json_block_match.group(1)
            else:
                json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', llm_response, re.DOTALL)
                json_str = json_match.group() if json_match else None

            if json_str:
                decision = json.loads(json_str)

                defaults = {
                    "question_type": "general",
                    "needs_faiss": False,
                    "needs_semantic_memory": False,
                    "needs_chat_history": False,
                    "needs_clarification": False,
                    "tool_name": "yok",
                    "tool_param": "",
                    "response_style": "conversational",
                    "is_farewell": False,
                    "topic_closed": False,
                    "closed_topic_summary": "",
                    "confidence": "medium",
                    "reasoning": ""
                }

                for key, default_val in defaults.items():
                    if key not in decision:
                        decision[key] = default_val

                if decision.get("question_type") or decision.get("tool_name"):
                    if decision.get('question_type') == 'farewell':
                        decision["is_farewell"] = True

                    should_close = (
                        decision.get('question_type') in ['farewell', 'topic_closed'] or
                        decision.get('is_farewell', False)
                    )
                    if should_close:
                        decision["topic_closed"] = True


                    if decision.get('question_type') == 'religious':
                        decision['tool_name'] = 'risale_ara'
                        decision['needs_faiss'] = True  # FAISS her zaman aÃ§Ä±k
                        decision['is_religious'] = True  # Dini konu flag'i

                        is_detail_followup, followup_confidence, matched_concepts = self._detect_detail_followup(
                            user_input, chat_history
                        )
                        if is_detail_followup:
                            decision['is_detail_followup'] = True
                            decision['followup_confidence'] = followup_confidence
                            decision['matched_concepts'] = matched_concepts
                            print(f"   ğŸ”„ TAKÄ°P MODU AKTÄ°F: FAISS arka plan olarak kullanÄ±lacak")
                        else:
                            decision['is_detail_followup'] = False

                    if decision.get('question_type') == 'ambiguous' or decision.get('needs_clarification'):
                        decision['tool_name'] = 'yok'
                        decision['needs_clarification'] = True

                    word_count = len(user_input.split())
                    if word_count <= 4 and not decision.get('needs_chat_history'):
                        decision['needs_chat_history'] = True
                        print(f"   ğŸ“Œ KÄ±sa mesaj ({word_count} kelime) â†’ chat_history zorunlu yapÄ±ldÄ±")

                    confidence_emoji = {"low": "ğŸ”´", "medium": "ğŸŸ¡", "high": "ğŸŸ¢"}.get(decision['confidence'], "ğŸŸ¡")

                    print(f"\nâœ… LLM KararÄ±:")
                    print(f"   â€¢ TÃ¼r: {decision['question_type']}")
                    print(f"   â€¢ GÃ¼ven: {confidence_emoji} {decision['confidence']}")
                    print(f"   â€¢ FAISS: {'âœ…' if decision['needs_faiss'] else 'âŒ'}")
                    print(f"   â€¢ Semantic: {'âœ…' if decision['needs_semantic_memory'] else 'âŒ'}")
                    print(f"   â€¢ History: {'âœ…' if decision['needs_chat_history'] else 'âŒ'}")
                    print(f"   â€¢ Tool: {decision['tool_name']}")
                    if decision['tool_param']:
                        print(f"   â€¢ Tool Param: {decision['tool_param']}")
                    print(f"   â€¢ Stil: {decision['response_style']}")
                    if decision.get('needs_clarification'):
                        print(f"   â€¢ â“ NetleÅŸtirme gerekiyor!")
                    if decision.get('is_farewell'):
                        print(f"   â€¢ ğŸ‘‹ VedalaÅŸma algÄ±landÄ±!")
                    if decision.get('topic_closed'):
                        print(f"   â€¢ ğŸ“• KONU KAPANDI: {decision.get('closed_topic_summary', 'Ã¶zet yok')}")
                    if "reasoning" in decision:
                        print(f"   â€¢ Sebep: {decision['reasoning']}")

                    return decision

            print("âš ï¸ JSON parse hatasÄ±, fallback karar")
            print(f"   ğŸ“ Ham LLM yanÄ±tÄ± (son 500 karakter):")
            print(f"   {llm_response[-500:] if len(llm_response) > 500 else llm_response}")
            return self._fallback_decision()

        except Exception as e:
            print(f"âš ï¸ LLM karar hatasÄ±: {e}, fallback karar")
            return self._fallback_decision()

    def _fallback_decision(self) -> Dict[str, Any]:
        """Hata durumunda gÃ¼venli fallback kararÄ± - tÃ¼m baÄŸlamÄ± kullanÄ±r"""
        return {
            "question_type": "general",
            "needs_faiss": False,
            "needs_semantic_memory": True,  # GÃ¼venli mod: hafÄ±za aÃ§
            "needs_chat_history": True,     # GÃ¼venli mod: history aÃ§
            "tool_name": "yok",
            "tool_param": "",
            "response_style": "conversational",
            "is_farewell": False,
            "topic_closed": False,
            "closed_topic_summary": "",
            "confidence": "medium",
            "reasoning": "Fallback: GÃ¼venli mod, tÃ¼m baÄŸlamÄ± kullan"
        }

    def _faiss_ara(self, user_input: str) -> str:
        """FAISS KB'de ara (dini sorularda)"""
        print("ğŸ” FAISS aramasÄ± yapÄ±lÄ±yor...")
        return self.faiss_kb.get_relevant_context(user_input, max_chunks=6)

    def _history_summary(self, chat_history: List[Dict], current_question_type: str = None, max_len: int = 6000) -> str:
        """
        Chat history'den mesajlarÄ± al

        YENÄ° TASARIM (Basit ve Net):
        - Son 12 mesaj (6 user + 6 AI) HER ZAMAN prompt'a gider
        - 12'den eskiler prompt'a GÄ°TMEZ (tampon bÃ¶lgede kalÄ±r)
        - Konu deÄŸiÅŸince tampon bÃ¶lge Ã¶zetlenip TopicMemory'ye gider
        - Eski konuya dÃ¶nÃ¼ldÃ¼ÄŸÃ¼nde TopicMemory'den Ã§ekilir
        """
        if not chat_history:
            return ""

        son_mesajlar = chat_history[-self.max_mesaj:] if len(chat_history) >= self.max_mesaj else chat_history

        if len(son_mesajlar) == 0:
            return ""

        tmp = []
        for m in son_mesajlar:
            is_user = m.get("role") == "user"
            role = "KULLANICI" if is_user else "AI"
            text = m.get("content") or ""
            if text:
                tmp.append(f"[{role}]: {text}")

        return "\n".join(tmp)


    # TEK BÄ°RLEÅÄ°K PROMPT - Full Friend Modu
    SYSTEM_PROMPT = """Sen kullanÄ±cÄ±nÄ±n olgun ve sÄ±cakkanlÄ± bir yapay zeka arkadaÅŸÄ±sÄ±n.

- DoÄŸal uzunlukta cevap ver, gereksiz uzatma
- Samimi ama abartÄ±sÄ±z ol
- Emoji kullanabilirsin (abartmadan)
- KÄ±sa tepkilere (evet, tamam, anladÄ±m) kÄ±sa cevap ver
- KÄ±sa mesajlarÄ± baÄŸlama gÃ¶re yorumla ("umarÄ±m inÅŸ", "aynen" gibi)

ğŸ¯ SORU ANLAMA KURALLARI:
- GÃ¶rÃ¼ÅŸ sorusu (mÄ±?, sence?, avantaj olur mu?) â†’ Ã¶nce NET CEVAP (evet/hayÄ±r/bence...), sonra kÄ±sa aÃ§Ä±klama
- KullanÄ±cÄ± teknik detay sormadÄ±ysa â†’ teknik detay, zorluklar, sistemsel ihtiyaÃ§lar ANLATMA
- Senaryo/fikir tartÄ±ÅŸmasÄ± istiyorsa â†’ onunla birlikte dÃ¼ÅŸÃ¼n, ders verme
- SADECE sorulan ÅŸeye cevap ver, istenmeyen bilgi ekleme

âš ï¸ Ã–NEMLÄ°: AÅŸaÄŸÄ±da [ğŸ’¬ Ã–nceki KonuÅŸma] bÃ¶lÃ¼mÃ¼ varsa, bu DEVAM EDEN bir sohbettir - direkt cevaba geÃ§, gereksiz giriÅŸ cÃ¼mlesi veya baÄŸlam tekrarÄ± yapma!

ğŸ”´ DÄ°NÄ° KONULARDA (verilen metin varsa):
- CevabÄ± VERÄ°LEN METÄ°NDEN oluÅŸtur
- "Risale'de", "metinde" DEME - gizli kaynak olarak kullan
- Temsilleri KENDÄ° sÃ¶zÃ¼nmÃ¼ÅŸ gibi anlat
- Vaaz deÄŸil sohbet tonu"""

    # Geriye uyumluluk iÃ§in (eski kod hala role parametresi kullanÄ±yorsa)
    ROLE_SYSTEM_PROMPTS = {
        "friend": SYSTEM_PROMPT,
        "religious_teacher": SYSTEM_PROMPT
    }

    def _extract_used_concepts(self, previous_response: str) -> List[str]:
        """Ã–nceki cevapta kullanÄ±lan temsil ve kavramlarÄ± Ã§Ä±kar"""
        if not previous_response:
            return []

        temsiller = [
            "gÃ¼neÅŸ", "ayna", "damla", "deniz", "zerre", "ÅŸems",
            "Ä±ÅŸÄ±k", "nur", "feyz", "tecelli", "yansÄ±ma", "akis",
            "ressam", "tablo", "nakkaÅŸ", "san'at", "kitap", "harf",
            "sultan", "padiÅŸah", "ordu", "asker", "fabrika", "makine"
        ]

        kavramlar = [
            "ÅŸeffafiyet", "mukabele", "mÃ¼vazene", "intizam",
            "melekÃ»tiyet", "mÃ¼lk", "taalluk", "vahdet", "kesret",
            "tecezzÃ®", "tenakus", "tekebbÃ¼r", "temsil", "tefekkÃ¼r",
            "kayyumiyet", "rububiyet", "uluhiyet", "vahdaniyet"
        ]

        used = []
        lower_response = previous_response.lower()

        for t in temsiller + kavramlar:
            if t in lower_response:
                used.append(t)

        return used

    def _detect_detail_followup(self, user_input: str, chat_history: List[Dict[str, Any]]) -> Tuple[bool, float, List[str]]:
        """
        Ä°ki katmanlÄ± takip sorusu tespiti

        KATMAN 1 (Ã–NCELÄ°KLÄ°): Kavram eÅŸleÅŸmesi
        - KullanÄ±cÄ±nÄ±n sorusundaki anahtar kelimeler Ã¶nceki cevabÄ±nda geÃ§iyor mu?

        KATMAN 2: Soru kalÄ±plarÄ±
        - "bu ne demek?", "nasÄ±l yani?", "Ã¶rnek verir misin?" gibi kalÄ±plar

        Returns:
            (is_followup, confidence_score, matched_concepts)
        """
        if not chat_history:
            return False, 0.0, []

        user_lower = user_input.lower()

        last_ai_response = ""
        for msg in reversed(chat_history):
            if msg.get('role') == 'assistant':
                last_ai_response = msg.get('content', '')
                break

        if not last_ai_response:
            return False, 0.0, []

        used_concepts = self._extract_used_concepts(last_ai_response)
        matched_concepts = []

        for concept in used_concepts:
            concept_variants = [concept]
            if 'b' in concept:
                concept_variants.append(concept.replace('b', 'p'))
            if 'p' in concept:
                concept_variants.append(concept.replace('p', 'b'))

            for variant in concept_variants:
                if variant in user_lower:
                    matched_concepts.append(concept)
                    break

        followup_patterns = [
            "bu ne demek", "nasÄ±l oluyor", "neden bÃ¶yle",
            "Ã¶rnek verir misin", "Ã¶rnek ver", "anlamadÄ±m",
            "aÃ§Ä±kla", "aÃ§Ä±klar mÄ±sÄ±n", "tam olarak", "nasÄ±l yani",
            "ne demek istedi", "ne demek bu", "yani nasÄ±l",
            "biraz daha", "detay ver", "mesela", "peki nasÄ±l",
            "nedir bu", "ne anlama", "aÃ§ar mÄ±sÄ±n"
        ]
        pattern_match = any(p in user_lower for p in followup_patterns)


        if matched_concepts and pattern_match:
            confidence = 0.95
            is_followup = True
            print(f"   ğŸ¯ TAKÄ°P TESPÄ°T: Kavram + KalÄ±p eÅŸleÅŸti (gÃ¼ven: %{int(confidence*100)})")
            print(f"      EÅŸleÅŸen kavramlar: {matched_concepts}")

        elif len(matched_concepts) >= 2:
            confidence = 0.85
            is_followup = True
            print(f"   ğŸ¯ TAKÄ°P TESPÄ°T: 2+ kavram eÅŸleÅŸti (gÃ¼ven: %{int(confidence*100)})")
            print(f"      EÅŸleÅŸen kavramlar: {matched_concepts}")

        elif matched_concepts:
            confidence = 0.70
            is_followup = True
            print(f"   ğŸ¯ TAKÄ°P TESPÄ°T: 1 kavram eÅŸleÅŸti (gÃ¼ven: %{int(confidence*100)})")
            print(f"      EÅŸleÅŸen kavram: {matched_concepts}")

        elif pattern_match and len(chat_history) >= 2:
            confidence = 0.55
            is_followup = True
            print(f"   ğŸ¯ TAKÄ°P TESPÄ°T: Soru kalÄ±bÄ± (gÃ¼ven: %{int(confidence*100)})")

        else:
            confidence = 0.0
            is_followup = False

        return is_followup, confidence, matched_concepts

    def _add_exclusion_to_prompt(self, role_prompt: str, used_concepts: List[str]) -> str:
        """KullanÄ±lmÄ±ÅŸ kavramlarÄ± prompt'a yasak olarak ekle"""
        if not used_concepts:
            return role_prompt

        exclusion_text = f"""
ğŸš« BU KAVRAMLARI TEKRAR KULLANMA (Ã¶nceki cevapta kullanÄ±ldÄ±):
{', '.join(used_concepts)}

BunlarÄ±n yerine VERÄ°LEN METÄ°NDEKÄ° DÄ°ÄER kavram ve temsilleri kullan veya FARKLI aÃ§Ä±dan anlat.
"""
        if "âŒ YAPMA:" in role_prompt:
            return role_prompt.replace("âŒ YAPMA:", f"{exclusion_text}\nâŒ YAPMA:")
        else:
            return role_prompt + exclusion_text

    def _prompt_olustur(
        self,
        user_input: str,
        tool_result: Optional[str],
        semantic_context: str,
        faiss_context: str,
        chat_history: str,
        role: str,
        closed_topics_warning: str = "",  # KapanmÄ±ÅŸ konu uyarÄ±sÄ±
        silent_long_term_context: str = "",  # ğŸ†• Sessiz uzun dÃ¶nem baÄŸlamÄ±
        needs_clarification: bool = False,  # ğŸ†• NetleÅŸtirme gerekli mi?
        llm_reasoning: str = "",  # ğŸ§  DecisionLLM'in Ã¶n araÅŸtÄ±rmasÄ±
        is_topic_closed: bool = False,  # ğŸ†• Konu kapandÄ± mÄ±? (kÄ±sa cevap ver)
        is_detail_followup: bool = False,  # ğŸ†• Takip sorusu mu? (FAISS arka plan olarak)
        tool_name: str = "yok",  # ğŸ†• KullanÄ±lan araÃ§ (web_ara iÃ§in Ã¶zel mod)
    ) -> str:
        """Final prompt'u oluÅŸtur (rol'e gÃ¶re)"""

        zaman = get_current_datetime()
        zaman_satiri = f"[â° ZAMAN BÄ°LÄ°NCÄ°]: {zaman['full']} ({zaman['zaman_dilimi']})"

        # Tek birleÅŸik prompt kullan
        role_prompt = self.SYSTEM_PROMPT

        # Dini konularda tekrar yasaÄŸÄ± kontrolÃ¼
        is_religious = role in ["religious_teacher", "religious"] or "risale_ara" in str(tool_name)
        if is_religious and chat_history and not is_detail_followup:
            used_concepts = self._extract_used_concepts(chat_history)
            if used_concepts:
                role_prompt = self._add_exclusion_to_prompt(role_prompt, used_concepts)
                print(f"ğŸš« Tekrar yasaÄŸÄ±na eklenen kavramlar: {', '.join(used_concepts)}")
        elif is_detail_followup:
            print(f"   â© Tekrar yasaÄŸÄ± atlandÄ± (takip modu - kullanÄ±cÄ± kavramÄ± soruyor)")

        combined_sources = []


        if closed_topics_warning:
            combined_sources.append(f"[âš ï¸ KAPANMIÅ KONULAR - TEKRAR AÃ‡MA!]:\n{closed_topics_warning}")

        if tool_result:
            if tool_name == "web_ara" or tool_name == "wiki_ara":
                combined_sources.append(f"[ğŸŒ Ä°NTERNET ARAÅTIRMASI]:\n{tool_result}\n\nâš ï¸ Bu bilgi soruyla alakalÄ± mÄ±? AlakasÄ±z veya yanlÄ±ÅŸ ise HÄ°Ã‡ KULLANMA, kendi bilginle cevap ver.")
            elif tool_name == "risale_ara":
                if is_detail_followup:
                    combined_sources.append(f"[ğŸ”‡ ARKA PLAN BÄ°LGÄ°SÄ° - DoÄŸrudan verme, kendi yorumunla aÃ§Ä±kla!]:\n{tool_result}")
                else:
                    combined_sources.append(f"[ğŸ“š RÄ°SALE-Ä° NUR'DAN - BU BÄ°LGÄ°YÄ° KULLAN!]:\n{tool_result}")
            else:
                combined_sources.append(f"[ğŸ”§ ARAÃ‡ SONUCU]:\n{tool_result}")

        if chat_history:
            combined_sources.append(f"[ğŸ’¬ Ã–nceki KonuÅŸma (DEVAM EDEN SOHBET - tekrar selamlama YAPMA!)]:\n{chat_history}")

        if semantic_context:
            combined_sources.append(f"[HAFIZA]:\n{semantic_context}")

        if faiss_context and not tool_result:
            combined_sources.append(f"[BÄ°LGÄ° TABANI]:\n{faiss_context}")

        if silent_long_term_context:
            combined_sources.append(f"[ğŸ”‡ ARKA PLAN BÄ°LGÄ°SÄ° - KULLANICIYA SÃ–YLEME]:\n{silent_long_term_context}")

        # KullanÄ±cÄ± profili ekle (varsa)
        if hasattr(self, 'profile_manager'):
            profile_context = self.profile_manager.get_prompt_context()
            if profile_context:
                combined_sources.insert(0, f"[ğŸ‘¤ KULLANICI PROFÄ°LÄ° - doÄŸal kullan, ezberletme]:\n{profile_context}")

        if not combined_sources:
            sep = "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            return f"""<|begin_of_text|><|start_header_id|>user<|end_header_id|>

{zaman_satiri}

[ğŸ­ ROL]: {role.upper()}
{role_prompt}

{sep}
ğŸ“‹ KURALLAR:
{sep}
1. âŒ Soruyu tekrarlama, liste yapma (*, -, 1. 2. 3.)
2. âœ… Kendi bilgin gibi Ã¶zgÃ¼venle sun
3. âœ… Samimi TÃ¼rkÃ§e konuÅŸ
4. âœ… RolÃ¼ne uygun davran

{sep}
ğŸ“© YENÄ° MESAJ:
{sep}
{user_input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""

        combined_str = "\n\n".join(combined_sources)

        # Tek tutarlÄ± yapÄ±landÄ±rma
        max_length = 2000  # Sabit maksimum uzunluk

        dynamic_rules = []

        if closed_topics_warning:
            dynamic_rules.append(f"âš ï¸ KAPANMIÅ KONU: \"{closed_topics_warning}\" konusu kapandÄ±, tekrar AÃ‡MA!")

        if silent_long_term_context:
            dynamic_rules.append("ğŸ”‡ Arka plan bilgisini sessizce kullan, zorla hatÄ±rlatma yapma")

        if tool_result:
            if tool_name == "web_ara" or tool_name == "wiki_ara":
                dynamic_rules.append("ğŸŒ Ä°nternet bilgisi geldi - alakalÄ±ysa kullan, alakasÄ±z veya yanlÄ±ÅŸ ise HÄ°Ã‡ KULLANMA!")
            else:
                dynamic_rules.append("ğŸ” ARAÃ‡ SONUCU verildi - bu bilgiyi MUTLAKA kullan, kendi tahminini yapma!")

        if needs_clarification:
            dynamic_rules.append("â“ BELÄ°RSÄ°Z SORU - Ã¶nce netleÅŸtirici soru sor, tahmin etme!")

        if is_topic_closed:
            dynamic_rules.append("ğŸ“• KONU KAPANDI - sadece 1-2 cÃ¼mle ile kapat")

        dynamic_rules_str = ""
        if dynamic_rules:
            dynamic_rules_str = "\n" + "\n".join([f"â€¢ {r}" for r in dynamic_rules])

        if (tool_name == "web_ara" or tool_name == "wiki_ara") and tool_result:
            context_header = "BaÄŸlam (Ä°NTERNET BÄ°LGÄ°SÄ° - alakalÄ±ysa kullan, deÄŸilse kullanma!):"
        elif is_detail_followup and tool_result:
            context_header = "BaÄŸlam (Arka plan - kendi yorumunla aÃ§Ä±kla):"
        elif tool_result:
            context_header = "BaÄŸlam (ARAÃ‡ SONUCUNU MUTLAKA KULLAN!):"
        else:
            context_header = "BaÄŸlam (Kullan, ama sadece GERÃ‡EKTEN alakalÄ±ysa):"

        # Dini konularda mÄ± belirleme
        is_religious_topic = is_religious or tool_name == "risale_ara"

        if is_religious_topic:
            if is_detail_followup:
                rules_text = """KURALLAR (TAKÄ°P SORUSU - AÃ‡IKLAMA MODU):
1. ğŸ”‡ ARKA PLAN bilgisini DOÄRUDAN VERME, referans olarak kullan
2. âœ… KENDÄ° YORUMUNLA ve Ã–RNEKLERLE aÃ§Ä±kla
3. âœ… Ã–nceki cevabÄ±ndan devam et, baÄŸlamÄ± koru
4. âœ… GÃ¼nlÃ¼k hayattan somut Ã¶rnekler ver
5. âœ… Samimi TÃ¼rkÃ§e konuÅŸ
6. âŒ Metni kopyala-yapÄ±ÅŸtÄ±r YAPMA, sindirerek anlat
7. ğŸ­ Bir arkadaÅŸÄ±na anlatÄ±r gibi aÃ§Ä±kla"""
            else:
                rules_text = """KURALLAR:
1. âš ï¸ YanlÄ±ÅŸ bilgiyi onaylama, nazikÃ§e dÃ¼zelt
2. âŒ Soruyu tekrarlama, liste yapma (*, -, 1. 2. 3.)
3. âœ… VERÄ°LEN METÄ°NDEN anlat - metindeki kavramlarÄ± MUTLAKA kullan
4. âœ… Samimi TÃ¼rkÃ§e konuÅŸ
5. ğŸ”„ Kendini tekrar etme, sohbeti ilerlet"""
        else:
            rules_text = """KURALLAR:
1. âš ï¸ YanlÄ±ÅŸ bilgiyi onaylama, nazikÃ§e dÃ¼zelt
2. âŒ Soruyu tekrarlama, liste yapma (*, -, 1. 2. 3.)
3. âŒ KAYNAK BELÄ°RTME YASAK: "Kaynaklara gÃ¶re" gibi ifadeler KULLANMA
4. âœ… Kendi bilgin gibi Ã¶zgÃ¼venle sun
5. âœ… Samimi TÃ¼rkÃ§e konuÅŸ
6. ğŸ”„ AynÄ± ÅŸeyleri dÃ¶ngÃ¼ye sokma, her cevap taze olsun"""

        sep = "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

        prompt = f"""<|begin_of_text|><|start_header_id|>user<|end_header_id|>

{zaman_satiri}

{role_prompt}

{sep}
ğŸ“š BAÄLAM (gerekirse kullan):
{sep}
{combined_str}

{sep}
ğŸ“‹ KURALLAR:
{sep}
{rules_text}{dynamic_rules_str}

{sep}
ğŸ“© YENÄ° MESAJ:
{sep}
{user_input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""

        return prompt


    async def hazirla_ve_prompt_olustur(
        self, user_input: str, chat_history: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        SEKRETER'Ä°N ANA GÃ–REVÄ° - TEK LLM KARAR SÄ°STEMÄ°!

        1. LLM'e karar verdirme (keyword yok! hem kaynak hem tool)
        2. LLM'in seÃ§tiÄŸi tool'u Ã§alÄ±ÅŸtÄ±r
        3. BaÄŸlamÄ± topla (LLM'in kararÄ±na gÃ¶re!)
        4. Prompt'u hazÄ±rla
        5. Gemma3 iÃ§in hazÄ±r paketi dÃ¶ndÃ¼r
        """
        print("\n" + "=" * 60)
        print("ğŸ“‹ SEKRETER Ã‡ALIÅIYOR (TEK LLM SÄ°STEMÄ°)")
        print("=" * 60)
        print(f"ğŸ“ KullanÄ±cÄ±: {user_input}")

        is_closed, closed_summary = self.is_topic_closed(user_input)
        if is_closed:
            print(f"âš ï¸ UYARI: Bu soru kapanmÄ±ÅŸ bir konuya benziyor: '{closed_summary}'")
            print("   AI'a bu konuyu tekrar aÃ§mamasÄ± sÃ¶ylenecek.")

        print("\nğŸ§  1. LLM tek karar veriyor (hem kaynak hem tool)...")
        decision = self._intelligent_decision(user_input, chat_history)

        if decision.get('topic_closed', False):
            topic_summary = decision.get('closed_topic_summary', '')

            if not topic_summary:
                if chat_history:
                    for msg in reversed(chat_history):
                        if msg.get('role') == 'assistant':
                            content = (msg.get('content') or '')[:100]
                            if content and len(content) > 5:
                                topic_summary = content
                                break

                if not topic_summary and chat_history:
                    for msg in reversed(chat_history):
                        if msg.get('role') == 'user':
                            content = (msg.get('content') or '').strip()
                            if content and len(content) > 10 and not any(
                                w in content.lower() for w in ['teÅŸekkÃ¼r', 'saÄŸol', 'eyvallah', 'gÃ¶rÃ¼ÅŸÃ¼rÃ¼z', 'bye', 'hoÅŸÃ§a']
                            ):
                                topic_summary = content[:100]
                                break

                if not topic_summary and decision.get('reasoning'):
                    topic_summary = decision['reasoning'][:100]

            if topic_summary:
                print(f"ğŸ’¾ Konu kaydediliyor: '{topic_summary[:50]}...'")
                self.add_closed_topic(topic_summary, chat_history)
            else:
                print("âš ï¸ topic_closed=true ama Ã¶zet Ã§Ä±karÄ±lamadÄ±, kayÄ±t atlandÄ±")

        tool_name = decision.get('tool_name', 'yok')
        tool_param = decision.get('tool_param', '')

        print(f"\nğŸ› ï¸ 2. AraÃ§ Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor (LLM kararÄ±: {tool_name})...")
        tool_result = await self._tool_calistir(tool_name, tool_param, user_input)

        print("\nğŸ“š 3. BaÄŸlam toplanÄ±yor (LLM kararÄ±na gÃ¶re)...")

        if decision['needs_semantic_memory']:
            semantic_context = self._hafizada_ara(user_input, len(chat_history))
            print(f"   â€¢ Semantic HafÄ±za: {'âœ… bulundu' if semantic_context else 'âŒ bulunamadÄ±'} (LLM kararÄ±)")
        else:
            semantic_context = ""
            print("   â€¢ Semantic HafÄ±za: â© atlandÄ± (LLM: gereksiz)")

        if decision['needs_faiss'] and tool_name != "risale_ara":
            faiss_context = self._faiss_ara(user_input)
            print(f"   â€¢ FAISS KB: {'âœ… bulundu' if faiss_context else 'âŒ bulunamadÄ±'} (LLM kararÄ±)")
        elif tool_name == "risale_ara":
            faiss_context = ""  # Tool zaten FAISS kullandÄ±, duplicate arama yapma
            print("   â€¢ FAISS KB: â© atlandÄ± (risale_ara tool'u zaten FAISS kullandÄ±)")
        else:
            faiss_context = ""
            print("   â€¢ FAISS KB: â© atlandÄ± (LLM: gereksiz)")


        if self.conversation_context:
            topic_changed = self.conversation_context.check_topic_before_response(
                user_input, chat_history
            )
            if topic_changed:
                print(f"   â€¢ ğŸ”„ Yeni konu algÄ±landÄ± - eski baÄŸlam temizlendi")

        conversation_context = self.get_conversation_context()
        if conversation_context:
            print(f"   â€¢ ğŸ§  ConversationContext: âœ… LLM Ã¶zeti enjekte edildi")
        else:
            print(f"   â€¢ ğŸ§  ConversationContext: â© henÃ¼z Ã¶zet yok")

        silent_long_term_context = ""
        if self.should_check_long_term_memory(user_input):
            silent_long_term_context = self.get_silent_long_term_context(user_input)
            if silent_long_term_context:
                print(f"   â€¢ ğŸ”‡ TopicMemory: âœ… sessiz baÄŸlam enjekte edildi")
            else:
                print(f"   â€¢ ğŸ”‡ TopicMemory: âŒ eÅŸleÅŸme yok")
        else:
            print("   â€¢ ğŸ”‡ TopicMemory: â© atlandÄ± (geÃ§miÅŸ referansÄ± yok)")

        combined_silent_context = ""
        if conversation_context:
            combined_silent_context = conversation_context
        if silent_long_term_context:
            if combined_silent_context:
                combined_silent_context += "\n\n" + silent_long_term_context
            else:
                combined_silent_context = silent_long_term_context

        question_type = decision['question_type']

        # SABÄ°T HISTORY - self.max_mesaj ile tutarlÄ± (ton deÄŸiÅŸikliÄŸi Ã¶nlenir)
        max_history_msgs = self.max_mesaj  # 20

        # Telegram history varsa onu kullan
        if chat_history and len(chat_history) > 0:
            limited_history = chat_history[-max_history_msgs:] if len(chat_history) > max_history_msgs else chat_history

            chat_history_summary = self._history_summary(
                limited_history,
                current_question_type=question_type
            )
            print(f"   â€¢ Chat History: âœ… son {len(limited_history)} mesaj dahil edildi ({len(limited_history)}/{len(chat_history)} toplam)")

        # Telegram history boÅŸsa ama self.hafiza doluysa, oradan Ã¶zet oluÅŸtur
        elif self.hafiza and len(self.hafiza) > 0:
            # self.hafiza formatÄ±nÄ± chat_history formatÄ±na Ã§evir
            hafiza_as_history = []
            for m in self.hafiza[-max_history_msgs:]:
                hafiza_as_history.append({
                    "role": m.get("rol", "user"),
                    "content": m.get("mesaj", "")
                })

            chat_history_summary = self._history_summary(
                hafiza_as_history,
                current_question_type=question_type
            )
            print(f"   â€¢ Chat History: âœ… HafizaAsistani'dan {len(hafiza_as_history)} mesaj kullanÄ±ldÄ± (Telegram session timeout)")
        else:
            chat_history_summary = ""
            print("   â€¢ Chat History: â© henÃ¼z yok")

        print("\nğŸ­ 4. Tek kiÅŸilik kullanÄ±lÄ±yor...")
        # ArtÄ±k ayrÄ± roller yok, tek tutarlÄ± kiÅŸilik
        role = "default"
        print(f"   â€¢ Mod: unified (tek kiÅŸilik)")

        closed_topics_warning = ""
        if is_closed and closed_summary:
            user_wants_reopen = self._user_wants_to_reopen_topic(user_input)

            if user_wants_reopen:
                print(f"   â€¢ KapanmÄ±ÅŸ Konu: '{closed_summary}' - KullanÄ±cÄ± tekrar aÃ§mak istiyor âœ…")
            else:
                closed_topics_warning = closed_summary
                print(f"   â€¢ KapanmÄ±ÅŸ Konu UyarÄ±sÄ±: '{closed_summary}' - AI'a bildirildi")
        else:
            print("   â€¢ KapanmÄ±ÅŸ Konu: Yok veya ilgisiz â©")

        print("\nğŸ“ 6. Prompt hazÄ±rlanÄ±yor...")
        needs_clarification = decision.get('needs_clarification', False)
        llm_reasoning = decision.get('reasoning', '')  # ğŸ§  DecisionLLM'in Ã¶n araÅŸtÄ±rmasÄ±
        is_topic_closed = decision.get('topic_closed', False)  # ğŸ“• Konu kapandÄ± mÄ±?
        is_detail_followup = decision.get('is_detail_followup', False)  # ğŸ†• Takip sorusu mu?

        if is_detail_followup:
            print(f"   â€¢ ğŸ”„ TAKÄ°P MODU: FAISS arka plan olarak kullanÄ±lacak")
            print(f"   â€¢ ğŸ“Š GÃ¼ven: %{int(decision.get('followup_confidence', 0) * 100)}")

        final_prompt = self._prompt_olustur(
            user_input,
            tool_result,
            semantic_context,
            faiss_context,
            chat_history_summary,
            role,
            closed_topics_warning,  # Sadece gerektiÄŸinde dolu
            combined_silent_context,  # ğŸ§ ğŸ”‡ BirleÅŸik baÄŸlam (ConversationContext + TopicMemory)
            needs_clarification,  # ğŸ†• NetleÅŸtirme gerekli mi?
            llm_reasoning,  # ğŸ§  DecisionLLM'in Ã¶n araÅŸtÄ±rmasÄ± - KOPUKLUK DÃœZELTMESÄ°!
            is_topic_closed,  # ğŸ“• Konu kapandÄ± mÄ±? (kÄ±sa cevap ver)
            is_detail_followup,  # ğŸ†• Takip sorusu mu? (FAISS arka plan olarak)
            tool_name,  # ğŸŒ KullanÄ±lan araÃ§ (web_ara iÃ§in Ã¶zel mod)
        )
        print(f"   â€¢ Prompt uzunluÄŸu: {len(final_prompt)} karakter")

        paket = {
            "prompt": final_prompt,
            "role": role,
            "tool_used": tool_name,
            "llm_decision": decision,
            "metadata": {
                "has_tool_result": tool_result is not None,
                "has_semantic": bool(semantic_context),
                "has_faiss": bool(faiss_context),
                "has_history": bool(chat_history_summary),
                "has_context_memory": bool(combined_silent_context),  # ğŸ§ ğŸ”‡ BirleÅŸik baÄŸlam
                "closed_topic_filtered": is_closed,  # KapanmÄ±ÅŸ konu filtresi uygulandÄ± mÄ±
                "needs_clarification": needs_clarification,  # ğŸ†• NetleÅŸtirme gerekli mi?
                "is_detail_followup": is_detail_followup,  # ğŸ†• Takip sorusu mu?
            },
        }

        print("\nâœ… SEKRETER HAZIR - Tek LLM kararÄ±yla paket oluÅŸturuldu!")
        print("=" * 60 + "\n")

        return paket


    def set_faiss_kb(self, faiss_kb):
        """FAISS KB'yi inject et"""
        self.faiss_kb.set_faiss_kb(faiss_kb)
        print(f"âœ… FAISS KB inject edildi (aktif: {self.faiss_kb.enabled})")

    @property
    def data(self):
        """Geriye uyumluluk: hafiza.data"""
        return self.hafiza

    @property
    def reranker(self):
        """Geriye uyumluluk: reranker var mÄ±? (ÅŸu an yok)"""
        return None

    def should_search_memory(self, chat_history_length: int) -> bool:
        """
        Geriye uyumluluk: HafÄ±za aramasÄ± yapÄ±lmalÄ± mÄ±?
        Eski PersonalAI bu metodu kullanÄ±yor
        """
        if not self.hafiza or len(self.hafiza) == 0:
            return False
        if len(self.hafiza) < 3:
            return False
        if chat_history_length == 0 and len(self.hafiza) > 0:
            return True
        return True

    def search_with_rerank(
        self, query: str, top_k: Optional[int] = None, initial_k: int = 50
    ) -> str:
        """
        Geriye uyumluluk: Reranker ile arama
        (Åu an normal search'e yÃ¶nlendiriliyor)
        """
        return self.search(query, top_k)

    def ilgili_mesajlari_bul(
        self, yeni_mesaj: str, max_mesaj: Optional[int] = None
    ) -> List[Dict[str, str]]:
        """
        Geriye uyumluluk: Ä°lgili mesajlarÄ± bul (eski API)
        NOT: ArtÄ±k _search_internal() kullanÄ±yor (Ã§ift iÅŸlem kaldÄ±rÄ±ldÄ±)
        Returns: [{"rol": "user", "mesaj": "..."}, ...]
        """
        if not self.hafiza or not yeni_mesaj:
            return []

        k = max_mesaj or self.max_mesaj
        return self._search_internal(yeni_mesaj, k)

    def son_mesajlari_al(self, n: int = 3) -> List[Dict[str, str]]:
        """
        Geriye uyumluluk: Son n mesajÄ± dÃ¶ndÃ¼r
        """
        if len(self.hafiza) < n:
            n = len(self.hafiza)

        son_mesajlar = self.hafiza[-n:]
        return [{"rol": m["rol"], "mesaj": m["mesaj"]} for m in son_mesajlar]

    def set_llm(self, llm):
        """LLM referansÄ±nÄ± ayarla - PersonalAI'dan Ã§aÄŸrÄ±lÄ±r"""
        self.llm = llm
        print("âœ… LLM HafizaAsistani'ya baÄŸlandÄ±")

    def _build_messages(
        self,
        user_input: str,
        paket: Dict[str, Any],
        chat_history: List[Dict] = None
    ) -> List[Dict[str, str]]:
        """
        Messages formatÄ± oluÅŸtur - LLM iÃ§in proper chat format

        Returns: [
            {"role": "system", "content": "..."},
            {"role": "user", "content": "msg1"},
            {"role": "assistant", "content": "resp1"},
            {"role": "user", "content": "current_input + context"}
        ]
        """
        messages = []

        # 1. System message - SYSTEM_PROMPT + zaman
        zaman = get_current_datetime()
        system_content = f"""{self.SYSTEM_PROMPT}

[â° ÅU AN]: {zaman['full']} ({zaman['zaman_dilimi']})"""

        messages.append({"role": "system", "content": system_content})

        # 2. Chat history - user/assistant rolleri ile
        max_history = self.max_mesaj  # 20

        # Telegram history varsa onu kullan
        if chat_history and len(chat_history) > 0:
            limited_history = chat_history[-max_history:] if len(chat_history) > max_history else chat_history
            for msg in limited_history:
                role = msg.get('role', 'user')
                content = msg.get('content', '')
                if content and role in ['user', 'assistant']:
                    messages.append({"role": role, "content": content})

        # Telegram history boÅŸsa self.hafiza'dan al
        elif self.hafiza and len(self.hafiza) > 0:
            for m in self.hafiza[-max_history:]:
                rol = m.get("rol", "user")
                mesaj = m.get("mesaj", "")
                if mesaj:
                    messages.append({"role": rol, "content": mesaj})

        # 3. Son user message - context ile birlikte
        context_parts = []

        # Metadata'dan context bilgilerini al
        metadata = paket.get('metadata', {})
        llm_decision = paket.get('llm_decision', {})

        # Prompt'tan context kÄ±sÄ±mlarÄ±nÄ± Ã§Ä±kar
        prompt = paket.get('prompt', '')

        # Tool result varsa ekle
        if metadata.get('has_tool_result'):
            tool_name = paket.get('tool_used', '')
            # Prompt'tan tool result'Ä± Ã§Ä±karmaya Ã§alÄ±ÅŸ
            if '[ğŸŒ Ä°NTERNET ARAÅTIRMASI]:' in prompt:
                start = prompt.find('[ğŸŒ Ä°NTERNET ARAÅTIRMASI]:')
                end = prompt.find('\n\n[', start + 1)
                if end == -1:
                    end = prompt.find('â”â”â”', start + 1)
                if start != -1 and end != -1:
                    context_parts.append(prompt[start:end].strip())
            elif '[ğŸ“š RÄ°SALE-Ä° NUR\'DAN' in prompt:
                start = prompt.find('[ğŸ“š RÄ°SALE-Ä° NUR\'DAN')
                end = prompt.find('\n\n[', start + 1)
                if end == -1:
                    end = prompt.find('â”â”â”', start + 1)
                if start != -1 and end != -1:
                    context_parts.append(prompt[start:end].strip())

        # Semantic context varsa ekle
        if metadata.get('has_semantic'):
            if '[HAFIZA]:' in prompt:
                start = prompt.find('[HAFIZA]:')
                end = prompt.find('\n\n[', start + 1)
                if end == -1:
                    end = prompt.find('â”â”â”', start + 1)
                if start != -1 and end != -1:
                    context_parts.append(prompt[start:end].strip())

        # FAISS context varsa ekle
        if metadata.get('has_faiss'):
            if '[BÄ°LGÄ° TABANI]:' in prompt:
                start = prompt.find('[BÄ°LGÄ° TABANI]:')
                end = prompt.find('\n\n[', start + 1)
                if end == -1:
                    end = prompt.find('â”â”â”', start + 1)
                if start != -1 and end != -1:
                    context_parts.append(prompt[start:end].strip())

        # KullanÄ±cÄ± profili varsa ekle
        if '[ğŸ‘¤ KULLANICI PROFÄ°LÄ°' in prompt:
            start = prompt.find('[ğŸ‘¤ KULLANICI PROFÄ°LÄ°')
            end = prompt.find('\n\n[', start + 1)
            if end == -1:
                end = prompt.find('â”â”â”', start + 1)
            if start != -1 and end != -1:
                context_parts.append(prompt[start:end].strip())

        # Son user message'Ä± oluÅŸtur
        if context_parts:
            user_content = f"""ğŸ“š BaÄŸlam:
{chr(10).join(context_parts)}

ğŸ“© Sorum:
{user_input}"""
        else:
            user_content = user_input

        messages.append({"role": "user", "content": user_content})

        return messages

    async def process(self, user_input: str, chat_history: List[Dict] = None, image_data=None) -> str:
        """
        Ana iÅŸlem metodu - Telegram'dan Ã§aÄŸrÄ±lÄ±r

        AkÄ±ÅŸ: Telegram â†’ HafizaAsistani.process() â†’ PersonalAI.generate() â†’ Telegram

        1. Paket hazÄ±rla (context, tool results, vb.)
        2. Messages formatÄ± oluÅŸtur
        3. LLM'e gÃ¶nder (proper chat format)
        4. CevabÄ± kaydet
        5. CevabÄ± dÃ¶ndÃ¼r
        """
        chat_history = chat_history or []

        # 1. Paket hazÄ±rla
        paket = await self.hazirla_ve_prompt_olustur(user_input, chat_history)

        # 2. LLM kontrolÃ¼
        if not hasattr(self, 'llm') or self.llm is None:
            return "âŒ LLM baÄŸlÄ± deÄŸil!"

        # 3. LLM'e gÃ¶nder
        if image_data:
            # Vision iÃ§in eski prompt formatÄ± kullan
            prompt = paket.get('prompt', user_input)
            response = await self.llm.generate(prompt, image_data)
        else:
            # Text iÃ§in messages formatÄ± kullan (YENÄ°!)
            messages = self._build_messages(user_input, paket, chat_history)
            response = await self.llm.generate(prompt=None, image_data=None, messages=messages)

        # 4. CevabÄ± kaydet
        self.add(user_input, response, chat_history)

        # 5. DÃ¶ndÃ¼r
        return response


async def test_sekreter():
    print("\n" + "=" * 60)
    print("ğŸ§ª HafizaAsistani v3.0 TEST")
    print("=" * 60)

    sekreter = HafizaAsistani(saat_limiti=48, esik=0.50, max_mesaj=20)

    print("\n--- TEST 1: Basit Sohbet ---")
    paket1 = await sekreter.hazirla_ve_prompt_olustur(
        user_input="Merhaba, nasÄ±lsÄ±n?",
        chat_history=[],
    )
    print(f"âœ… Prompt hazÄ±r (uzunluk: {len(paket1['prompt'])})")
    print(f"   Role: {paket1['role']}")
    print(f"   Tool: {paket1['tool_used']}")

    print("\n--- TEST 2: Matematik ---")
    paket2 = await sekreter.hazirla_ve_prompt_olustur(
        user_input="15 Ã§arpÄ± 7 kaÃ§ eder?",
        chat_history=[],
    )
    print("âœ… Prompt hazÄ±r")
    print(f"   Tool: {paket2['tool_used']}")
    print(f"   Tool sonucu: {paket2['metadata']['has_tool_result']}")

    print("\n--- TEST 3: Zaman ---")
    paket3 = await sekreter.hazirla_ve_prompt_olustur(
        user_input="Saat kaÃ§?",
        chat_history=[],
    )
    print("âœ… Prompt hazÄ±r")
    print(f"   Tool: {paket3['tool_used']}")

    print("\n" + "=" * 60)
    print("âœ… TÃ¼m testler tamamlandÄ± (elle de deneyebilirsin).")
    print("=" * 60)


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        asyncio.run(test_sekreter())